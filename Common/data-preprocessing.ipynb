{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Set Up\n",
    "This notebook is for the initial set up of the LLM application that will be the same for each model.\n",
    "\n",
    "The focus is on the data-pre processing step of the RAG pipeline and getting the data into the vector database.\n",
    "\n",
    "We need to put the data of the SMU Catalog of 2023-2024 into Qdrant which is a cloud vector database. This will allow the language model to access and retrieve the necessary information.\n",
    "\n",
    "There are many changes that can be done at this step to alter how the text goes into the vector database (ex: different text splitters, document loaders, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the necessary dependecies for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies necessary for this step are: openai, pypdf, qdrant-client, langchain, python-dotenv, tiktoken, langchain-openai, and pandas\n",
    "%pip install openai pypdf qdrant-client langchain python-dotenv tiktoken langchain-openai pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up to initialize API keys from .env file into the\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "find_dotenv(filename='SURF-Project_Optimizing-PerunaBot/setup/.env')\n",
    "load_dotenv(dotenv_path='c:/Users/yawbt/OneDrive/Documents/GitHub/SURF-Project_Optimizing-PerunaBot/setup/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import qdrant_client\n",
    "from qdrant_client.http import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Qdrant host URL and API keys\n",
    "qdrant_host = os.environ['QDRANT_HOST']\n",
    "qdrant_api_key = os.environ['QDRANT_API_KEY']\n",
    "qdrant_collection_name = os.environ['QDRANT_COLLECTION_NAME']\n",
    "\n",
    "#Initialize Qdrant Client\n",
    "client = qdrant_client.QdrantClient(\n",
    "    url=qdrant_host, \n",
    "    api_key = qdrant_api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create 1st collection of vectors\n",
    "\n",
    "vectors_config = models.VectorParams(\n",
    "   size=1536, #for OpenAI\n",
    "   distance=models.Distance.COSINE\n",
    "   )\n",
    "\n",
    "client.recreate_collection(\n",
    "   collection_name = qdrant_collection_name,\n",
    "   vectors_config=vectors_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to create the vectorstore collection inside the database. Eventually, we will have more than one collection to see how changes to how the data is uploaded affects the accuracy and other evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Qdrant\n",
    "\n",
    "\n",
    "# create vector store\n",
    "def get_vector_store():\n",
    "    client = qdrant_client.QdrantClient(\n",
    "    qdrant_host, \n",
    "    api_key = qdrant_api_key,\n",
    "    )\n",
    "\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    vector_store = Qdrant(\n",
    "        client=client, \n",
    "        collection_name=qdrant_collection_name, \n",
    "        embeddings=embeddings,\n",
    "    )\n",
    "\n",
    "    return vector_store\n",
    "\n",
    "# created vector store\n",
    "vector_store = get_vector_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is where the experiment begins! If you take a look at the pdfs in the data folder, the catalog pdf is over 800 pages long! To upload it into the vector databse, we have to 1st get all the text from the pdfs and split it into chunks that can be turned into vectors using langchain text splitters. We will use the OpenAI embedding model to turn the text chunks into vector embeddings.\n",
    "\n",
    "First we will do the PDFs, then later on the CSV of the FAQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing OpenAI API key\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypdf\n",
    "\n",
    "# langchain imports\n",
    "%pip install rank_bm25\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import ParentDocumentRetriever, EnsembleRetriever, BM25Retriever\n",
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "# file paths to the two PDFs we're using\n",
    "pdf_paths = ['C:/Users/yawbt/OneDrive/Documents/GitHub/SURF-Project_Optimizing-PerunaBot/Data/20232024 Undergraduate Catalog91123.pdf',\n",
    "             'C:/Users/yawbt/OneDrive/Documents/GitHub/SURF-Project_Optimizing-PerunaBot/Data/Official University Calendar 2023-2024.pdf'\n",
    "             ]\n",
    "\n",
    "# function to get the text from the PDFs\n",
    "def load_pdf_documents(pdf_paths):\n",
    "    pdf_documents = []\n",
    "    for path in pdf_paths:\n",
    "        try:\n",
    "            # Open the PDF file in binary read mode\n",
    "            with open(path, 'rb') as file:\n",
    "                # Read the PDF file using PyPDF2\n",
    "                pdf_reader = pypdf.PdfReader(file)\n",
    "                pdf_documents.append(pdf_reader)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {path}: {e}\")\n",
    "    return pdf_documents\n",
    "\n",
    "# text from the PDFs\n",
    "pdfs_doc_text = load_pdf_documents(pdf_paths)\n",
    "\n",
    "# langchain text splitting method\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=150, chunk_overlap=30, length_function=len) \n",
    "parent_splitter =RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50, length_function=len)  \n",
    "\n",
    "# storage for parent splitter\n",
    "store = InMemoryStore()\n",
    "\n",
    "# retriever\n",
    "parent_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vector_store, \n",
    "    docstore=store, \n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    "    )\n",
    "\n",
    "# adding split documents into the Qdrant vector database\n",
    "parent_retriever.add_documents(pdfs_doc_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
