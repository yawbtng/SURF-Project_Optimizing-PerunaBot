{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Set Up\n",
    "This notebook is for the initial set up of the LLM application that will be the same for each model.\n",
    "\n",
    "The focus is on the data-pre processing step of the RAG pipeline and getting the data into the vector database.\n",
    "\n",
    "We need to put the data of the SMU Catalog of 2023-2024 into Qdrant which is a cloud vector database. This will allow the language model to access and retrieve the necessary information.\n",
    "\n",
    "There are many changes that can be done at this step to alter how the text goes into the vector database (ex: different text splitters, document loaders, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the necessary dependecies for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "# Dependencies necessary for this step are: openai, pypdf, qdrant-client, langchain, python-dotenv, tiktoken, langchain-openai, and pandas\n",
    "%pip install openai pypdf qdrant-client langchain python-dotenv tiktoken langchain-openai pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up to initialize API keys from .env file into the\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "find_dotenv(filename='SURF-Project_Optimizing-PerunaBot/setup/.env')\n",
    "load_dotenv(dotenv_path='c:/Users/yawbt/OneDrive/Documents/GitHub/SURF-Project_Optimizing-PerunaBot/setup/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import qdrant_client\n",
    "from qdrant_client.http import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Qdrant host URL and API keys\n",
    "qdrant_host = os.environ['QDRANT_HOST']\n",
    "qdrant_api_key = os.environ['QDRANT_API_KEY']\n",
    "qdrant_collection_name = os.environ['QDRANT_COLLECTION_NAME']\n",
    "\n",
    "#Initialize Qdrant Client\n",
    "client = qdrant_client.QdrantClient(\n",
    "    url=qdrant_host, \n",
    "    api_key = qdrant_api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create 1st collection of vectors\n",
    "\n",
    "vectors_config = models.VectorParams(\n",
    "   size=1536, #for OpenAI\n",
    "   distance=models.Distance.COSINE\n",
    "   )\n",
    "\n",
    "client.recreate_collection(\n",
    "   collection_name = qdrant_collection_name,\n",
    "   vectors_config=vectors_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to create the vectorstore collection inside the database. Eventually, we will have more than one collection to see how changes to how the data is uploaded affects the accuracy and other evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Qdrant\n",
    "\n",
    "# create vector store\n",
    "def get_vector_store():\n",
    "    client = qdrant_client.QdrantClient(\n",
    "    qdrant_host, \n",
    "    api_key = qdrant_api_key,\n",
    "    )\n",
    "\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    vector_store = Qdrant(\n",
    "        client=client, \n",
    "        collection_name=qdrant_collection_name, \n",
    "        embeddings=embeddings,\n",
    "    )\n",
    "\n",
    "    return vector_store\n",
    "\n",
    "# created vector store\n",
    "vector_store = get_vector_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is where the experiment begins! If you take a look at the pdfs in the data section"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
