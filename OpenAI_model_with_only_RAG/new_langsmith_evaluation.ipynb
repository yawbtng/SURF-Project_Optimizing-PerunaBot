{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating each RAG pipeline using langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load environment variables from the .env file using 'from dotenv import find_dotenv, load_dotenv'\n",
    "load_dotenv(find_dotenv(filename='SURF-Project_Optimizing-PerunaBot/setup/.env'))\n",
    "\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the 4 different RAG pipelines we made for each evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from OG_PerunaBot_chain import Original_PerunaBot_eval_chain\n",
    "from chain_0 import base_retriever_eval_chain_0\n",
    "from chain_1 import parent_retriever_eval_chain_1\n",
    "from chain_2 import ensemble_retriever_eval_chain_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "\n",
    "# Target task definition\n",
    "\n",
    "# The name or UUID of the LangSmith dataset to evaluate on.\n",
    "\n",
    "data = \"SMU Schools QA\"\n",
    "\n",
    "# A string to prefix the experiment name with.\n",
    "# If not provided, a random string will be generated.\n",
    "experiment_prefix = \"SMU Schools QA\"\n",
    "\n",
    "# List of evaluators to score the outputs of target task\n",
    "evaluators = [\n",
    "  LangChainStringEvaluator(\"cot_qa\"),\n",
    "  LangChainStringEvaluator(\"labeled_criteria\", config={\"criteria\": \"detail\"}),\n",
    "  LangChainStringEvaluator(\"labeled_criteria\", config={\"criteria\": \"coherence\"}),\n",
    "  LangChainStringEvaluator(\"labeled_criteria\", config={\"criteria\": \"relevance\"}),\n",
    "  LangChainStringEvaluator(\"labeled_criteria\", config={\"criteria\": \"helpfulness\"})\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_OG_chain(inputs: dict):\n",
    "    response = Original_PerunaBot_eval_chain.invoke({\"question\": inputs[\"question\"]})\n",
    "    return {\"answer\" : response[\"output\"]}\n",
    "\n",
    "def predict_chain_0(inputs: dict):\n",
    "    response = base_retriever_eval_chain_0.invoke({\"question\": inputs[\"question\"]})\n",
    "    return {\"answer\" : response[\"output\"]}\n",
    "\n",
    "def predict_chain_1(inputs: dict):\n",
    "    response = parent_retriever_eval_chain_1.invoke({\"question\": inputs[\"question\"]})\n",
    "    return {\"answer\" : response[\"output\"]}\n",
    "\n",
    "def predict_chain_2(inputs: dict):\n",
    "    response = ensemble_retriever_eval_chain_2.invoke({\"question\": inputs[\"question\"]})\n",
    "    return {\"answer\" : response[\"output\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'SMU Schools QA on OG PerunaBot chain-a304c553' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/7a23c577-228e-4b2b-a8af-c9e0a13c1625/compare?selectedSessions=ecf88071-640f-4256-974d-9fd4d1a97eac\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f4f8b7b2014c7cb7034e48eccd6b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 98231041-a269-4f41-a1d5-2968d0514a2e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9956, Requested 455. Please try again in 2.466s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9956, Requested 455. Please try again in 2.466s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e5a49a2f-db19-47f9-af4a-0935398a1364: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9960, Requested 417. Please try again in 2.262s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9960, Requested 417. Please try again in 2.262s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run c1d04d3f-dedd-4ea9-b3d0-fd716613e0eb: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9832, Requested 411. Please try again in 1.458s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9832, Requested 411. Please try again in 1.458s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the target task\n",
    "OG_PerunaBot_langsmith_eval = evaluate(\n",
    "  predict_OG_chain,\n",
    "  data=data,\n",
    "  evaluators=evaluators,\n",
    "  experiment_prefix=experiment_prefix + \" on OG PerunaBot chain\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'SMU Schools QA on chain 0-84b421e8' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/7a23c577-228e-4b2b-a8af-c9e0a13c1625/compare?selectedSessions=6e309932-01f3-4527-8494-e22d3aea26a3\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d1749f3df94fa6917ba5c03a3ca5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator evaluate> on run fa9943e0-e122-434b-8408-9b13e89eb842: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9987, Requested 447. Please try again in 2.604s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9987, Requested 447. Please try again in 2.604s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 8ade7397-37cf-4532-b325-67da96b48b12: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9916, Requested 516. Please try again in 2.592s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9916, Requested 516. Please try again in 2.592s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run ac93a675-ddfe-4fe2-80ca-c197510136db: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9916, Requested 521. Please try again in 2.622s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9916, Requested 521. Please try again in 2.622s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run ac93a675-ddfe-4fe2-80ca-c197510136db: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9895, Requested 530. Please try again in 2.55s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9895, Requested 530. Please try again in 2.55s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 73755ae2-aed2-4cb9-b52d-bc1faa021cf2: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9560, Requested 461. Please try again in 125ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9560, Requested 461. Please try again in 125ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 0802c07e-5f77-49dc-95a5-a768610b3644: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9940, Requested 485. Please try again in 2.55s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9940, Requested 485. Please try again in 2.55s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "chain_0_langsmith_eval = evaluate(\n",
    "    predict_chain_0,\n",
    "    data=data,\n",
    "    evaluators=evaluators,\n",
    "    experiment_prefix=experiment_prefix + \" on chain 0\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'SMU Schools QA on chain 1-218c12d4' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/7a23c577-228e-4b2b-a8af-c9e0a13c1625/compare?selectedSessions=f3f2b3db-eb84-40b3-89b5-15243b76b76c\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f77b8828c34ee6a940e3cf17be1f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 85141248-c6ff-43c9-a196-1e40471c7212: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9974, Requested 471. Please try again in 2.67s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9974, Requested 471. Please try again in 2.67s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 2b2ae51a-c06b-4f6f-b464-132a03233b1a: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9590, Requested 498. Please try again in 528ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9590, Requested 498. Please try again in 528ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 85141248-c6ff-43c9-a196-1e40471c7212: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9933, Requested 480. Please try again in 2.478s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9933, Requested 480. Please try again in 2.478s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 2b2ae51a-c06b-4f6f-b464-132a03233b1a: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9631, Requested 507. Please try again in 828ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9631, Requested 507. Please try again in 828ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run ea62d84c-d8bb-462c-8eb8-6c0f3f6a7f43: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9830, Requested 591. Please try again in 2.526s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9830, Requested 591. Please try again in 2.526s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 5cf14db0-17d2-482c-b2bb-68362b97a206: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9981, Requested 459. Please try again in 2.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9981, Requested 459. Please try again in 2.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chain_1_langsmith_eval = evaluate(\n",
    "    predict_chain_1,\n",
    "    data=data,\n",
    "    evaluators=evaluators,\n",
    "    experiment_prefix=experiment_prefix + \" on chain 1\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'SMU Schools QA on chain 2-bc545425' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/7a23c577-228e-4b2b-a8af-c9e0a13c1625/compare?selectedSessions=741bccb0-8b19-42a9-a919-523e38be7eb7\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44bc0375f754941947fc2747c43fbc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 1efeb8bd-5d78-4f16-aaad-5a89628dbedd: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9973, Requested 458. Please try again in 2.586s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9973, Requested 458. Please try again in 2.586s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 8d5c8e7d-6f4c-46ea-a7c4-7bc423213c41: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9978, Requested 471. Please try again in 2.694s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9978, Requested 471. Please try again in 2.694s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 95418e1e-637c-4470-9f09-eedced3612f9: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9934, Requested 598. Please try again in 3.192s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9934, Requested 598. Please try again in 3.192s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 8d5c8e7d-6f4c-46ea-a7c4-7bc423213c41: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9972, Requested 480. Please try again in 2.712s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9972, Requested 480. Please try again in 2.712s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 51dcdcaa-1456-460f-91f9-8d3de7ad86dc: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9649, Requested 479. Please try again in 768ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9649, Requested 479. Please try again in 768ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 21e02e27-1267-47ec-b863-cdac7927f78e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9977, Requested 461. Please try again in 2.628s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9977, Requested 461. Please try again in 2.628s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 95418e1e-637c-4470-9f09-eedced3612f9: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9902, Requested 607. Please try again in 3.054s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9902, Requested 607. Please try again in 3.054s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chain_2_langsmith_eval = evaluate(\n",
    "    predict_chain_2,\n",
    "    data=data,\n",
    "    evaluators=evaluators,\n",
    "    experiment_prefix=experiment_prefix + \" on chain 2\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.integrations.langchain import EvaluatorChain as RagasEvaluatorChain\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_utilization\n",
    ")\n",
    "\n",
    "# create evaluation chains\n",
    "faithfulness_chain = RagasEvaluatorChain(metric=faithfulness)\n",
    "answer_rel_chain = RagasEvaluatorChain(metric=answer_relevancy)\n",
    "context_util_chain = RagasEvaluatorChain(metric=context_utilization)\n",
    "\n",
    "ragas_evaluators = [\n",
    "    faithfulness_chain,\n",
    "    answer_rel_chain,\n",
    "    context_util_chain\n",
    "]\n",
    "\n",
    "dataset_2 = \"RAGAS Testset QA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_OG_chain_with_context(input: dict):\n",
    "    response = Original_PerunaBot_eval_chain.invoke({\"question\": input[\"question\"]})\n",
    "    return {\"answer\": response[\"output\"], \"contexts\": response[\"context\"]}\n",
    "\n",
    "def predict_chain_0_with_context(input: dict):\n",
    "    response = base_retriever_eval_chain_0.invoke({\"question\": input[\"question\"]})\n",
    "    return {\"answer\": response[\"output\"], \"contexts\": response[\"context\"]}\n",
    "\n",
    "def predict_chain_1_with_context(input: dict):\n",
    "    response = parent_retriever_eval_chain_1.invoke({\"question\": input[\"question\"]})\n",
    "    return {\"answer\": response[\"output\"], \"contexts\": response[\"context\"]}\n",
    "\n",
    "def predict_chain_2_with_context(input: dict):\n",
    "    response = ensemble_retriever_eval_chain_2.invoke({\"question\": input[\"question\"]})\n",
    "    return {\"answer\": response[\"output\"], \"contexts\": response[\"context\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the target task\n",
    "OG_PerunaBot_ragas_langsmith_eval = evaluate(\n",
    "  predict_OG_chain_with_context,\n",
    "  data=dataset_2,\n",
    "  evaluators=ragas_evaluators,\n",
    "  experiment_prefix=\"OG PerunaBot chain\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'chain 0-8d0b3f5a' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/3643247a-7c6c-40d9-927e-ae50f5055df5/compare?selectedSessions=b7c5970b-a793-4d6a-968f-44537eba5bd2\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6388e5eaf27643be9d2d125decee8137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 30000, Used 28136, Requested 2975. Please try again in 2.222s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000022801C20DD0>, max_retries=1, _reproducibility=1)) on run 9b39066d-ec9e-4029-8fc0-d37b46db6ccf: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000002280682BD50>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 9b39066d-ec9e-4029-8fc0-d37b46db6ccf: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=ContextUtilization(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='context_utilization', evaluation_mode=<EvaluationMode.qac: 1>, context_precision_prompt=Prompt(name='context_precision', instruction='Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"description\": \"Answer for the verification task wether the context was useful.\", \"type\": \"object\", \"properties\": {\"reason\": {\"title\": \"Reason\", \"description\": \"Reason for verification\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"Binary (0/1) verdict of verification\", \"type\": \"integer\"}}, \"required\": [\"reason\", \"verdict\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'What can you tell me about albert Albert Einstein?', 'context': 'Albert Einstein (14 March 1879  18 April 1955) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His massenergy equivalence formula E = mc2, which arises from relativity theory, has been called \"the world\\'s most famous equation\". He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\", a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made Einstein synonymous with genius.', 'answer': 'Albert Einstein born in 14 March 1879 was German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. He received the 1921 Nobel Prize in Physics for his services to theoretical physics. He published 4 papers in 1905. Einstein moved to Switzerland in 1895', 'verification': {'reason': \"The provided context was indeed useful in arriving at the given answer. The context includes key information about Albert Einstein's life and contributions, which are reflected in the answer.\", 'verdict': 1}}, {'question': 'who won 2020 icc world cup?', 'context': \"The 2022 ICC Men's T20 World Cup, held from October 16 to November 13, 2022, in Australia, was the eighth edition of the tournament. Originally scheduled for 2020, it was postponed due to the COVID-19 pandemic. England emerged victorious, defeating Pakistan by five wickets in the final to clinch their second ICC Men's T20 World Cup title.\", 'answer': 'England', 'verification': {'reason': 'the context was useful in clarifying the situation regarding the 2020 ICC World Cup and indicating that England was the winner of the tournament that was intended to be held in 2020 but actually took place in 2022.', 'verdict': 1}}, {'question': 'What is the tallest mountain in the world?', 'context': 'The Andes is the longest continental mountain range in the world, located in South America. It stretches across seven countries and features many of the highest peaks in the Western Hemisphere. The range is known for its diverse ecosystems, including the high-altitude Andean Plateau and the Amazon rainforest.', 'answer': 'Mount Everest.', 'verification': {'reason': \"the provided context discusses the Andes mountain range, which, while impressive, does not include Mount Everest or directly relate to the question about the world's tallest mountain.\", 'verdict': 0}}], input_keys=['question', 'context', 'answer'], output_key='verification', output_type='json', language='english'), max_retries=1, _reproducibility=1)) on run 9b39066d-ec9e-4029-8fc0-d37b46db6ccf: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000022801C20DD0>, max_retries=1, _reproducibility=1)) on run 25718ca4-3fe2-4309-a071-996a5ab553ca: AttributeError(\"partially initialized module 'anyio._backends._asyncio' has no attribute 'run_sync_in_worker_thread' (most likely due to a circular import)\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 246, in _ascore\n",
      "    statements = await self.llm.generate(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 170, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 713, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 673, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 858, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 740, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1295, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1539, in _request\n",
      "    self._platform = await asyncify(get_platform)()\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_sync.py\", line 75, in wrapper\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: partially initialized module 'anyio._backends._asyncio' has no attribute 'run_sync_in_worker_thread' (most likely due to a circular import)\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000002280682BD50>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 25718ca4-3fe2-4309-a071-996a5ab553ca: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000022801C20DD0>, max_retries=1, _reproducibility=1)) on run cd89217a-94f0-49b2-a1a4-98b06f685880: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000002280682BD50>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run cd89217a-94f0-49b2-a1a4-98b06f685880: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000022801C20DD0>, max_retries=1, _reproducibility=1)) on run 8d0aa32f-73da-4118-af4b-900a6d46ae44: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000002280682BD50>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 8d0aa32f-73da-4118-af4b-900a6d46ae44: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000022801C20DD0>, max_retries=1, _reproducibility=1)) on run 68ea9cfc-0ba2-4bc2-8bbb-74efdcfeabd6: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000002280682BD50>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 68ea9cfc-0ba2-4bc2-8bbb-74efdcfeabd6: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000022801C20DD0>, max_retries=1, _reproducibility=1)) on run 1607337f-a0a7-489f-803f-4018da756427: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000002280682BD50>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 1607337f-a0a7-489f-803f-4018da756427: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000022801C20DD0>, max_retries=1, _reproducibility=1)) on run 31d61ac8-c66c-44f3-8266-8cc57d5f8731: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000002280682BD50>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 31d61ac8-c66c-44f3-8266-8cc57d5f8731: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000022801C20DD0>, max_retries=1, _reproducibility=1)) on run 10b4387b-660c-4cc9-9b3d-8aa7a789b7c0: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000002280682BD50>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 10b4387b-660c-4cc9-9b3d-8aa7a789b7c0: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000022801C20DD0>, max_retries=1, _reproducibility=1)) on run 27126f18-2482-4fd6-861f-5e6c14af48f7: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000002280682BD50>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 27126f18-2482-4fd6-861f-5e6c14af48f7: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000022801C20DD0>, max_retries=1, _reproducibility=1)) on run a804c063-98ae-4317-8568-f299315672fa: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000022801C20DD0>, max_retries=1, _reproducibility=1)) on run 0e76f3ef-2889-417a-9c7b-50a1a76217c9: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000002280682BD50>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run a804c063-98ae-4317-8568-f299315672fa: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000002280682BD50>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 0e76f3ef-2889-417a-9c7b-50a1a76217c9: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000022801C20DD0>, max_retries=1, _reproducibility=1)) on run 6c6bfb20-4849-46cd-a929-c4d1d09306ab: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000002280682BD50>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 6c6bfb20-4849-46cd-a929-c4d1d09306ab: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000022801C20DD0>, max_retries=1, _reproducibility=1)) on run eeefa66e-00fb-46fd-a5f5-832225bf30bc: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000002280682BD50>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run eeefa66e-00fb-46fd-a5f5-832225bf30bc: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=ContextUtilization(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='context_utilization', evaluation_mode=<EvaluationMode.qac: 1>, context_precision_prompt=Prompt(name='context_precision', instruction='Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"description\": \"Answer for the verification task wether the context was useful.\", \"type\": \"object\", \"properties\": {\"reason\": {\"title\": \"Reason\", \"description\": \"Reason for verification\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"Binary (0/1) verdict of verification\", \"type\": \"integer\"}}, \"required\": [\"reason\", \"verdict\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'What can you tell me about albert Albert Einstein?', 'context': 'Albert Einstein (14 March 1879  18 April 1955) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His massenergy equivalence formula E = mc2, which arises from relativity theory, has been called \"the world\\'s most famous equation\". He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\", a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made Einstein synonymous with genius.', 'answer': 'Albert Einstein born in 14 March 1879 was German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. He received the 1921 Nobel Prize in Physics for his services to theoretical physics. He published 4 papers in 1905. Einstein moved to Switzerland in 1895', 'verification': {'reason': \"The provided context was indeed useful in arriving at the given answer. The context includes key information about Albert Einstein's life and contributions, which are reflected in the answer.\", 'verdict': 1}}, {'question': 'who won 2020 icc world cup?', 'context': \"The 2022 ICC Men's T20 World Cup, held from October 16 to November 13, 2022, in Australia, was the eighth edition of the tournament. Originally scheduled for 2020, it was postponed due to the COVID-19 pandemic. England emerged victorious, defeating Pakistan by five wickets in the final to clinch their second ICC Men's T20 World Cup title.\", 'answer': 'England', 'verification': {'reason': 'the context was useful in clarifying the situation regarding the 2020 ICC World Cup and indicating that England was the winner of the tournament that was intended to be held in 2020 but actually took place in 2022.', 'verdict': 1}}, {'question': 'What is the tallest mountain in the world?', 'context': 'The Andes is the longest continental mountain range in the world, located in South America. It stretches across seven countries and features many of the highest peaks in the Western Hemisphere. The range is known for its diverse ecosystems, including the high-altitude Andean Plateau and the Amazon rainforest.', 'answer': 'Mount Everest.', 'verification': {'reason': \"the provided context discusses the Andes mountain range, which, while impressive, does not include Mount Everest or directly relate to the question about the world's tallest mountain.\", 'verdict': 0}}], input_keys=['question', 'context', 'answer'], output_key='verification', output_type='json', language='english'), max_retries=1, _reproducibility=1)) on run 27126f18-2482-4fd6-861f-5e6c14af48f7: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1558, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1661, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1689, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1726, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1763, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 373, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 216, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 196, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 101, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 143, in handle_async_request\n",
      "    raise exc\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 113, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 186, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 224, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 196, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 138, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1203, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x0000022806EB27D0 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 160, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 170, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 713, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 673, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 858, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 740, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1295, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1582, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1651, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1582, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1651, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1592, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator EvaluatorChain(metric=ContextUtilization(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='context_utilization', evaluation_mode=<EvaluationMode.qac: 1>, context_precision_prompt=Prompt(name='context_precision', instruction='Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"description\": \"Answer for the verification task wether the context was useful.\", \"type\": \"object\", \"properties\": {\"reason\": {\"title\": \"Reason\", \"description\": \"Reason for verification\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"Binary (0/1) verdict of verification\", \"type\": \"integer\"}}, \"required\": [\"reason\", \"verdict\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'What can you tell me about albert Albert Einstein?', 'context': 'Albert Einstein (14 March 1879  18 April 1955) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His massenergy equivalence formula E = mc2, which arises from relativity theory, has been called \"the world\\'s most famous equation\". He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\", a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made Einstein synonymous with genius.', 'answer': 'Albert Einstein born in 14 March 1879 was German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. He received the 1921 Nobel Prize in Physics for his services to theoretical physics. He published 4 papers in 1905. Einstein moved to Switzerland in 1895', 'verification': {'reason': \"The provided context was indeed useful in arriving at the given answer. The context includes key information about Albert Einstein's life and contributions, which are reflected in the answer.\", 'verdict': 1}}, {'question': 'who won 2020 icc world cup?', 'context': \"The 2022 ICC Men's T20 World Cup, held from October 16 to November 13, 2022, in Australia, was the eighth edition of the tournament. Originally scheduled for 2020, it was postponed due to the COVID-19 pandemic. England emerged victorious, defeating Pakistan by five wickets in the final to clinch their second ICC Men's T20 World Cup title.\", 'answer': 'England', 'verification': {'reason': 'the context was useful in clarifying the situation regarding the 2020 ICC World Cup and indicating that England was the winner of the tournament that was intended to be held in 2020 but actually took place in 2022.', 'verdict': 1}}, {'question': 'What is the tallest mountain in the world?', 'context': 'The Andes is the longest continental mountain range in the world, located in South America. It stretches across seven countries and features many of the highest peaks in the Western Hemisphere. The range is known for its diverse ecosystems, including the high-altitude Andean Plateau and the Amazon rainforest.', 'answer': 'Mount Everest.', 'verification': {'reason': \"the provided context discusses the Andes mountain range, which, while impressive, does not include Mount Everest or directly relate to the question about the world's tallest mountain.\", 'verdict': 0}}], input_keys=['question', 'context', 'answer'], output_key='verification', output_type='json', language='english'), max_retries=1, _reproducibility=1)) on run a804c063-98ae-4317-8568-f299315672fa: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1558, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1661, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1689, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1726, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1763, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 373, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 216, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 196, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 101, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 143, in handle_async_request\n",
      "    raise exc\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 113, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 186, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 224, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 196, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 138, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1203, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x0000022806C65B10 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 160, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 170, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 713, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 673, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 858, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 740, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1295, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1582, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1651, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1582, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1651, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1592, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000022801C20DD0>, max_retries=1, _reproducibility=1)) on run 9a82463a-4e3c-4010-8ec1-ce1bc063b861: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000002280682BD50>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 9a82463a-4e3c-4010-8ec1-ce1bc063b861: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000022801C20DD0>, max_retries=1, _reproducibility=1)) on run 16fdfc17-1359-4bfd-b358-4dda292008f0: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000002280682BD50>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 16fdfc17-1359-4bfd-b358-4dda292008f0: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000022801C20DD0>, max_retries=1, _reproducibility=1)) on run ecdec3e2-4a66-4463-8d6f-35a9cc3d24e0: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000002280682BD50>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run ecdec3e2-4a66-4463-8d6f-35a9cc3d24e0: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chain_0_ragas_langsmith_eval = evaluate(\n",
    "    predict_chain_0_with_context,\n",
    "    data=dataset_2,\n",
    "    evaluators=ragas_evaluators,\n",
    "    experiment_prefix=\"chain 0\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'chain 1-248e040c' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/3643247a-7c6c-40d9-927e-ae50f5055df5/compare?selectedSessions=d43cb0fe-b6b9-4599-9f7b-d644e19674b1\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8612a5d7247b45238c5f1cff58348521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 30000, Used 27254, Requested 3209. Please try again in 926ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 30000, Used 29767, Requested 3257. Please try again in 6.048s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 30000, Used 27944, Requested 3315. Please try again in 2.518s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000020376F94B10>, max_retries=1, _reproducibility=1)) on run 05a3a02d-c9b9-46d0-90c5-be69bfe5967e: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000020376F94B10>, max_retries=1, _reproducibility=1)) on run ef80e375-7bb9-4379-882c-1cb0183b0be4: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x0000020377F22F10>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 05a3a02d-c9b9-46d0-90c5-be69bfe5967e: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x0000020377F22F10>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run ef80e375-7bb9-4379-882c-1cb0183b0be4: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=ContextUtilization(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='context_utilization', evaluation_mode=<EvaluationMode.qac: 1>, context_precision_prompt=Prompt(name='context_precision', instruction='Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"description\": \"Answer for the verification task wether the context was useful.\", \"type\": \"object\", \"properties\": {\"reason\": {\"title\": \"Reason\", \"description\": \"Reason for verification\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"Binary (0/1) verdict of verification\", \"type\": \"integer\"}}, \"required\": [\"reason\", \"verdict\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'What can you tell me about albert Albert Einstein?', 'context': 'Albert Einstein (14 March 1879  18 April 1955) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His massenergy equivalence formula E = mc2, which arises from relativity theory, has been called \"the world\\'s most famous equation\". He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\", a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made Einstein synonymous with genius.', 'answer': 'Albert Einstein born in 14 March 1879 was German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. He received the 1921 Nobel Prize in Physics for his services to theoretical physics. He published 4 papers in 1905. Einstein moved to Switzerland in 1895', 'verification': {'reason': \"The provided context was indeed useful in arriving at the given answer. The context includes key information about Albert Einstein's life and contributions, which are reflected in the answer.\", 'verdict': 1}}, {'question': 'who won 2020 icc world cup?', 'context': \"The 2022 ICC Men's T20 World Cup, held from October 16 to November 13, 2022, in Australia, was the eighth edition of the tournament. Originally scheduled for 2020, it was postponed due to the COVID-19 pandemic. England emerged victorious, defeating Pakistan by five wickets in the final to clinch their second ICC Men's T20 World Cup title.\", 'answer': 'England', 'verification': {'reason': 'the context was useful in clarifying the situation regarding the 2020 ICC World Cup and indicating that England was the winner of the tournament that was intended to be held in 2020 but actually took place in 2022.', 'verdict': 1}}, {'question': 'What is the tallest mountain in the world?', 'context': 'The Andes is the longest continental mountain range in the world, located in South America. It stretches across seven countries and features many of the highest peaks in the Western Hemisphere. The range is known for its diverse ecosystems, including the high-altitude Andean Plateau and the Amazon rainforest.', 'answer': 'Mount Everest.', 'verification': {'reason': \"the provided context discusses the Andes mountain range, which, while impressive, does not include Mount Everest or directly relate to the question about the world's tallest mountain.\", 'verdict': 0}}], input_keys=['question', 'context', 'answer'], output_key='verification', output_type='json', language='english'), max_retries=1, _reproducibility=1)) on run 05a3a02d-c9b9-46d0-90c5-be69bfe5967e: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=ContextUtilization(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='context_utilization', evaluation_mode=<EvaluationMode.qac: 1>, context_precision_prompt=Prompt(name='context_precision', instruction='Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"description\": \"Answer for the verification task wether the context was useful.\", \"type\": \"object\", \"properties\": {\"reason\": {\"title\": \"Reason\", \"description\": \"Reason for verification\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"Binary (0/1) verdict of verification\", \"type\": \"integer\"}}, \"required\": [\"reason\", \"verdict\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'What can you tell me about albert Albert Einstein?', 'context': 'Albert Einstein (14 March 1879  18 April 1955) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His massenergy equivalence formula E = mc2, which arises from relativity theory, has been called \"the world\\'s most famous equation\". He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\", a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made Einstein synonymous with genius.', 'answer': 'Albert Einstein born in 14 March 1879 was German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. He received the 1921 Nobel Prize in Physics for his services to theoretical physics. He published 4 papers in 1905. Einstein moved to Switzerland in 1895', 'verification': {'reason': \"The provided context was indeed useful in arriving at the given answer. The context includes key information about Albert Einstein's life and contributions, which are reflected in the answer.\", 'verdict': 1}}, {'question': 'who won 2020 icc world cup?', 'context': \"The 2022 ICC Men's T20 World Cup, held from October 16 to November 13, 2022, in Australia, was the eighth edition of the tournament. Originally scheduled for 2020, it was postponed due to the COVID-19 pandemic. England emerged victorious, defeating Pakistan by five wickets in the final to clinch their second ICC Men's T20 World Cup title.\", 'answer': 'England', 'verification': {'reason': 'the context was useful in clarifying the situation regarding the 2020 ICC World Cup and indicating that England was the winner of the tournament that was intended to be held in 2020 but actually took place in 2022.', 'verdict': 1}}, {'question': 'What is the tallest mountain in the world?', 'context': 'The Andes is the longest continental mountain range in the world, located in South America. It stretches across seven countries and features many of the highest peaks in the Western Hemisphere. The range is known for its diverse ecosystems, including the high-altitude Andean Plateau and the Amazon rainforest.', 'answer': 'Mount Everest.', 'verification': {'reason': \"the provided context discusses the Andes mountain range, which, while impressive, does not include Mount Everest or directly relate to the question about the world's tallest mountain.\", 'verdict': 0}}], input_keys=['question', 'context', 'answer'], output_key='verification', output_type='json', language='english'), max_retries=1, _reproducibility=1)) on run ef80e375-7bb9-4379-882c-1cb0183b0be4: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000020376F94B10>, max_retries=1, _reproducibility=1)) on run c945558e-5a5a-4430-87e1-72b176d4c964: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x0000020377F22F10>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run c945558e-5a5a-4430-87e1-72b176d4c964: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=ContextUtilization(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='context_utilization', evaluation_mode=<EvaluationMode.qac: 1>, context_precision_prompt=Prompt(name='context_precision', instruction='Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"description\": \"Answer for the verification task wether the context was useful.\", \"type\": \"object\", \"properties\": {\"reason\": {\"title\": \"Reason\", \"description\": \"Reason for verification\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"Binary (0/1) verdict of verification\", \"type\": \"integer\"}}, \"required\": [\"reason\", \"verdict\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'What can you tell me about albert Albert Einstein?', 'context': 'Albert Einstein (14 March 1879  18 April 1955) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His massenergy equivalence formula E = mc2, which arises from relativity theory, has been called \"the world\\'s most famous equation\". He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\", a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made Einstein synonymous with genius.', 'answer': 'Albert Einstein born in 14 March 1879 was German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. He received the 1921 Nobel Prize in Physics for his services to theoretical physics. He published 4 papers in 1905. Einstein moved to Switzerland in 1895', 'verification': {'reason': \"The provided context was indeed useful in arriving at the given answer. The context includes key information about Albert Einstein's life and contributions, which are reflected in the answer.\", 'verdict': 1}}, {'question': 'who won 2020 icc world cup?', 'context': \"The 2022 ICC Men's T20 World Cup, held from October 16 to November 13, 2022, in Australia, was the eighth edition of the tournament. Originally scheduled for 2020, it was postponed due to the COVID-19 pandemic. England emerged victorious, defeating Pakistan by five wickets in the final to clinch their second ICC Men's T20 World Cup title.\", 'answer': 'England', 'verification': {'reason': 'the context was useful in clarifying the situation regarding the 2020 ICC World Cup and indicating that England was the winner of the tournament that was intended to be held in 2020 but actually took place in 2022.', 'verdict': 1}}, {'question': 'What is the tallest mountain in the world?', 'context': 'The Andes is the longest continental mountain range in the world, located in South America. It stretches across seven countries and features many of the highest peaks in the Western Hemisphere. The range is known for its diverse ecosystems, including the high-altitude Andean Plateau and the Amazon rainforest.', 'answer': 'Mount Everest.', 'verification': {'reason': \"the provided context discusses the Andes mountain range, which, while impressive, does not include Mount Everest or directly relate to the question about the world's tallest mountain.\", 'verdict': 0}}], input_keys=['question', 'context', 'answer'], output_key='verification', output_type='json', language='english'), max_retries=1, _reproducibility=1)) on run c945558e-5a5a-4430-87e1-72b176d4c964: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000020376F94B10>, max_retries=1, _reproducibility=1)) on run 907167fb-7c9d-4ecb-8d0c-2644948a3378: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x0000020377F22F10>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 907167fb-7c9d-4ecb-8d0c-2644948a3378: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000020376F94B10>, max_retries=1, _reproducibility=1)) on run 030aef9a-0e09-4c0d-823e-35905b19615f: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x0000020377F22F10>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 030aef9a-0e09-4c0d-823e-35905b19615f: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000020376F94B10>, max_retries=1, _reproducibility=1)) on run f0c554e1-6ca8-49c2-b063-33426bb9aaff: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x0000020377F22F10>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run f0c554e1-6ca8-49c2-b063-33426bb9aaff: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000020376F94B10>, max_retries=1, _reproducibility=1)) on run 26de321d-6ba2-43e1-bc33-a4bf2bbcbc8e: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x0000020377F22F10>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 26de321d-6ba2-43e1-bc33-a4bf2bbcbc8e: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000020376F94B10>, max_retries=1, _reproducibility=1)) on run 6eee1f38-d864-4b1f-a923-00b39c5303e3: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000020376F94B10>, max_retries=1, _reproducibility=1)) on run 29897ffd-8ffe-4027-8f30-b69d13de1a6f: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x0000020377F22F10>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 6eee1f38-d864-4b1f-a923-00b39c5303e3: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x0000020377F22F10>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 29897ffd-8ffe-4027-8f30-b69d13de1a6f: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000020376F94B10>, max_retries=1, _reproducibility=1)) on run e91d4c30-53fa-4896-839e-a95d55fddbb4: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x0000020377F22F10>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run e91d4c30-53fa-4896-839e-a95d55fddbb4: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000020376F94B10>, max_retries=1, _reproducibility=1)) on run b06870a1-f681-4dbd-a516-612da43fa473: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x0000020377F22F10>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run b06870a1-f681-4dbd-a516-612da43fa473: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000020376F94B10>, max_retries=1, _reproducibility=1)) on run cec146b9-57c3-486a-968f-7b10bfe81904: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x0000020377F22F10>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run cec146b9-57c3-486a-968f-7b10bfe81904: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000020376F94B10>, max_retries=1, _reproducibility=1)) on run b305b66b-1cc5-4d59-9911-31584c01d82c: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x0000020377F22F10>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run b305b66b-1cc5-4d59-9911-31584c01d82c: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000020376F94B10>, max_retries=1, _reproducibility=1)) on run ae380b5a-37f0-48f2-9b99-dc22811ae4ad: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x0000020377F22F10>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run ae380b5a-37f0-48f2-9b99-dc22811ae4ad: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000020376F94B10>, max_retries=1, _reproducibility=1)) on run 252aef18-44bd-485d-bb86-69175b86737e: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x0000020377F22F10>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 252aef18-44bd-485d-bb86-69175b86737e: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=ContextUtilization(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='context_utilization', evaluation_mode=<EvaluationMode.qac: 1>, context_precision_prompt=Prompt(name='context_precision', instruction='Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"description\": \"Answer for the verification task wether the context was useful.\", \"type\": \"object\", \"properties\": {\"reason\": {\"title\": \"Reason\", \"description\": \"Reason for verification\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"Binary (0/1) verdict of verification\", \"type\": \"integer\"}}, \"required\": [\"reason\", \"verdict\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'What can you tell me about albert Albert Einstein?', 'context': 'Albert Einstein (14 March 1879  18 April 1955) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His massenergy equivalence formula E = mc2, which arises from relativity theory, has been called \"the world\\'s most famous equation\". He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\", a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made Einstein synonymous with genius.', 'answer': 'Albert Einstein born in 14 March 1879 was German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. He received the 1921 Nobel Prize in Physics for his services to theoretical physics. He published 4 papers in 1905. Einstein moved to Switzerland in 1895', 'verification': {'reason': \"The provided context was indeed useful in arriving at the given answer. The context includes key information about Albert Einstein's life and contributions, which are reflected in the answer.\", 'verdict': 1}}, {'question': 'who won 2020 icc world cup?', 'context': \"The 2022 ICC Men's T20 World Cup, held from October 16 to November 13, 2022, in Australia, was the eighth edition of the tournament. Originally scheduled for 2020, it was postponed due to the COVID-19 pandemic. England emerged victorious, defeating Pakistan by five wickets in the final to clinch their second ICC Men's T20 World Cup title.\", 'answer': 'England', 'verification': {'reason': 'the context was useful in clarifying the situation regarding the 2020 ICC World Cup and indicating that England was the winner of the tournament that was intended to be held in 2020 but actually took place in 2022.', 'verdict': 1}}, {'question': 'What is the tallest mountain in the world?', 'context': 'The Andes is the longest continental mountain range in the world, located in South America. It stretches across seven countries and features many of the highest peaks in the Western Hemisphere. The range is known for its diverse ecosystems, including the high-altitude Andean Plateau and the Amazon rainforest.', 'answer': 'Mount Everest.', 'verification': {'reason': \"the provided context discusses the Andes mountain range, which, while impressive, does not include Mount Everest or directly relate to the question about the world's tallest mountain.\", 'verdict': 0}}], input_keys=['question', 'context', 'answer'], output_key='verification', output_type='json', language='english'), max_retries=1, _reproducibility=1)) on run cec146b9-57c3-486a-968f-7b10bfe81904: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1558, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1661, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1689, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1726, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1763, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 373, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 216, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 196, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 101, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 143, in handle_async_request\n",
      "    raise exc\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 113, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 186, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 224, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 196, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 138, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1203, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x00000203783D3110 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 160, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 170, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 713, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 673, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 858, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 740, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1295, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1582, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1651, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1582, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1651, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1592, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator EvaluatorChain(metric=ContextUtilization(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='context_utilization', evaluation_mode=<EvaluationMode.qac: 1>, context_precision_prompt=Prompt(name='context_precision', instruction='Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"description\": \"Answer for the verification task wether the context was useful.\", \"type\": \"object\", \"properties\": {\"reason\": {\"title\": \"Reason\", \"description\": \"Reason for verification\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"Binary (0/1) verdict of verification\", \"type\": \"integer\"}}, \"required\": [\"reason\", \"verdict\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'What can you tell me about albert Albert Einstein?', 'context': 'Albert Einstein (14 March 1879  18 April 1955) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His massenergy equivalence formula E = mc2, which arises from relativity theory, has been called \"the world\\'s most famous equation\". He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\", a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made Einstein synonymous with genius.', 'answer': 'Albert Einstein born in 14 March 1879 was German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. He received the 1921 Nobel Prize in Physics for his services to theoretical physics. He published 4 papers in 1905. Einstein moved to Switzerland in 1895', 'verification': {'reason': \"The provided context was indeed useful in arriving at the given answer. The context includes key information about Albert Einstein's life and contributions, which are reflected in the answer.\", 'verdict': 1}}, {'question': 'who won 2020 icc world cup?', 'context': \"The 2022 ICC Men's T20 World Cup, held from October 16 to November 13, 2022, in Australia, was the eighth edition of the tournament. Originally scheduled for 2020, it was postponed due to the COVID-19 pandemic. England emerged victorious, defeating Pakistan by five wickets in the final to clinch their second ICC Men's T20 World Cup title.\", 'answer': 'England', 'verification': {'reason': 'the context was useful in clarifying the situation regarding the 2020 ICC World Cup and indicating that England was the winner of the tournament that was intended to be held in 2020 but actually took place in 2022.', 'verdict': 1}}, {'question': 'What is the tallest mountain in the world?', 'context': 'The Andes is the longest continental mountain range in the world, located in South America. It stretches across seven countries and features many of the highest peaks in the Western Hemisphere. The range is known for its diverse ecosystems, including the high-altitude Andean Plateau and the Amazon rainforest.', 'answer': 'Mount Everest.', 'verification': {'reason': \"the provided context discusses the Andes mountain range, which, while impressive, does not include Mount Everest or directly relate to the question about the world's tallest mountain.\", 'verdict': 0}}], input_keys=['question', 'context', 'answer'], output_key='verification', output_type='json', language='english'), max_retries=1, _reproducibility=1)) on run b06870a1-f681-4dbd-a516-612da43fa473: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1558, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1661, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1689, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1726, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1763, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 373, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 216, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 196, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 101, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 143, in handle_async_request\n",
      "    raise exc\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 113, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 186, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 224, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 196, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 138, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1203, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x00000203786A5390 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 160, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 170, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 713, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 673, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 858, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 740, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1295, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1582, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1651, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1582, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1651, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1592, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x0000020376F94B10>, max_retries=1, _reproducibility=1)) on run ecf37d1b-0289-4368-b088-daf15a37bddd: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x0000020377F22F10>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run ecf37d1b-0289-4368-b088-daf15a37bddd: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chain_1_ragas_langsmith_eval = evaluate(\n",
    "    predict_chain_1_with_context,\n",
    "    data=dataset_2,\n",
    "    evaluators=ragas_evaluators,\n",
    "    experiment_prefix=\"chain 1\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'chain 2-c52d3c61' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/3643247a-7c6c-40d9-927e-ae50f5055df5/compare?selectedSessions=fbfa5c22-9704-4cbe-b672-dc68e93f4551\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5265832b12534b99b05ae8fa843c1f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 30000, Used 29163, Requested 3750. Please try again in 5.826s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 30000, Used 29051, Requested 3899. Please try again in 5.9s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 30000, Used 27343, Requested 2703. Please try again in 92ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 30000, Used 27568, Requested 4922. Please try again in 4.98s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x000001A09181CA50>, max_retries=1, _reproducibility=1)) on run b703bf1e-e3a8-4b6c-91fc-9ef121d3d433: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x000001A09181CA50>, max_retries=1, _reproducibility=1)) on run d8c213dd-757b-4861-9140-5436c989da52: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000001A08FAA0850>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run b703bf1e-e3a8-4b6c-91fc-9ef121d3d433: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000001A08FAA0850>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run d8c213dd-757b-4861-9140-5436c989da52: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=ContextUtilization(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='context_utilization', evaluation_mode=<EvaluationMode.qac: 1>, context_precision_prompt=Prompt(name='context_precision', instruction='Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"description\": \"Answer for the verification task wether the context was useful.\", \"type\": \"object\", \"properties\": {\"reason\": {\"title\": \"Reason\", \"description\": \"Reason for verification\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"Binary (0/1) verdict of verification\", \"type\": \"integer\"}}, \"required\": [\"reason\", \"verdict\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'What can you tell me about albert Albert Einstein?', 'context': 'Albert Einstein (14 March 1879  18 April 1955) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His massenergy equivalence formula E = mc2, which arises from relativity theory, has been called \"the world\\'s most famous equation\". He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\", a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made Einstein synonymous with genius.', 'answer': 'Albert Einstein born in 14 March 1879 was German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. He received the 1921 Nobel Prize in Physics for his services to theoretical physics. He published 4 papers in 1905. Einstein moved to Switzerland in 1895', 'verification': {'reason': \"The provided context was indeed useful in arriving at the given answer. The context includes key information about Albert Einstein's life and contributions, which are reflected in the answer.\", 'verdict': 1}}, {'question': 'who won 2020 icc world cup?', 'context': \"The 2022 ICC Men's T20 World Cup, held from October 16 to November 13, 2022, in Australia, was the eighth edition of the tournament. Originally scheduled for 2020, it was postponed due to the COVID-19 pandemic. England emerged victorious, defeating Pakistan by five wickets in the final to clinch their second ICC Men's T20 World Cup title.\", 'answer': 'England', 'verification': {'reason': 'the context was useful in clarifying the situation regarding the 2020 ICC World Cup and indicating that England was the winner of the tournament that was intended to be held in 2020 but actually took place in 2022.', 'verdict': 1}}, {'question': 'What is the tallest mountain in the world?', 'context': 'The Andes is the longest continental mountain range in the world, located in South America. It stretches across seven countries and features many of the highest peaks in the Western Hemisphere. The range is known for its diverse ecosystems, including the high-altitude Andean Plateau and the Amazon rainforest.', 'answer': 'Mount Everest.', 'verification': {'reason': \"the provided context discusses the Andes mountain range, which, while impressive, does not include Mount Everest or directly relate to the question about the world's tallest mountain.\", 'verdict': 0}}], input_keys=['question', 'context', 'answer'], output_key='verification', output_type='json', language='english'), max_retries=1, _reproducibility=1)) on run b703bf1e-e3a8-4b6c-91fc-9ef121d3d433: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=ContextUtilization(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='context_utilization', evaluation_mode=<EvaluationMode.qac: 1>, context_precision_prompt=Prompt(name='context_precision', instruction='Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"description\": \"Answer for the verification task wether the context was useful.\", \"type\": \"object\", \"properties\": {\"reason\": {\"title\": \"Reason\", \"description\": \"Reason for verification\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"Binary (0/1) verdict of verification\", \"type\": \"integer\"}}, \"required\": [\"reason\", \"verdict\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'What can you tell me about albert Albert Einstein?', 'context': 'Albert Einstein (14 March 1879  18 April 1955) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His massenergy equivalence formula E = mc2, which arises from relativity theory, has been called \"the world\\'s most famous equation\". He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\", a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made Einstein synonymous with genius.', 'answer': 'Albert Einstein born in 14 March 1879 was German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. He received the 1921 Nobel Prize in Physics for his services to theoretical physics. He published 4 papers in 1905. Einstein moved to Switzerland in 1895', 'verification': {'reason': \"The provided context was indeed useful in arriving at the given answer. The context includes key information about Albert Einstein's life and contributions, which are reflected in the answer.\", 'verdict': 1}}, {'question': 'who won 2020 icc world cup?', 'context': \"The 2022 ICC Men's T20 World Cup, held from October 16 to November 13, 2022, in Australia, was the eighth edition of the tournament. Originally scheduled for 2020, it was postponed due to the COVID-19 pandemic. England emerged victorious, defeating Pakistan by five wickets in the final to clinch their second ICC Men's T20 World Cup title.\", 'answer': 'England', 'verification': {'reason': 'the context was useful in clarifying the situation regarding the 2020 ICC World Cup and indicating that England was the winner of the tournament that was intended to be held in 2020 but actually took place in 2022.', 'verdict': 1}}, {'question': 'What is the tallest mountain in the world?', 'context': 'The Andes is the longest continental mountain range in the world, located in South America. It stretches across seven countries and features many of the highest peaks in the Western Hemisphere. The range is known for its diverse ecosystems, including the high-altitude Andean Plateau and the Amazon rainforest.', 'answer': 'Mount Everest.', 'verification': {'reason': \"the provided context discusses the Andes mountain range, which, while impressive, does not include Mount Everest or directly relate to the question about the world's tallest mountain.\", 'verdict': 0}}], input_keys=['question', 'context', 'answer'], output_key='verification', output_type='json', language='english'), max_retries=1, _reproducibility=1)) on run d8c213dd-757b-4861-9140-5436c989da52: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x000001A09181CA50>, max_retries=1, _reproducibility=1)) on run 4be74be8-654f-467c-af4d-514aec9b533a: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000001A08FAA0850>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 4be74be8-654f-467c-af4d-514aec9b533a: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=ContextUtilization(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='context_utilization', evaluation_mode=<EvaluationMode.qac: 1>, context_precision_prompt=Prompt(name='context_precision', instruction='Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"description\": \"Answer for the verification task wether the context was useful.\", \"type\": \"object\", \"properties\": {\"reason\": {\"title\": \"Reason\", \"description\": \"Reason for verification\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"Binary (0/1) verdict of verification\", \"type\": \"integer\"}}, \"required\": [\"reason\", \"verdict\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'What can you tell me about albert Albert Einstein?', 'context': 'Albert Einstein (14 March 1879  18 April 1955) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His massenergy equivalence formula E = mc2, which arises from relativity theory, has been called \"the world\\'s most famous equation\". He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\", a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made Einstein synonymous with genius.', 'answer': 'Albert Einstein born in 14 March 1879 was German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. He received the 1921 Nobel Prize in Physics for his services to theoretical physics. He published 4 papers in 1905. Einstein moved to Switzerland in 1895', 'verification': {'reason': \"The provided context was indeed useful in arriving at the given answer. The context includes key information about Albert Einstein's life and contributions, which are reflected in the answer.\", 'verdict': 1}}, {'question': 'who won 2020 icc world cup?', 'context': \"The 2022 ICC Men's T20 World Cup, held from October 16 to November 13, 2022, in Australia, was the eighth edition of the tournament. Originally scheduled for 2020, it was postponed due to the COVID-19 pandemic. England emerged victorious, defeating Pakistan by five wickets in the final to clinch their second ICC Men's T20 World Cup title.\", 'answer': 'England', 'verification': {'reason': 'the context was useful in clarifying the situation regarding the 2020 ICC World Cup and indicating that England was the winner of the tournament that was intended to be held in 2020 but actually took place in 2022.', 'verdict': 1}}, {'question': 'What is the tallest mountain in the world?', 'context': 'The Andes is the longest continental mountain range in the world, located in South America. It stretches across seven countries and features many of the highest peaks in the Western Hemisphere. The range is known for its diverse ecosystems, including the high-altitude Andean Plateau and the Amazon rainforest.', 'answer': 'Mount Everest.', 'verification': {'reason': \"the provided context discusses the Andes mountain range, which, while impressive, does not include Mount Everest or directly relate to the question about the world's tallest mountain.\", 'verdict': 0}}], input_keys=['question', 'context', 'answer'], output_key='verification', output_type='json', language='english'), max_retries=1, _reproducibility=1)) on run 4be74be8-654f-467c-af4d-514aec9b533a: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x000001A09181CA50>, max_retries=1, _reproducibility=1)) on run 74d81e2d-76be-4520-b5f2-57e9ed1fdafd: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000001A08FAA0850>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 74d81e2d-76be-4520-b5f2-57e9ed1fdafd: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=ContextUtilization(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='context_utilization', evaluation_mode=<EvaluationMode.qac: 1>, context_precision_prompt=Prompt(name='context_precision', instruction='Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"description\": \"Answer for the verification task wether the context was useful.\", \"type\": \"object\", \"properties\": {\"reason\": {\"title\": \"Reason\", \"description\": \"Reason for verification\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"Binary (0/1) verdict of verification\", \"type\": \"integer\"}}, \"required\": [\"reason\", \"verdict\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'What can you tell me about albert Albert Einstein?', 'context': 'Albert Einstein (14 March 1879  18 April 1955) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His massenergy equivalence formula E = mc2, which arises from relativity theory, has been called \"the world\\'s most famous equation\". He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\", a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made Einstein synonymous with genius.', 'answer': 'Albert Einstein born in 14 March 1879 was German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. He received the 1921 Nobel Prize in Physics for his services to theoretical physics. He published 4 papers in 1905. Einstein moved to Switzerland in 1895', 'verification': {'reason': \"The provided context was indeed useful in arriving at the given answer. The context includes key information about Albert Einstein's life and contributions, which are reflected in the answer.\", 'verdict': 1}}, {'question': 'who won 2020 icc world cup?', 'context': \"The 2022 ICC Men's T20 World Cup, held from October 16 to November 13, 2022, in Australia, was the eighth edition of the tournament. Originally scheduled for 2020, it was postponed due to the COVID-19 pandemic. England emerged victorious, defeating Pakistan by five wickets in the final to clinch their second ICC Men's T20 World Cup title.\", 'answer': 'England', 'verification': {'reason': 'the context was useful in clarifying the situation regarding the 2020 ICC World Cup and indicating that England was the winner of the tournament that was intended to be held in 2020 but actually took place in 2022.', 'verdict': 1}}, {'question': 'What is the tallest mountain in the world?', 'context': 'The Andes is the longest continental mountain range in the world, located in South America. It stretches across seven countries and features many of the highest peaks in the Western Hemisphere. The range is known for its diverse ecosystems, including the high-altitude Andean Plateau and the Amazon rainforest.', 'answer': 'Mount Everest.', 'verification': {'reason': \"the provided context discusses the Andes mountain range, which, while impressive, does not include Mount Everest or directly relate to the question about the world's tallest mountain.\", 'verdict': 0}}], input_keys=['question', 'context', 'answer'], output_key='verification', output_type='json', language='english'), max_retries=1, _reproducibility=1)) on run 74d81e2d-76be-4520-b5f2-57e9ed1fdafd: ValueError(\"Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 190, in evaluate_run\n",
      "    self._validate_langsmith_eval(run, example)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 179, in _validate_langsmith_eval\n",
      "    raise ValueError(\n",
      "ValueError: Expected 'answer' and 'contexts' in run.outputs.Got: ['output']\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x000001A09181CA50>, max_retries=1, _reproducibility=1)) on run c20095f3-3050-4457-9b82-9234cf25f612: AttributeError(\"partially initialized module 'anyio._backends._asyncio' has no attribute 'run_sync_in_worker_thread' (most likely due to a circular import)\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 246, in _ascore\n",
      "    statements = await self.llm.generate(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 170, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 713, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 673, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 858, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 740, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1295, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1539, in _request\n",
      "    self._platform = await asyncify(get_platform)()\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_sync.py\", line 75, in wrapper\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: partially initialized module 'anyio._backends._asyncio' has no attribute 'run_sync_in_worker_thread' (most likely due to a circular import)\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x000001A09181CA50>, max_retries=1, _reproducibility=1)) on run c23255a5-b2db-4676-bdc4-20eac70dec9d: AttributeError(\"partially initialized module 'anyio._backends._asyncio' has no attribute 'run_sync_in_worker_thread' (most likely due to a circular import)\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 246, in _ascore\n",
      "    statements = await self.llm.generate(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 170, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 713, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 673, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 858, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 740, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1295, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1539, in _request\n",
      "    self._platform = await asyncify(get_platform)()\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_sync.py\", line 75, in wrapper\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: partially initialized module 'anyio._backends._asyncio' has no attribute 'run_sync_in_worker_thread' (most likely due to a circular import)\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000001A08FAA0850>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run c20095f3-3050-4457-9b82-9234cf25f612: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000001A08FAA0850>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run c23255a5-b2db-4676-bdc4-20eac70dec9d: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x000001A09181CA50>, max_retries=1, _reproducibility=1)) on run e49d8f9a-1e3d-4a41-a966-aae447d3e9e7: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x000001A09181CA50>, max_retries=1, _reproducibility=1)) on run 2712e62a-a16e-4594-9ea0-62807d6c086c: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000001A08FAA0850>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run e49d8f9a-1e3d-4a41-a966-aae447d3e9e7: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000001A08FAA0850>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 2712e62a-a16e-4594-9ea0-62807d6c086c: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x000001A09181CA50>, max_retries=1, _reproducibility=1)) on run 01098174-a1e8-418e-9cca-2a7199f00263: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000001A08FAA0850>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 01098174-a1e8-418e-9cca-2a7199f00263: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x000001A09181CA50>, max_retries=1, _reproducibility=1)) on run 4303b22e-f421-4f49-a14a-7d5428345541: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000001A08FAA0850>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 4303b22e-f421-4f49-a14a-7d5428345541: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x000001A09181CA50>, max_retries=1, _reproducibility=1)) on run 24659dd3-e92b-4bc7-bec1-2a4a59640ff1: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000001A08FAA0850>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 24659dd3-e92b-4bc7-bec1-2a4a59640ff1: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x000001A09181CA50>, max_retries=1, _reproducibility=1)) on run 942b4a68-9320-463f-8f3f-ee2f06fba4fb: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000001A08FAA0850>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 942b4a68-9320-463f-8f3f-ee2f06fba4fb: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x000001A09181CA50>, max_retries=1, _reproducibility=1)) on run 680fdd69-3032-4cef-b8fc-532df7ddc7d9: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000001A08FAA0850>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 680fdd69-3032-4cef-b8fc-532df7ddc7d9: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x000001A09181CA50>, max_retries=1, _reproducibility=1)) on run 629f348b-ef6e-425d-bda6-9cee047fb878: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000001A08FAA0850>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 629f348b-ef6e-425d-bda6-9cee047fb878: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x000001A09181CA50>, max_retries=1, _reproducibility=1)) on run 6eef6ccd-84ff-4491-876c-066c94854b6a: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000001A08FAA0850>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 6eef6ccd-84ff-4491-876c-066c94854b6a: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=Faithfulness(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='faithfulness', evaluation_mode=<EvaluationMode.qac: 1>, nli_statements_message=Prompt(name='nli_statements', instruction='Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return verdict as 1 if the statement can be directly inferred based on the context or 0 if the statement can not be directly inferred based on the context.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/StatementFaithfulnessAnswer\"}, \"definitions\": {\"StatementFaithfulnessAnswer\": {\"title\": \"StatementFaithfulnessAnswer\", \"type\": \"object\", \"properties\": {\"statement\": {\"title\": \"Statement\", \"description\": \"the original statement, word-by-word\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"the reason of the verdict\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"the verdict(0/1) of the faithfulness.\", \"type\": \"integer\"}}, \"required\": [\"statement\", \"reason\", \"verdict\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'context': 'John is a student at XYZ University. He is pursuing a degree in Computer Science. He is enrolled in several courses this semester, including Data Structures, Algorithms, and Database Management. John is a diligent student and spends a significant amount of time studying and completing assignments. He often stays late in the library to work on his projects.', 'statements': ['John is majoring in Biology.', 'John is taking a course on Artificial Intelligence.', 'John is a dedicated student.', 'John has a part-time job.'], 'answer': [{'statement': 'John is majoring in Biology.', 'reason': \"John's major is explicitly mentioned as Computer Science. There is no information suggesting he is majoring in Biology.\", 'verdict': 0}, {'statement': 'John is taking a course on Artificial Intelligence.', 'reason': 'The context mentions the courses John is currently enrolled in, and Artificial Intelligence is not mentioned. Therefore, it cannot be deduced that John is taking a course on AI.', 'verdict': 0}, {'statement': 'John is a dedicated student.', 'reason': 'The context states that he spends a significant amount of time studying and completing assignments. Additionally, it mentions that he often stays late in the library to work on his projects, which implies dedication.', 'verdict': 1}, {'statement': 'John has a part-time job.', 'reason': 'There is no information given in the context about John having a part-time job.', 'verdict': 0}]}, {'context': 'Photosynthesis is a process used by plants, algae, and certain bacteria to convert light energy into chemical energy.', 'statements': ['Albert Einstein was a genius.'], 'answer': [{'statement': 'Albert Einstein was a genius.', 'reason': 'The context and statement are unrelated', 'verdict': 0}]}], input_keys=['context', 'statements'], output_key='answer', output_type='json', language='english'), statement_prompt=Prompt(name='long_form_answer', instruction=\"Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under 'sentences' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.\", output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Statements\"}, \"definitions\": {\"Statements\": {\"title\": \"Statements\", \"type\": \"object\", \"properties\": {\"sentence_index\": {\"title\": \"Sentence Index\", \"description\": \"Index of the sentence from the statement list\", \"type\": \"integer\"}, \"simpler_statements\": {\"title\": \"Simpler Statements\", \"description\": \"the simpler statements\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentence_index\", \"simpler_statements\"]}}}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'Who was Albert Einstein and what is he best known for?', 'answer': 'He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.', 'sentences': '\\n        0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \\n        1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\\n        ', 'analysis': [{'sentence_index': 0, 'simpler_statements': ['Albert Einstein was a German-born theoretical physicist.', 'Albert Einstein is recognized as one of the greatest and most influential physicists of all time.']}, {'sentence_index': 1, 'simpler_statements': ['Albert Einstein was best known for developing the theory of relativity.', 'Albert Einstein also made important contributions to the development of the theory of quantum mechanics.']}]}], input_keys=['question', 'answer', 'sentences'], output_key='analysis', output_type='json', language='english'), sentence_segmenter=<pysbd.segmenter.Segmenter object at 0x000001A09181CA50>, max_retries=1, _reproducibility=1)) on run 79b29f65-48ea-47c2-8440-c26bfd278428: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 262, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 204, in _create_nli_prompt\n",
      "    contexts_str: str = \"\\n\".join(contexts)\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=AnswerRelevancy(embeddings=<ragas.embeddings.base.LangchainEmbeddingsWrapper object at 0x000001A08FAA0850>, llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='answer_relevancy', evaluation_mode=<EvaluationMode.qac: 1>, question_generation=Prompt(name='question_generation', instruction='Generate a question for the given answer and Identify if answer is noncommittal. Give noncommittal as 1 if the answer is noncommittal and 0 if the answer is committal. A noncommittal answer is one that is evasive, vague, or ambiguous. For example, \"I don\\'t know\" or \"I\\'m not sure\" are noncommittal answers', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"type\": \"object\", \"properties\": {\"question\": {\"title\": \"Question\", \"type\": \"string\"}, \"noncommittal\": {\"title\": \"Noncommittal\", \"type\": \"integer\"}}, \"required\": [\"question\", \"noncommittal\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'answer': 'Albert Einstein was born in Germany.', 'context': 'Albert Einstein was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time', 'output': {'question': 'Where was Albert Einstein born?', 'noncommittal': 0}}, {'answer': 'It can change its skin color based on the temperature of its environment.', 'context': 'A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.', 'output': {'question': 'What unique ability does the newly discovered species of frog have?', 'noncommittal': 0}}, {'answer': 'Everest', 'context': 'The tallest mountain on Earth, measured from sea level, is a renowned peak located in the Himalayas.', 'output': {'question': 'What is the tallest mountain on Earth?', 'noncommittal': 0}}, {'answer': \"I don't know about the  groundbreaking feature of the smartphone invented in 2023 as am unaware of information beyond 2022. \", 'context': 'In 2023, a groundbreaking invention was announced: a smartphone with a battery life of one month, revolutionizing the way people use mobile technology.', 'output': {'question': 'What was the groundbreaking feature of the smartphone invented in 2023?', 'noncommittal': 1}}], input_keys=['answer', 'context'], output_key='output', output_type='json', language='english'), strictness=3)) on run 79b29f65-48ea-47c2-8440-c26bfd278428: TypeError('sequence item 0: expected str instance, Document found')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 151, in _ascore\n",
      "    prompt = self._create_question_gen_prompt(row)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 146, in _create_question_gen_prompt\n",
      "    return self.question_generation.format(answer=ans, context=\"\\n\".join(ctx))\n",
      "                                                               ^^^^^^^^^^^^^^\n",
      "TypeError: sequence item 0: expected str instance, Document found\n",
      "Error running evaluator EvaluatorChain(metric=ContextUtilization(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='context_utilization', evaluation_mode=<EvaluationMode.qac: 1>, context_precision_prompt=Prompt(name='context_precision', instruction='Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"description\": \"Answer for the verification task wether the context was useful.\", \"type\": \"object\", \"properties\": {\"reason\": {\"title\": \"Reason\", \"description\": \"Reason for verification\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"Binary (0/1) verdict of verification\", \"type\": \"integer\"}}, \"required\": [\"reason\", \"verdict\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'What can you tell me about albert Albert Einstein?', 'context': 'Albert Einstein (14 March 1879  18 April 1955) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His massenergy equivalence formula E = mc2, which arises from relativity theory, has been called \"the world\\'s most famous equation\". He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\", a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made Einstein synonymous with genius.', 'answer': 'Albert Einstein born in 14 March 1879 was German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. He received the 1921 Nobel Prize in Physics for his services to theoretical physics. He published 4 papers in 1905. Einstein moved to Switzerland in 1895', 'verification': {'reason': \"The provided context was indeed useful in arriving at the given answer. The context includes key information about Albert Einstein's life and contributions, which are reflected in the answer.\", 'verdict': 1}}, {'question': 'who won 2020 icc world cup?', 'context': \"The 2022 ICC Men's T20 World Cup, held from October 16 to November 13, 2022, in Australia, was the eighth edition of the tournament. Originally scheduled for 2020, it was postponed due to the COVID-19 pandemic. England emerged victorious, defeating Pakistan by five wickets in the final to clinch their second ICC Men's T20 World Cup title.\", 'answer': 'England', 'verification': {'reason': 'the context was useful in clarifying the situation regarding the 2020 ICC World Cup and indicating that England was the winner of the tournament that was intended to be held in 2020 but actually took place in 2022.', 'verdict': 1}}, {'question': 'What is the tallest mountain in the world?', 'context': 'The Andes is the longest continental mountain range in the world, located in South America. It stretches across seven countries and features many of the highest peaks in the Western Hemisphere. The range is known for its diverse ecosystems, including the high-altitude Andean Plateau and the Amazon rainforest.', 'answer': 'Mount Everest.', 'verification': {'reason': \"the provided context discusses the Andes mountain range, which, while impressive, does not include Mount Everest or directly relate to the question about the world's tallest mountain.\", 'verdict': 0}}], input_keys=['question', 'context', 'answer'], output_key='verification', output_type='json', language='english'), max_retries=1, _reproducibility=1)) on run e49d8f9a-1e3d-4a41-a966-aae447d3e9e7: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1558, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1661, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1689, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1726, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1763, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 373, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 216, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 196, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 101, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 143, in handle_async_request\n",
      "    raise exc\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 113, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 186, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 224, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 196, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 138, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1203, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x000001A0901ABFD0 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 160, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 170, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 713, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 673, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 858, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 740, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1295, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1582, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1651, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1582, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1651, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1592, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error running evaluator EvaluatorChain(metric=ContextUtilization(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=10, max_wait=60, max_workers=16, thread_timeout=80.0, exception_types=<class 'openai.RateLimitError'>, log_tenacity=False)), name='context_utilization', evaluation_mode=<EvaluationMode.qac: 1>, context_precision_prompt=Prompt(name='context_precision', instruction='Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as \"1\" if useful and \"0\" if not with json output.', output_format_instruction='The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{\"description\": \"Answer for the verification task wether the context was useful.\", \"type\": \"object\", \"properties\": {\"reason\": {\"title\": \"Reason\", \"description\": \"Reason for verification\", \"type\": \"string\"}, \"verdict\": {\"title\": \"Verdict\", \"description\": \"Binary (0/1) verdict of verification\", \"type\": \"integer\"}}, \"required\": [\"reason\", \"verdict\"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).', examples=[{'question': 'What can you tell me about albert Albert Einstein?', 'context': 'Albert Einstein (14 March 1879  18 April 1955) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. Best known for developing the theory of relativity, he also made important contributions to quantum mechanics, and was thus a central figure in the revolutionary reshaping of the scientific understanding of nature that modern physics accomplished in the first decades of the twentieth century. His massenergy equivalence formula E = mc2, which arises from relativity theory, has been called \"the world\\'s most famous equation\". He received the 1921 Nobel Prize in Physics \"for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect\", a pivotal step in the development of quantum theory. His work is also known for its influence on the philosophy of science. In a 1999 poll of 130 leading physicists worldwide by the British journal Physics World, Einstein was ranked the greatest physicist of all time. His intellectual achievements and originality have made Einstein synonymous with genius.', 'answer': 'Albert Einstein born in 14 March 1879 was German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time. He received the 1921 Nobel Prize in Physics for his services to theoretical physics. He published 4 papers in 1905. Einstein moved to Switzerland in 1895', 'verification': {'reason': \"The provided context was indeed useful in arriving at the given answer. The context includes key information about Albert Einstein's life and contributions, which are reflected in the answer.\", 'verdict': 1}}, {'question': 'who won 2020 icc world cup?', 'context': \"The 2022 ICC Men's T20 World Cup, held from October 16 to November 13, 2022, in Australia, was the eighth edition of the tournament. Originally scheduled for 2020, it was postponed due to the COVID-19 pandemic. England emerged victorious, defeating Pakistan by five wickets in the final to clinch their second ICC Men's T20 World Cup title.\", 'answer': 'England', 'verification': {'reason': 'the context was useful in clarifying the situation regarding the 2020 ICC World Cup and indicating that England was the winner of the tournament that was intended to be held in 2020 but actually took place in 2022.', 'verdict': 1}}, {'question': 'What is the tallest mountain in the world?', 'context': 'The Andes is the longest continental mountain range in the world, located in South America. It stretches across seven countries and features many of the highest peaks in the Western Hemisphere. The range is known for its diverse ecosystems, including the high-altitude Andean Plateau and the Amazon rainforest.', 'answer': 'Mount Everest.', 'verification': {'reason': \"the provided context discusses the Andes mountain range, which, while impressive, does not include Mount Everest or directly relate to the question about the world's tallest mountain.\", 'verdict': 0}}], input_keys=['question', 'context', 'answer'], output_key='verification', output_type='json', language='english'), max_retries=1, _reproducibility=1)) on run 629f348b-ef6e-425d-bda6-9cee047fb878: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1558, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1661, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1689, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1726, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1763, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 373, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 216, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 196, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 101, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 143, in handle_async_request\n",
      "    raise exc\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 113, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 186, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 224, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 196, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 138, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1203, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\locks.py\", line 210, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x000001A090130290 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\integrations\\langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 160, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 170, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 713, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 673, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"C:\\Users\\yawbt\\anaconda3\\Lib\\asyncio\\tasks.py\", line 267, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 858, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 740, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1295, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1826, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1582, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1651, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1582, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1651, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1592, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chain_2_ragas_langsmith_eval = evaluate(\n",
    "    predict_chain_2_with_context,\n",
    "    data=dataset_2,\n",
    "    evaluators=ragas_evaluators,\n",
    "    experiment_prefix=\"chain 2\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "\n",
    "# Target task definition\n",
    "\n",
    "# The name or UUID of the LangSmith dataset to evaluate on.\n",
    "# Alternatively, you can pass an iterator of examples\n",
    "dataset_3 = \"SMU Schools Questions\"\n",
    "\n",
    "\n",
    "# List of evaluators to score the outputs of target task\n",
    "langsmith_evaluators = [\n",
    "  LangChainStringEvaluator(\"labeled_criteria\", config={\"criteria\": \"detail\"}),\n",
    "  LangChainStringEvaluator(\"labeled_criteria\", config={\"criteria\": \"coherence\"}),\n",
    "  LangChainStringEvaluator(\"labeled_criteria\", config={\"criteria\": \"relevance\"}),\n",
    "  LangChainStringEvaluator(\"labeled_criteria\", config={\"criteria\": \"helpfulness\"})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_OG_chain(inputs: dict):\n",
    "    response = Original_PerunaBot_eval_chain.invoke({\"question\": inputs[\"question\"]})\n",
    "    return {\"answer\" : response[\"output\"]}\n",
    "\n",
    "def predict_chain_0(inputs: dict):\n",
    "    response = base_retriever_eval_chain_0.invoke({\"question\": inputs[\"question\"]})\n",
    "    return {\"answer\" : response[\"output\"]}\n",
    "\n",
    "def predict_chain_1(inputs: dict):\n",
    "    response = parent_retriever_eval_chain_1.invoke({\"question\": inputs[\"question\"]})\n",
    "    return {\"answer\" : response[\"output\"]}\n",
    "\n",
    "def predict_chain_2(inputs: dict):\n",
    "    response = ensemble_retriever_eval_chain_2.invoke({\"question\": inputs[\"question\"]})\n",
    "    return {\"answer\" : response[\"output\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'OG PerunaBot chain-39986212' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/5d401ffc-aab6-461d-9092-0648c24d8a80/compare?selectedSessions=77674d36-5c7f-40ab-aac5-9ade509cd489\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe7eda781be643bab06a3a874cb839de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e5b01709-c139-4df4-be2f-b067cbf3c941: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f2363ec5-c4ee-46a3-95f9-804ea4405acb: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 935c3984-4e80-4d97-a3e2-1dbb42a4ce79: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f44fba6b-a717-4848-bff3-a78d59b728f2: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 8fe11ebe-5391-4d21-aea8-b5e0dfd43acd: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 75844b64-0804-452b-a5a2-f0b78900937d: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 73d428f7-9312-4811-8ace-fab6ec462783: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 666b3bc5-b617-4154-acf3-b78cf4b65be7: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e5b01709-c139-4df4-be2f-b067cbf3c941: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f2363ec5-c4ee-46a3-95f9-804ea4405acb: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 935c3984-4e80-4d97-a3e2-1dbb42a4ce79: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f44fba6b-a717-4848-bff3-a78d59b728f2: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 8fe11ebe-5391-4d21-aea8-b5e0dfd43acd: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 75844b64-0804-452b-a5a2-f0b78900937d: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 73d428f7-9312-4811-8ace-fab6ec462783: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 666b3bc5-b617-4154-acf3-b78cf4b65be7: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e5b01709-c139-4df4-be2f-b067cbf3c941: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f2363ec5-c4ee-46a3-95f9-804ea4405acb: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 935c3984-4e80-4d97-a3e2-1dbb42a4ce79: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f44fba6b-a717-4848-bff3-a78d59b728f2: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 8fe11ebe-5391-4d21-aea8-b5e0dfd43acd: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 75844b64-0804-452b-a5a2-f0b78900937d: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 73d428f7-9312-4811-8ace-fab6ec462783: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 666b3bc5-b617-4154-acf3-b78cf4b65be7: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e5b01709-c139-4df4-be2f-b067cbf3c941: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f2363ec5-c4ee-46a3-95f9-804ea4405acb: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 935c3984-4e80-4d97-a3e2-1dbb42a4ce79: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f44fba6b-a717-4848-bff3-a78d59b728f2: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 8fe11ebe-5391-4d21-aea8-b5e0dfd43acd: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 75844b64-0804-452b-a5a2-f0b78900937d: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 73d428f7-9312-4811-8ace-fab6ec462783: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 666b3bc5-b617-4154-acf3-b78cf4b65be7: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n"
     ]
    }
   ],
   "source": [
    "OG_PerunaBot_langsmith_eval_2 = evaluate(\n",
    "    predict_OG_chain,\n",
    "    data=dataset_3,\n",
    "    evaluators=langsmith_evaluators,\n",
    "    experiment_prefix=\"OG PerunaBot chain\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'chain 0-1f26194d' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/5d401ffc-aab6-461d-9092-0648c24d8a80/compare?selectedSessions=40dba849-ef43-4fc2-85f6-2ac2fb331aeb\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b430fae7dc274c48aefb49421771e23c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 67c3d8ce-b579-4d1e-8e53-ccb99043cb75: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 4d7e27fc-8d2c-4e2b-8be8-96cb486be42d: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run c778d699-8295-4d2c-9c4b-467adfb5b064: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d2e3c2e3-a083-4f9e-9e15-2d9e1e93c462: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a544d6c2-7c9a-4fd9-888b-d348f4760abb: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f88733fc-6c56-40f1-8f74-32f42e7f8fd7: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 09a85b47-11c8-48e7-81f3-4a2ddd7fb3e8: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 67c3d8ce-b579-4d1e-8e53-ccb99043cb75: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d32dc7a5-64db-4a65-9392-2c4d8a8b7de3: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 4d7e27fc-8d2c-4e2b-8be8-96cb486be42d: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run c778d699-8295-4d2c-9c4b-467adfb5b064: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d2e3c2e3-a083-4f9e-9e15-2d9e1e93c462: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a544d6c2-7c9a-4fd9-888b-d348f4760abb: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f88733fc-6c56-40f1-8f74-32f42e7f8fd7: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 09a85b47-11c8-48e7-81f3-4a2ddd7fb3e8: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 67c3d8ce-b579-4d1e-8e53-ccb99043cb75: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d32dc7a5-64db-4a65-9392-2c4d8a8b7de3: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 4d7e27fc-8d2c-4e2b-8be8-96cb486be42d: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run c778d699-8295-4d2c-9c4b-467adfb5b064: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d2e3c2e3-a083-4f9e-9e15-2d9e1e93c462: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a544d6c2-7c9a-4fd9-888b-d348f4760abb: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f88733fc-6c56-40f1-8f74-32f42e7f8fd7: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 09a85b47-11c8-48e7-81f3-4a2ddd7fb3e8: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 67c3d8ce-b579-4d1e-8e53-ccb99043cb75: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d32dc7a5-64db-4a65-9392-2c4d8a8b7de3: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 4d7e27fc-8d2c-4e2b-8be8-96cb486be42d: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run c778d699-8295-4d2c-9c4b-467adfb5b064: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d2e3c2e3-a083-4f9e-9e15-2d9e1e93c462: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a544d6c2-7c9a-4fd9-888b-d348f4760abb: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f88733fc-6c56-40f1-8f74-32f42e7f8fd7: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 09a85b47-11c8-48e7-81f3-4a2ddd7fb3e8: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d32dc7a5-64db-4a65-9392-2c4d8a8b7de3: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chain_0_langsmith_eval_2 = evaluate(\n",
    "    predict_chain_0,\n",
    "    data=dataset_3,\n",
    "    evaluators=langsmith_evaluators,\n",
    "    experiment_prefix=\"chain 0\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'chain 1-30610d12' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/5d401ffc-aab6-461d-9092-0648c24d8a80/compare?selectedSessions=0f8bfae4-12be-4d93-becd-9d480a978689\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad0693178164baeb8e3a90c2d8705e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 86e982a7-a2c4-40cb-b19d-6ee6f2aff587: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run fffe0baf-724b-4239-ab1e-4d9c4ae9393b: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 86b68797-93c8-4d94-9c94-dc1d0a60dcc0: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 5ce1b5b0-0c32-4ad7-9ba7-cc94dabf2740: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run de14b9d0-da99-47ca-b80c-b89ae25c8b1f: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e06a6d22-940f-4ca5-97a0-809d0ed2aa7e: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f2462bf5-9368-4a6d-bb75-a206cc8dfc81: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d27f6923-eb47-4246-ada2-d5d55e8caabb: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 86e982a7-a2c4-40cb-b19d-6ee6f2aff587: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run fffe0baf-724b-4239-ab1e-4d9c4ae9393b: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 86b68797-93c8-4d94-9c94-dc1d0a60dcc0: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 5ce1b5b0-0c32-4ad7-9ba7-cc94dabf2740: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run de14b9d0-da99-47ca-b80c-b89ae25c8b1f: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e06a6d22-940f-4ca5-97a0-809d0ed2aa7e: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f2462bf5-9368-4a6d-bb75-a206cc8dfc81: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d27f6923-eb47-4246-ada2-d5d55e8caabb: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 86e982a7-a2c4-40cb-b19d-6ee6f2aff587: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run fffe0baf-724b-4239-ab1e-4d9c4ae9393b: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 86b68797-93c8-4d94-9c94-dc1d0a60dcc0: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 5ce1b5b0-0c32-4ad7-9ba7-cc94dabf2740: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run de14b9d0-da99-47ca-b80c-b89ae25c8b1f: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e06a6d22-940f-4ca5-97a0-809d0ed2aa7e: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f2462bf5-9368-4a6d-bb75-a206cc8dfc81: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d27f6923-eb47-4246-ada2-d5d55e8caabb: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 86e982a7-a2c4-40cb-b19d-6ee6f2aff587: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run fffe0baf-724b-4239-ab1e-4d9c4ae9393b: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 86b68797-93c8-4d94-9c94-dc1d0a60dcc0: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 5ce1b5b0-0c32-4ad7-9ba7-cc94dabf2740: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run de14b9d0-da99-47ca-b80c-b89ae25c8b1f: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e06a6d22-940f-4ca5-97a0-809d0ed2aa7e: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f2462bf5-9368-4a6d-bb75-a206cc8dfc81: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d27f6923-eb47-4246-ada2-d5d55e8caabb: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chain_1_langsmith_eval_2 = evaluate(\n",
    "    predict_chain_1,\n",
    "    data=dataset_3,\n",
    "    evaluators=langsmith_evaluators,\n",
    "    experiment_prefix=\"chain 1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'chain 2-83a99ce8' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/5d401ffc-aab6-461d-9092-0648c24d8a80/compare?selectedSessions=0d993ac0-9056-4302-828d-f57baa5f933d\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957796059cc444da8f51cda53c0e494c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 73769364-8264-4e01-9c6e-391062925a4b: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 41b62245-1701-4632-82d5-cd1cb9cf3b7d: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run daed3f65-c695-41a5-af52-2f95423fd53c: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run dd41fb95-f9e5-4974-9b6f-7f83f7d982d6: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run b5fb4ac8-c047-45d1-846a-c89356e2e5e1: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 73769364-8264-4e01-9c6e-391062925a4b: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 13a1eae0-a918-4f43-9129-c75a572367a8: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 4c1abba7-6a41-429c-8436-a11985478599: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 41b62245-1701-4632-82d5-cd1cb9cf3b7d: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 2a120e01-762c-463f-9161-77add2f3b872: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run daed3f65-c695-41a5-af52-2f95423fd53c: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run dd41fb95-f9e5-4974-9b6f-7f83f7d982d6: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run b5fb4ac8-c047-45d1-846a-c89356e2e5e1: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 73769364-8264-4e01-9c6e-391062925a4b: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 13a1eae0-a918-4f43-9129-c75a572367a8: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 4c1abba7-6a41-429c-8436-a11985478599: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 41b62245-1701-4632-82d5-cd1cb9cf3b7d: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 2a120e01-762c-463f-9161-77add2f3b872: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run daed3f65-c695-41a5-af52-2f95423fd53c: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run dd41fb95-f9e5-4974-9b6f-7f83f7d982d6: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run b5fb4ac8-c047-45d1-846a-c89356e2e5e1: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 73769364-8264-4e01-9c6e-391062925a4b: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 13a1eae0-a918-4f43-9129-c75a572367a8: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 4c1abba7-6a41-429c-8436-a11985478599: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 41b62245-1701-4632-82d5-cd1cb9cf3b7d: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 2a120e01-762c-463f-9161-77add2f3b872: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run daed3f65-c695-41a5-af52-2f95423fd53c: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run dd41fb95-f9e5-4974-9b6f-7f83f7d982d6: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run b5fb4ac8-c047-45d1-846a-c89356e2e5e1: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 13a1eae0-a918-4f43-9129-c75a572367a8: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 4c1abba7-6a41-429c-8436-a11985478599: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 2a120e01-762c-463f-9161-77add2f3b872: ValueError('LabeledCriteriaEvalChain requires a reference string.')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 219, in evaluate_strings\n",
      "    self._check_evaluation_args(reference=reference, input=input)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 127, in _check_evaluation_args\n",
      "    raise ValueError(f\"{self.__class__.__name__} requires a reference string.\")\n",
      "ValueError: LabeledCriteriaEvalChain requires a reference string.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chain_2_langsmith_eval_2 = evaluate(\n",
    "    predict_chain_2,\n",
    "    data=dataset_3,\n",
    "    evaluators=langsmith_evaluators,\n",
    "    experiment_prefix=\"chain 2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import evaluate_comparative\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langsmith.schemas import Run, Example\n",
    "\n",
    "prompts = {\n",
    "    \"prompt\" : hub.pull(\"langchain-ai/pairwise-evaluation-2\"),\n",
    "    \"rag prompt\" : hub.pull(\"langchain-ai/pairwise-evaluation-rag\"),\n",
    "    \"academic advisor prompt\" : hub.pull(\"perunabot-pairwise-evaluation\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Normal Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_pairwise_with_prompt(runs: list[Run], example: Example):\n",
    "    scores = {}\n",
    "    \n",
    "    # Create the model to run your evaluator\n",
    "    model = ChatOpenAI(model=\"gpt-4o\")\n",
    "    \n",
    "    runnable = prompts[\"prompt\"] | model\n",
    "    response = runnable.invoke({\n",
    "        \"question\": example.inputs[\"question\"],\n",
    "        \"answer_a\": runs[0].outputs[\"answer\"] if runs[0].outputs is not None else \"N/A\",\n",
    "        \"answer_b\": runs[1].outputs[\"answer\"] if runs[1].outputs is not None else \"N/A\",\n",
    "    })\n",
    "    score = response[\"Preference\"]\n",
    "    if score == 1:\n",
    "        scores[runs[0].id] = 1\n",
    "        scores[runs[1].id] = 0\n",
    "    elif score == 2:\n",
    "        scores[runs[0].id] = 0\n",
    "        scores[runs[1].id] = 1\n",
    "    else:\n",
    "        scores[runs[0].id] = 0\n",
    "        scores[runs[1].id] = 0\n",
    "    return {\"key\": \"ranked_preference\", \"scores\": scores}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OG PerunaBot vs Chain 0\n",
    "pairwise_eval_1 = evaluate_comparative(\n",
    "    [\"OG PerunaBot chain-39986212\", \"chain 0-1f26194d\"],\n",
    "    evaluators=[evaluate_pairwise_with_prompt],\n",
    "    experiment_prefix=\"OG PerunaBot vs Chain 0\",\n",
    "    randomize_order=True,\n",
    "    metadata={\"run name\": \"OG PerunaBot vs Chain 0\",\n",
    "              \"prompt\" : \"langchain-ai/pairwise-evaluation-2\"}\n",
    ")\n",
    "\n",
    "# OG PerunaBot vs Chain 1\n",
    "pairwise_eval_2 = evaluate_comparative(\n",
    "    [\"OG PerunaBot chain-39986212\", \"chain 1-30610d12\"],\n",
    "    evaluators=[evaluate_pairwise_with_prompt],\n",
    "    experiment_prefix=\"OG PerunaBot vs Chain 1\",\n",
    "    randomize_order=True,\n",
    "    metadata={\"run name\": \"OG PerunaBot vs Chain 1\",\n",
    "             \"prompt\" : \"langchain-ai/pairwise-evaluation-2\"}\n",
    ")\n",
    "\n",
    "# OG PerunaBot vs Chain 2\n",
    "pairwise_eval_3 = evaluate_comparative(\n",
    "    [\"OG PerunaBot chain-39986212\", \"chain 2-83a99ce8\"],\n",
    "    evaluators=[evaluate_pairwise_with_prompt],\n",
    "    experiment_prefix=\"OG PerunaBot vs Chain 2\",\n",
    "    randomize_order=True,\n",
    "    metadata={\"run name\": \"OG PerunaBot vs Chain 2\",\n",
    "              \"prompt\" : \"langchain-ai/pairwise-evaluation-2\"}\n",
    ")\n",
    "\n",
    "# Chain 0 vs Chain 1\n",
    "pairwise_eval_4 = evaluate_comparative(\n",
    "    [\"chain 0-1f26194d\", \"chain 1-30610d12\"],\n",
    "    evaluators=[evaluate_pairwise_with_prompt],\n",
    "    experiment_prefix=\"Chain 0 vs Chain 1\",\n",
    "    randomize_order=True,\n",
    "    metadata={\"run name\": \"Chain 0 vs Chain 1\",\n",
    "             \"prompt\" : \"langchain-ai/pairwise-evaluation-2\"}\n",
    ")\n",
    "\n",
    "# Chain 0 vs Chain 2\n",
    "pairwise_eval_5 = evaluate_comparative(\n",
    "    [\"chain 0-1f26194d\", \"chain 2-83a99ce8\"],\n",
    "    evaluators=[evaluate_pairwise_with_prompt],\n",
    "    experiment_prefix=\"Chain 0 vs Chain 2\",\n",
    "    randomize_order=True,\n",
    "    metadata={\"run name\": \"Chain 0 vs Chain 2\",\n",
    "              \"prompt\" : \"langchain-ai/pairwise-evaluation-2\"}\n",
    ")\n",
    "\n",
    "# Chain 1 vs Chain 2\n",
    "pairwise_eval_6 = evaluate_comparative(\n",
    "    [\"chain 1-30610d12\", \"chain 2-83a99ce8\"],\n",
    "    evaluators=[evaluate_pairwise_with_prompt],\n",
    "    experiment_prefix=\"Chain 1 vs Chain 2\",\n",
    "    randomize_order=True,\n",
    "    metadata={\"run name\": \"Chain 1 vs Chain 2\",\n",
    "              \"prompt\" : \"langchain-ai/pairwise-evaluation-2\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "![Pairwise Evaluation Results](../Data/Evaluation%20Results/pairwise%20evaluation%20v1%207-30.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using RAG Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_pairwise_with_rag_prompt(runs: list[Run], example: Example):\n",
    "    scores = {}\n",
    "    \n",
    "    # Create the model to run your evaluator\n",
    "    model = ChatOpenAI(model=\"gpt-4o\")\n",
    "    \n",
    "    runnable = prompts[\"rag prompt\"] | model\n",
    "    response = runnable.invoke({\n",
    "        \"question\": example.inputs[\"question\"],\n",
    "        \"answer_a\": runs[0].outputs[\"answer\"] if runs[0].outputs is not None else \"N/A\",\n",
    "        \"answer_b\": runs[1].outputs[\"answer\"] if runs[1].outputs is not None else \"N/A\",\n",
    "    })\n",
    "    score = response[\"Preference\"]\n",
    "    if score == 1:\n",
    "        scores[runs[0].id] = 1\n",
    "        scores[runs[1].id] = 0\n",
    "    elif score == 2:\n",
    "        scores[runs[0].id] = 0\n",
    "        scores[runs[1].id] = 1\n",
    "    else:\n",
    "        scores[runs[0].id] = 0\n",
    "        scores[runs[1].id] = 0\n",
    "    return {\"key\": \"ranked_preference\", \"scores\": scores}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OG PerunaBot vs Chain 0\n",
    "pairwise_eval_1 = evaluate_comparative(\n",
    "    [\"OG PerunaBot chain-39986212\", \"chain 0-1f26194d\"],\n",
    "    evaluators=[evaluate_pairwise_with_rag_prompt],\n",
    "    experiment_prefix=\"OG PerunaBot vs Chain 0\",\n",
    "    randomize_order=True,\n",
    "    metadata={\"run name\": \"OG PerunaBot vs Chain 0\",\n",
    "              \"prompt\" : \"langchain-ai/pairwise-evaluation-rag\"}\n",
    ")\n",
    "\n",
    "# OG PerunaBot vs Chain 1\n",
    "pairwise_eval_2 = evaluate_comparative(\n",
    "    [\"OG PerunaBot chain-39986212\", \"chain 1-30610d12\"],\n",
    "    evaluators=[evaluate_pairwise_with_rag_prompt],\n",
    "    experiment_prefix=\"OG PerunaBot vs Chain 1\",\n",
    "    randomize_order=True,\n",
    "    metadata={\"run name\": \"OG PerunaBot vs Chain 1\",\n",
    "              \"prompt\" : \"langchain-ai/pairwise-evaluation-rag\"}\n",
    ")\n",
    "\n",
    "# OG PerunaBot vs Chain 2\n",
    "pairwise_eval_3 = evaluate_comparative(\n",
    "    [\"OG PerunaBot chain-39986212\", \"chain 2-83a99ce8\"],\n",
    "    evaluators=[evaluate_pairwise_with_rag_prompt],\n",
    "    experiment_prefix=\"OG PerunaBot vs Chain 2\",\n",
    "    randomize_order=True,\n",
    "    metadata={\"run name\": \"OG PerunaBot vs Chain 2\",\n",
    "              \"prompt\" : \"langchain-ai/pairwise-evaluation-rag\"}\n",
    ")\n",
    "\n",
    "# Chain 0 vs Chain 1\n",
    "pairwise_eval_4 = evaluate_comparative(\n",
    "    [\"chain 0-1f26194d\", \"chain 1-30610d12\"],\n",
    "    evaluators=[evaluate_pairwise_with_rag_prompt],\n",
    "    experiment_prefix=\"Chain 0 vs Chain 1\",\n",
    "    randomize_order=True,\n",
    "    metadata={\"run name\": \"Chain 0 vs Chain 1\",\n",
    "              \"prompt\" : \"langchain-ai/pairwise-evaluation-rag\"}\n",
    ")\n",
    "\n",
    "# Chain 0 vs Chain 2\n",
    "pairwise_eval_5 = evaluate_comparative(\n",
    "    [\"chain 0-1f26194d\", \"chain 2-83a99ce8\"],\n",
    "    evaluators=[evaluate_pairwise_with_rag_prompt],\n",
    "    experiment_prefix=\"Chain 0 vs Chain 2\",\n",
    "    randomize_order=True,\n",
    "    metadata={\"run name\": \"Chain 0 vs Chain 2\",\n",
    "              \"prompt\" : \"langchain-ai/pairwise-evaluation-rag\"}\n",
    ")\n",
    "\n",
    "# Chain 1 vs Chain 2\n",
    "pairwise_eval_6 = evaluate_comparative(\n",
    "    [\"chain 1-30610d12\", \"chain 2-83a99ce8\"],\n",
    "    evaluators=[evaluate_pairwise_with_rag_prompt],\n",
    "    experiment_prefix=\"Chain 1 vs Chain 2\",\n",
    "    randomize_order=True,\n",
    "    metadata={\"run name\": \"Chain 1 vs Chain 2\",\n",
    "              \"prompt\" : \"langchain-ai/pairwise-evaluation-rag\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "![Pairwise Evaluation Results](../Data/Evaluation%20Results/pairwise%20evaluation%20v2%207-30.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Academic Advisor Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_pairwise_with_advisor_prompt(runs: list[Run], example: Example):\n",
    "    scores = {}\n",
    "    \n",
    "    # Create the model to run your evaluator\n",
    "    model = ChatOpenAI(model_name=\"gpt-4o\")\n",
    "    \n",
    "    runnable = prompts[\"academic advisor prompt\"] | model\n",
    "    response = runnable.invoke({\n",
    "        \"question\": example.inputs[\"question\"],\n",
    "        \"answer_a\": runs[0].outputs[\"answer\"] if runs[0].outputs is not None else \"N/A\",\n",
    "        \"answer_b\": runs[1].outputs[\"answer\"] if runs[1].outputs is not None else \"N/A\",\n",
    "    })\n",
    "    score = response[\"Preference\"]\n",
    "    if score == 1:\n",
    "        scores[runs[0].id] = 1\n",
    "        scores[runs[1].id] = 0\n",
    "    elif score == 2:\n",
    "        scores[runs[0].id] = 0\n",
    "        scores[runs[1].id] = 1\n",
    "    else:\n",
    "        scores[runs[0].id] = 0\n",
    "        scores[runs[1].id] = 0\n",
    "    return {\"key\": \"ranked_preference\", \"scores\": scores}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/5d401ffc-aab6-461d-9092-0648c24d8a80/compare?selectedSessions=77674d36-5c7f-40ab-aac5-9ade509cd489%2C40dba849-ef43-4fc2-85f6-2ac2fb331aeb&comparativeExperiment=1048b5ad-3b25-46ab-8e2b-27f4e5dc0a25\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96b0fac66344fa780e9d610689d1f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/5d401ffc-aab6-461d-9092-0648c24d8a80/compare?selectedSessions=77674d36-5c7f-40ab-aac5-9ade509cd489%2C0f8bfae4-12be-4d93-becd-9d480a978689&comparativeExperiment=80d0a129-9728-4ae4-bbc7-976fdc81baf2\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6337af5a5456485c917b74ec4f45d75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/5d401ffc-aab6-461d-9092-0648c24d8a80/compare?selectedSessions=77674d36-5c7f-40ab-aac5-9ade509cd489%2C0d993ac0-9056-4302-828d-f57baa5f933d&comparativeExperiment=7f7c7de0-45c6-4970-aa46-a627fe8bc1bc\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68a7ce3b2cc4039a7209784d437f17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/5d401ffc-aab6-461d-9092-0648c24d8a80/compare?selectedSessions=40dba849-ef43-4fc2-85f6-2ac2fb331aeb%2C0f8bfae4-12be-4d93-becd-9d480a978689&comparativeExperiment=17f0e8f5-371c-407b-9af7-970943f6cb66\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c7dc147f7a469783408ab38451363f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/5d401ffc-aab6-461d-9092-0648c24d8a80/compare?selectedSessions=40dba849-ef43-4fc2-85f6-2ac2fb331aeb%2C0d993ac0-9056-4302-828d-f57baa5f933d&comparativeExperiment=a985e125-8cf1-4990-9cdd-1422a91a0a3f\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cce57473ed94417a56166018aeda205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/5d401ffc-aab6-461d-9092-0648c24d8a80/compare?selectedSessions=0f8bfae4-12be-4d93-becd-9d480a978689%2C0d993ac0-9056-4302-828d-f57baa5f933d&comparativeExperiment=b3e2db54-c774-434c-b812-28ca43c74cd4\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693e0449d74840a499332c3bd83377f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OG PerunaBot vs Chain 0\n",
    "pairwise_eval_1 = evaluate_comparative(\n",
    "    [\"OG PerunaBot chain-39986212\", \"chain 0-1f26194d\"],\n",
    "    evaluators=[evaluate_pairwise_with_advisor_prompt],\n",
    "    experiment_prefix=\"OG PerunaBot vs Chain 0\",\n",
    "    randomize_order=True,\n",
    "    metadata={\"run name\": \"OG PerunaBot vs Chain 0\",\n",
    "              \"prompt\" : \"perunabot-pairwise-evaluation\"}\n",
    ")\n",
    "\n",
    "# OG PerunaBot vs Chain 1\n",
    "pairwise_eval_2 = evaluate_comparative(\n",
    "    [\"OG PerunaBot chain-39986212\", \"chain 1-30610d12\"],\n",
    "    evaluators=[evaluate_pairwise_with_advisor_prompt],\n",
    "    experiment_prefix=\"OG PerunaBot vs Chain 1\",\n",
    "    randomize_order=True,\n",
    "    metadata={\"run name\": \"OG PerunaBot vs Chain 1\",\n",
    "              \"prompt\" : \"perunabot-pairwise-evaluation\"}\n",
    ")\n",
    "\n",
    "# OG PerunaBot vs Chain 2\n",
    "pairwise_eval_3 = evaluate_comparative(\n",
    "    [\"OG PerunaBot chain-39986212\", \"chain 2-83a99ce8\"],\n",
    "    evaluators=[evaluate_pairwise_with_advisor_prompt],\n",
    "    experiment_prefix=\"OG PerunaBot vs Chain 2\",\n",
    "    randomize_order=True,\n",
    "    metadata={\"run name\": \"OG PerunaBot vs Chain 2\",\n",
    "              \"prompt\" : \"perunabot-pairwise-evaluation\"}\n",
    ")\n",
    "\n",
    "# Chain 0 vs Chain 1\n",
    "pairwise_eval_4 = evaluate_comparative(\n",
    "    [\"chain 0-1f26194d\", \"chain 1-30610d12\"],\n",
    "    evaluators=[evaluate_pairwise_with_advisor_prompt],\n",
    "    experiment_prefix=\"Chain 0 vs Chain 1\",\n",
    "    randomize_order=True,\n",
    "    metadata={\"run name\": \"Chain 0 vs Chain 1\",\n",
    "              \"prompt\" : \"perunabot-pairwise-evaluation\"}\n",
    ")\n",
    "\n",
    "# Chain 0 vs Chain 2\n",
    "pairwise_eval_5 = evaluate_comparative(\n",
    "    [\"chain 0-1f26194d\", \"chain 2-83a99ce8\"],\n",
    "    evaluators=[evaluate_pairwise_with_advisor_prompt],\n",
    "    experiment_prefix=\"Chain 0 vs Chain 2\",\n",
    "    randomize_order=True,\n",
    "    metadata={\"run name\": \"Chain 0 vs Chain 2\",\n",
    "              \"prompt\" : \"perunabot-pairwise-evaluation\"}\n",
    ")\n",
    "\n",
    "# Chain 1 vs Chain 2\n",
    "pairwise_eval_6 = evaluate_comparative(\n",
    "    [\"chain 1-30610d12\", \"chain 2-83a99ce8\"],\n",
    "    evaluators=[evaluate_pairwise_with_advisor_prompt],\n",
    "    experiment_prefix=\"Chain 1 vs Chain 2\",\n",
    "    randomize_order=True,\n",
    "    metadata={\"run name\": \"Chain 1 vs Chain 2\",\n",
    "              \"prompt\" : \"perunabot-pairwise-evaluation\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "![Pairwise Evaluation Results](../Data/Evaluation%20Results/pairwise%20evaluation%20v3%207-30.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data with corrected ties\n",
    "individual_wins = {\n",
    "    \"OG PerunaBot\": 7,\n",
    "    \"Chain 0\": 42,\n",
    "    \"Chain 1\": 38,\n",
    "    \"Chain 2\": 47\n",
    "}\n",
    "\n",
    "# Extracting data\n",
    "chains = list(individual_wins.keys())\n",
    "wins = list(individual_wins.values())\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(chains, wins, color=['blue', 'green', 'red', 'purple'])\n",
    "plt.xlabel('Chains')\n",
    "plt.ylabel('Number of Wins')\n",
    "\n",
    "# Add text annotations to the plot\n",
    "for i in range(len(chains)):\n",
    "    plt.text(i, wins[i], str(wins[i]), ha='center', va='bottom')\n",
    "\n",
    "plt.title('Individual Wins of Each Chain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win percentage of each chain (out of 72 total comparisons):\n",
      "OG PerunaBot: 9.72%\n",
      "Chain 0: 58.33%\n",
      "Chain 1: 52.78%\n",
      "Chain 2: 65.28%\n"
     ]
    }
   ],
   "source": [
    "# Data with corrected ties\n",
    "individual_wins = {\n",
    "    \"OG PerunaBot\": 7,\n",
    "    \"Chain 0\": 42,\n",
    "    \"Chain 1\": 38,\n",
    "    \"Chain 2\": 47\n",
    "}\n",
    "\n",
    "print(\"Win percentage of each chain (out of 72 total comparisons):\")\n",
    "for i in individual_wins:\n",
    "    win_percentage = ((individual_wins[i] / 72) * 100).__round__(2)\n",
    "    print(f\"{i}: {win_percentage}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data with wins based on thumbs up\n",
    "overall_wins = {\n",
    "    \"OG PerunaBot\": 0,\n",
    "    \"Chain 0\": 7,\n",
    "    \"Chain 1\": 4,\n",
    "    \"Chain 2\": 6\n",
    "}\n",
    "\n",
    "# Extracting data\n",
    "chains = list(overall_wins.keys())\n",
    "thumbs_up_wins = list(overall_wins.values())\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(chains, thumbs_up_wins, color=['blue', 'green', 'red', 'purple'])\n",
    "plt.xlabel('Chains')\n",
    "plt.ylabel('Number of Wins')\n",
    "\n",
    "# Add text annotations to the plot\n",
    "for i in range(len(chains)):\n",
    "    plt.text(i, thumbs_up_wins[i], str(thumbs_up_wins[i]), ha='center', va='bottom')\n",
    "\n",
    "plt.title('Performance Comparison of RAG Pipelines (Thumbs Up Count)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypothesis:** \n",
    "OG PerunaBot is going to do worse compared to the other chains. Then the order from best to worst will be Chain 2, Chain 1, then Chain 0.\n",
    "\n",
    "**Results:** OG PerunaBot was in last place, but the order was Chain 2, Chain 0, then Chain 1.\n",
    "\n",
    "**New Hypothesis:** \n",
    "OG PerunaBot did worse because using gpt-3.5-turbo without prompt engineering while the others use gpt-4o with prompt engineering (Chain 0 is basically OG PerunaBot with prompt engineering, using gpt-4o). The biggest difference is in the prompt engineering more than the model. To test this, I will compare all 4 again using gpt-3.5-turbo.\n",
    "\n",
    "I would also like to compare gpt-4o and gpt-4o-mini for the top 3 chains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from OG_PerunaBot_chain import Original_PerunaBot_eval_chain, Original_PerunaBot_eval_chain_v1, Original_PerunaBot_eval_chain_v2\n",
    "from chain_0 import base_retriever_eval_chain_0, base_retriever_eval_chain_0_v1, base_retriever_eval_chain_0_v2\n",
    "from chain_1 import parent_retriever_eval_chain_1, parent_retriever_eval_chain_1_v1, parent_retriever_eval_chain_1_v2\n",
    "from chain_2 import ensemble_retriever_eval_chain_2, ensemble_retriever_eval_chain_2_v1, ensemble_retriever_eval_chain_2_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "OG_PerunaBot_chains = {\n",
    "    \"OG PerunaBot (gpt-3.5-turbo)\": Original_PerunaBot_eval_chain, # gpt-3.5-turbo\n",
    "    \"Original PerunaBot v1 (gpt-4o)\": Original_PerunaBot_eval_chain_v1, # gpt-4o\n",
    "    \"Original PerunaBot v2 (gpt-4o-mini)\": Original_PerunaBot_eval_chain_v2, # gpt-4o-mini\n",
    "\n",
    "}\n",
    "\n",
    "PerunaBot_0_chains = {\n",
    "    \"PerunaBot 0 v1 (gpt-3.5-turbo)\": base_retriever_eval_chain_0_v1, # gpt-3.5-turbo\n",
    "    \"PerunaBot 0 (gpt-4o)\": base_retriever_eval_chain_0, # gpt-4o\n",
    "    \"PerunaBot 0 v2 (gpt-4o-mini)\": base_retriever_eval_chain_0_v2, # gpt-4o-mini\n",
    "}\n",
    "\n",
    "PerunaBot_1_chains = {\n",
    "    \"PerunaBot 1 v1 (gpt-3.5-turbo)\": parent_retriever_eval_chain_1_v1, # gpt-3.5-turbo\n",
    "    \"PerunaBot 1 (gpt-4o)\": parent_retriever_eval_chain_1, # gpt-4o\n",
    "    \"PerunaBot 1 v2 (gpt-4o-mini)\": parent_retriever_eval_chain_1_v2, # gpt-4o-mini\n",
    "}\n",
    "\n",
    "PerunaBot_2_chains = {\n",
    "    \"PerunaBot 2 v1 (gpt-3.5-turbo)\": ensemble_retriever_eval_chain_2_v1, # gpt-3.5-turbo\n",
    "    \"PerunaBot 2 (gpt-4o)\": ensemble_retriever_eval_chain_2, # gpt-4o\n",
    "    \"PerunaBot 2 v2 (gpt-4o-mini)\": ensemble_retriever_eval_chain_2_v2 # gpt-4o-mini\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "\n",
    "# Target task definition\n",
    "\n",
    "# The name or UUID of the LangSmith dataset to evaluate on.\n",
    "\n",
    "new_data = \"Dataset 8/6/2024\"\n",
    "\n",
    "\n",
    "# List of evaluators to score the outputs of target task\n",
    "new_evaluators = [\n",
    "  LangChainStringEvaluator(\"cot_qa\"),\n",
    "  LangChainStringEvaluator(\"labeled_criteria\", config={\"criteria\": \"coherence\"}),\n",
    "  LangChainStringEvaluator(\"labeled_criteria\", config={\"criteria\": \"helpfulness\"})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import evaluate_comparative\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langsmith.schemas import Run, Example\n",
    "\n",
    "prompts = {\n",
    "    \"base prompt\" : hub.pull(\"langchain-ai/pairwise-evaluation-2\"),\n",
    "    \"rag prompt\" : hub.pull(\"langchain-ai/pairwise-evaluation-rag\"),\n",
    "    \"academic advisor prompt\" : hub.pull(\"perunabot-pairwise-evaluation\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pairwise_with_prompt(runs: list[Run], example: Example):\n",
    "    scores = {}\n",
    "    \n",
    "    # Create the model to run your evaluator\n",
    "    model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    \n",
    "    runnable = prompts[\"base prompt\"] | model\n",
    "    response = runnable.invoke({\n",
    "        \"question\": example.inputs[\"Question\"],\n",
    "        \"answer_a\": runs[0].outputs[\"output\"] if runs[0].outputs is not None else \"N/A\",\n",
    "        \"answer_b\": runs[1].outputs[\"output\"] if runs[1].outputs is not None else \"N/A\",\n",
    "    })\n",
    "    score = response[\"Preference\"]\n",
    "    if score == 1:\n",
    "        scores[runs[0].id] = 1\n",
    "        scores[runs[1].id] = 0\n",
    "    elif score == 2:\n",
    "        scores[runs[0].id] = 0\n",
    "        scores[runs[1].id] = 1\n",
    "    else:\n",
    "        scores[runs[0].id] = 0\n",
    "        scores[runs[1].id] = 0\n",
    "    return {\"key\": \"ranked_preference\", \"scores\": scores}\n",
    "\n",
    "def evaluate_pairwise_with_rag_prompt(runs: list[Run], example: Example):\n",
    "\n",
    "    scores = {}\n",
    "    \n",
    "    # Create the model to run your evaluator\n",
    "    model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    \n",
    "    runnable = prompts[\"rag prompt\"] | model\n",
    "    response = runnable.invoke({\n",
    "        \"question\": example.inputs[\"Question\"],\n",
    "        \"answer_a\": runs[0].outputs[\"output\"] if runs[0].outputs is not None else \"N/A\",\n",
    "        \"answer_b\": runs[1].outputs[\"output\"] if runs[1].outputs is not None else \"N/A\",\n",
    "    })\n",
    "    score = response[\"Preference\"]\n",
    "    if score == 1:\n",
    "        scores[runs[0].id] = 1\n",
    "        scores[runs[1].id] = 0\n",
    "    elif score == 2:\n",
    "        scores[runs[0].id] = 0\n",
    "        scores[runs[1].id] = 1\n",
    "    else:\n",
    "        scores[runs[0].id] = 0\n",
    "        scores[runs[1].id] = 0\n",
    "    return {\"key\": \"ranked_preference\", \"scores\": scores}\n",
    "\n",
    "def evaluate_pairwise_with__advisor_prompt(runs: list[Run], example: Example):\n",
    "    scores = {}\n",
    "    \n",
    "    # Create the model to run your evaluator\n",
    "    model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    \n",
    "    runnable = prompts[\"academic advisor prompt\"] | model\n",
    "    response = runnable.invoke({\n",
    "        \"question\": example.inputs[\"Question\"],\n",
    "        \"answer_a\": runs[0].outputs[\"output\"] if runs[0].outputs is not None else \"N/A\",\n",
    "        \"answer_b\": runs[1].outputs[\"output\"] if runs[1].outputs is not None else \"N/A\",\n",
    "    })\n",
    "    score = response[\"Preference\"]\n",
    "    if score == 1:\n",
    "        scores[runs[0].id] = 1\n",
    "        scores[runs[1].id] = 0\n",
    "    elif score == 2:\n",
    "        scores[runs[0].id] = 0\n",
    "        scores[runs[1].id] = 1\n",
    "    else:\n",
    "        scores[runs[0].id] = 0\n",
    "        scores[runs[1].id] = 0\n",
    "    return {\"key\": \"ranked_preference\", \"scores\": scores}\n",
    "\n",
    "evaluate_pairwise_functions = {\n",
    "    \"base prompt\": evaluate_pairwise_with_prompt,\n",
    "    \"rag prompt\": evaluate_pairwise_with_rag_prompt,\n",
    "    \"academic advisor prompt\": evaluate_pairwise_with__advisor_prompt\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run pairwise evaluations\n",
    "def run_pairwise_evaluations(experiments, evaluate_pairwise_functions):\n",
    "    for name in evaluate_pairwise_functions:\n",
    "        for i in range(len(experiments)):\n",
    "            for j in range(i + 1, len(experiments)):\n",
    "                print(f\"Evaluating: {experiments[i]} vs {experiments[j]} with prompt: {name}\")\n",
    "                evaluate_comparative(\n",
    "                    [experiments[i], experiments[j]],\n",
    "                    evaluators=[evaluate_pairwise_functions[name]],\n",
    "                    experiment_prefix=f\"{experiments[i]} vs {experiments[j]}\",\n",
    "                    randomize_order=True,\n",
    "                    metadata={\"run name\": f\"{experiments[i]} vs {experiments[j]}\", \"prompt\": name}\n",
    "                )\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'OG PerunaBot (gpt-3.5-turbo)-81aab9e3' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=87d56d66-8f17-4a61-9467-955b33bec539\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aeb156b3333490192665d704a2be8a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f39bb6ba-bf01-4ac7-b916-ea0d85c77148: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9942, Requested 477. Please try again in 2.514s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9942, Requested 477. Please try again in 2.514s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 88b2c329-0894-45b7-8b81-98bfcf01fc0d: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9755, Requested 391. Please try again in 876ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9755, Requested 391. Please try again in 876ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 7f124cda-2e04-4582-8d85-c303873fab09: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9733, Requested 406. Please try again in 834ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9733, Requested 406. Please try again in 834ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a19e9da1-85e6-47a1-8fe2-6cfd16253e66: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9982, Requested 498. Please try again in 2.88s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9982, Requested 498. Please try again in 2.88s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e61d95b2-e7ca-4459-9135-ea84cd7bcd05: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9983, Requested 501. Please try again in 2.904s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9983, Requested 501. Please try again in 2.904s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 362d85df-643a-4faa-9d76-d21ca1d8486d: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9958, Requested 507. Please try again in 2.79s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9958, Requested 507. Please try again in 2.79s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 3a453043-bfad-41f5-b1a3-0aef65ec48c3: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9908, Requested 572. Please try again in 2.88s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9908, Requested 572. Please try again in 2.88s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run c0b52f1f-4d74-4058-a318-fe987597cb48: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9638, Requested 499. Please try again in 822ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9638, Requested 499. Please try again in 822ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 8e4a38d1-a315-45fd-9b98-0ba22740ce12: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9621, Requested 522. Please try again in 858ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9621, Requested 522. Please try again in 858ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a19e9da1-85e6-47a1-8fe2-6cfd16253e66: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9973, Requested 452. Please try again in 2.55s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9973, Requested 452. Please try again in 2.55s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e61d95b2-e7ca-4459-9135-ea84cd7bcd05: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9970, Requested 455. Please try again in 2.55s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9970, Requested 455. Please try again in 2.55s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 4d20be14-a14b-4217-b968-caf527a3aef1: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9864, Requested 562. Please try again in 2.556s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9864, Requested 562. Please try again in 2.556s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a366ac4b-6ee3-469a-8603-bb2c5e12a833: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9804, Requested 772. Please try again in 3.456s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9804, Requested 772. Please try again in 3.456s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run ee9604bd-d99a-42f1-b94c-f4588e36ef9c: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9668, Requested 463. Please try again in 786ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9668, Requested 463. Please try again in 786ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e61d95b2-e7ca-4459-9135-ea84cd7bcd05: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9983, Requested 463. Please try again in 2.676s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9983, Requested 463. Please try again in 2.676s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 346f6d73-db29-414e-9e85-fff2785253bb: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9972, Requested 477. Please try again in 2.694s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9972, Requested 477. Please try again in 2.694s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'Original PerunaBot v1 (gpt-4o)-dc4c4966' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=b0eed89c-c8f2-41db-9a36-945133929aa8\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30bd2003abf49038dd5e09c57e6e0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator evaluate> on run fa8b342d-6013-42bb-820f-ae4abb57c7fb: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9744, Requested 520. Please try again in 1.584s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9744, Requested 520. Please try again in 1.584s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run cb63c9c3-eca0-45f0-b659-32b887c15815: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9869, Requested 749. Please try again in 3.708s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9869, Requested 749. Please try again in 3.708s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run fa8b342d-6013-42bb-820f-ae4abb57c7fb: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9917, Requested 474. Please try again in 2.346s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9917, Requested 474. Please try again in 2.346s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run c85c1135-4a87-4fef-9893-30d3870f1620: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9971, Requested 427. Please try again in 2.388s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9971, Requested 427. Please try again in 2.388s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run eacd603d-16b7-4b08-8aa1-16fc05c03a71: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9946, Requested 450. Please try again in 2.376s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9946, Requested 450. Please try again in 2.376s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 232c4570-a5b9-4873-9ae5-f7156a9482bc: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9942, Requested 451. Please try again in 2.358s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9942, Requested 451. Please try again in 2.358s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d2094230-b99b-4a56-8a85-34c89463fe1e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9849, Requested 614. Please try again in 2.778s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9849, Requested 614. Please try again in 2.778s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run cb63c9c3-eca0-45f0-b659-32b887c15815: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9756, Requested 703. Please try again in 2.754s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9756, Requested 703. Please try again in 2.754s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 04dca5e6-7eef-4edc-bf35-1fce85a4e084: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9960, Requested 458. Please try again in 2.508s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9960, Requested 458. Please try again in 2.508s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run fa8b342d-6013-42bb-820f-ae4abb57c7fb: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9937, Requested 483. Please try again in 2.52s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9937, Requested 483. Please try again in 2.52s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a49e438b-f07c-492d-89e0-aac53db1084d: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9896, Requested 527. Please try again in 2.538s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9896, Requested 527. Please try again in 2.538s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 232c4570-a5b9-4873-9ae5-f7156a9482bc: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9966, Requested 460. Please try again in 2.556s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9966, Requested 460. Please try again in 2.556s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run eacd603d-16b7-4b08-8aa1-16fc05c03a71: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9964, Requested 459. Please try again in 2.538s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9964, Requested 459. Please try again in 2.538s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d2094230-b99b-4a56-8a85-34c89463fe1e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9643, Requested 623. Please try again in 1.596s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9643, Requested 623. Please try again in 1.596s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run cb63c9c3-eca0-45f0-b659-32b887c15815: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9601, Requested 712. Please try again in 1.878s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9601, Requested 712. Please try again in 1.878s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 04dca5e6-7eef-4edc-bf35-1fce85a4e084: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9901, Requested 466. Please try again in 2.202s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9901, Requested 466. Please try again in 2.202s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a49e438b-f07c-492d-89e0-aac53db1084d: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9837, Requested 535. Please try again in 2.232s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9837, Requested 535. Please try again in 2.232s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 0be5f12f-2199-4c9a-8c54-1bb8d07ec0b3: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9807, Requested 565. Please try again in 2.232s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9807, Requested 565. Please try again in 2.232s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 9c909ed7-71b7-4e6e-9c4d-a7674eb696cf: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9754, Requested 430. Please try again in 1.104s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9754, Requested 430. Please try again in 1.104s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 638d31f6-4a2e-4ff0-a429-2016382e6f4e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9711, Requested 469. Please try again in 1.08s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9711, Requested 469. Please try again in 1.08s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 6f67e7e3-d180-4437-b2a0-253163e63054: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9667, Requested 390. Please try again in 342ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9667, Requested 390. Please try again in 342ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 4668b0b8-d503-4785-942c-48eb7b6e2f13: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9637, Requested 419. Please try again in 336ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9637, Requested 419. Please try again in 336ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 638d31f6-4a2e-4ff0-a429-2016382e6f4e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9633, Requested 423. Please try again in 336ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9633, Requested 423. Please try again in 336ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 0be5f12f-2199-4c9a-8c54-1bb8d07ec0b3: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9971, Requested 519. Please try again in 2.94s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9971, Requested 519. Please try again in 2.94s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 9c909ed7-71b7-4e6e-9c4d-a7674eb696cf: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9622, Requested 384. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9622, Requested 384. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'Original PerunaBot v2 (gpt-4o-mini)-b0bfcf3b' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=940b35b5-4208-4166-acce-7db614d152a8\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce679ae3cae4353aec989e6a9ad978e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 679d7c0b-863e-421c-9c82-3b16098c7568: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9767, Requested 497. Please try again in 1.584s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9767, Requested 497. Please try again in 1.584s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 285a4790-e2d2-4cd5-83dd-27a94b6368aa: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9740, Requested 523. Please try again in 1.578s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9740, Requested 523. Please try again in 1.578s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 23698bd4-ef94-4555-9e03-cf56ff409814: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9946, Requested 645. Please try again in 3.546s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9946, Requested 645. Please try again in 3.546s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 679d7c0b-863e-421c-9c82-3b16098c7568: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9918, Requested 451. Please try again in 2.214s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9918, Requested 451. Please try again in 2.214s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f7f94528-2b18-4e44-9d7e-b9a696984960: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9914, Requested 743. Please try again in 3.941s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9914, Requested 743. Please try again in 3.941s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 285a4790-e2d2-4cd5-83dd-27a94b6368aa: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9869, Requested 477. Please try again in 2.076s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9869, Requested 477. Please try again in 2.076s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 790539c1-7e05-4e84-9e35-779030c86a5d: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9620, Requested 384. Please try again in 24ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9620, Requested 384. Please try again in 24ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 0e7bd378-b682-44f1-a53c-95d548494945: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9975, Requested 420. Please try again in 2.37s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9975, Requested 420. Please try again in 2.37s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run c507d4c6-f34a-4ed4-b9b6-2d52b028f2e1: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9933, Requested 460. Please try again in 2.358s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9933, Requested 460. Please try again in 2.358s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run ce7617a8-295e-430c-8cd1-2dc64b837b35: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9965, Requested 541. Please try again in 3.036s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9965, Requested 541. Please try again in 3.036s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 23698bd4-ef94-4555-9e03-cf56ff409814: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9892, Requested 599. Please try again in 2.946s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9892, Requested 599. Please try again in 2.946s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 679d7c0b-863e-421c-9c82-3b16098c7568: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9965, Requested 460. Please try again in 2.55s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9965, Requested 460. Please try again in 2.55s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 285a4790-e2d2-4cd5-83dd-27a94b6368aa: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9933, Requested 486. Please try again in 2.514s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9933, Requested 486. Please try again in 2.514s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 0e7bd378-b682-44f1-a53c-95d548494945: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9886, Requested 429. Please try again in 1.89s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9886, Requested 429. Please try again in 1.89s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 39d97762-d3b1-424a-b02f-5af1896bf504: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9886, Requested 428. Please try again in 1.883s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9886, Requested 428. Please try again in 1.883s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f7f94528-2b18-4e44-9d7e-b9a696984960: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9978, Requested 697. Please try again in 4.05s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9978, Requested 697. Please try again in 4.05s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run c507d4c6-f34a-4ed4-b9b6-2d52b028f2e1: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9882, Requested 469. Please try again in 2.106s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9882, Requested 469. Please try again in 2.106s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run ce7617a8-295e-430c-8cd1-2dc64b837b35: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9801, Requested 550. Please try again in 2.106s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9801, Requested 550. Please try again in 2.106s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 23698bd4-ef94-4555-9e03-cf56ff409814: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9745, Requested 607. Please try again in 2.112s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9745, Requested 607. Please try again in 2.112s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 39d97762-d3b1-424a-b02f-5af1896bf504: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9632, Requested 437. Please try again in 414ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9632, Requested 437. Please try again in 414ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run c93715bf-1da2-4f59-b080-99d51d8639c9: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9558, Requested 494. Please try again in 312ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9558, Requested 494. Please try again in 312ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 934eda8a-4ff0-4a34-bd3d-41062f7f42d0: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9920, Requested 510. Please try again in 2.58s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9920, Requested 510. Please try again in 2.58s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a1fbdec6-422e-4cbc-a120-320481de5583: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9877, Requested 580. Please try again in 2.742s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9877, Requested 580. Please try again in 2.742s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 934eda8a-4ff0-4a34-bd3d-41062f7f42d0: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9973, Requested 464. Please try again in 2.622s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9973, Requested 464. Please try again in 2.622s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f7f94528-2b18-4e44-9d7e-b9a696984960: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9863, Requested 706. Please try again in 3.414s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9863, Requested 706. Please try again in 3.414s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a1fbdec6-422e-4cbc-a120-320481de5583: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9585, Requested 534. Please try again in 714ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9585, Requested 534. Please try again in 714ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name in OG_PerunaBot_chains:\n",
    "    def predict_chain(inputs: dict):\n",
    "        chain = OG_PerunaBot_chains[name]\n",
    "        response = chain.invoke({\"question\": inputs[\"Question\"]})\n",
    "        return response[\"output\"]\n",
    "    \n",
    "    eval = evaluate(\n",
    "        predict_chain,\n",
    "        data=new_data,\n",
    "        evaluators=new_evaluators,\n",
    "        experiment_prefix=f\"{name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: OG PerunaBot (gpt-3.5-turbo)-81aab9e3 vs Original PerunaBot v1 (gpt-4o)-dc4c4966 with prompt: base prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=87d56d66-8f17-4a61-9467-955b33bec539%2Cb0eed89c-c8f2-41db-9a36-945133929aa8&comparativeExperiment=a474415a-f335-45c0-941e-17fbec0c7faf\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bdcca10ce024ec087ad60c6471ee9e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: OG PerunaBot (gpt-3.5-turbo)-81aab9e3 vs Original PerunaBot v2 (gpt-4o-mini)-b0bfcf3b with prompt: base prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=87d56d66-8f17-4a61-9467-955b33bec539%2C940b35b5-4208-4166-acce-7db614d152a8&comparativeExperiment=8f16290d-3377-470d-9cbd-9968094837f5\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3caa7e08d81d41edb11a2e70e13f854f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Original PerunaBot v1 (gpt-4o)-dc4c4966 vs Original PerunaBot v2 (gpt-4o-mini)-b0bfcf3b with prompt: base prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=b0eed89c-c8f2-41db-9a36-945133929aa8%2C940b35b5-4208-4166-acce-7db614d152a8&comparativeExperiment=3b219fe2-a1f5-47d1-bb94-0204e27eaec0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3bc8410e3364e55b0b7e96e1ce4f32c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: OG PerunaBot (gpt-3.5-turbo)-81aab9e3 vs Original PerunaBot v1 (gpt-4o)-dc4c4966 with prompt: rag prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=87d56d66-8f17-4a61-9467-955b33bec539%2Cb0eed89c-c8f2-41db-9a36-945133929aa8&comparativeExperiment=96e44d2a-3dba-4199-9e75-d5517e6c3b5b\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64cf787593b4282b31d01b98ae5ebc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: OG PerunaBot (gpt-3.5-turbo)-81aab9e3 vs Original PerunaBot v2 (gpt-4o-mini)-b0bfcf3b with prompt: rag prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=87d56d66-8f17-4a61-9467-955b33bec539%2C940b35b5-4208-4166-acce-7db614d152a8&comparativeExperiment=0e4cf554-7501-4bd9-89ed-104c790bb929\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15235a721bed4fceae72cfc7b82262cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Original PerunaBot v1 (gpt-4o)-dc4c4966 vs Original PerunaBot v2 (gpt-4o-mini)-b0bfcf3b with prompt: rag prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=b0eed89c-c8f2-41db-9a36-945133929aa8%2C940b35b5-4208-4166-acce-7db614d152a8&comparativeExperiment=fdc566e3-e715-46b2-b550-4604285fb0fb\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65fd04de5934b5c934604cfd9c3b29c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: OG PerunaBot (gpt-3.5-turbo)-81aab9e3 vs Original PerunaBot v1 (gpt-4o)-dc4c4966 with prompt: academic advisor prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=87d56d66-8f17-4a61-9467-955b33bec539%2Cb0eed89c-c8f2-41db-9a36-945133929aa8&comparativeExperiment=54eca3e6-aa25-4072-9464-98060b93ec90\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199319e7f7f344d0ab6453f3eab809d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: OG PerunaBot (gpt-3.5-turbo)-81aab9e3 vs Original PerunaBot v2 (gpt-4o-mini)-b0bfcf3b with prompt: academic advisor prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=87d56d66-8f17-4a61-9467-955b33bec539%2C940b35b5-4208-4166-acce-7db614d152a8&comparativeExperiment=376f92b4-d60b-4f8a-a6a8-45ba72d891ec\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6edd0337458247e389831ced6b091876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Original PerunaBot v1 (gpt-4o)-dc4c4966 vs Original PerunaBot v2 (gpt-4o-mini)-b0bfcf3b with prompt: academic advisor prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=b0eed89c-c8f2-41db-9a36-945133929aa8%2C940b35b5-4208-4166-acce-7db614d152a8&comparativeExperiment=f40fc5c8-fb28-494e-9ac6-aea05a76efc0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ca5d8c6f0245dfba1b043cf54e1a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the experiments\n",
    "OG_PuernaBot_experiments = [\n",
    "    \"OG PerunaBot (gpt-3.5-turbo)-81aab9e3\",\n",
    "    \"Original PerunaBot v1 (gpt-4o)-dc4c4966\",\n",
    "    \"Original PerunaBot v2 (gpt-4o-mini)-b0bfcf3b\"\n",
    "]\n",
    "\n",
    "# Run the evaluations\n",
    "OG_Peruna_Bot_pairwise_results = run_pairwise_evaluations(OG_PuernaBot_experiments, evaluate_pairwise_functions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "![Model Pairwise Evaluation Results](../Data/Evaluation%20Results/pairwise%20evaluation_model%20OG%20PerunaBot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data with corrected ties\n",
    "individual_wins = {\n",
    "    \"gpt-3.5-turbo\": 42,\n",
    "    \"gpt-4o\": 10,\n",
    "    \"gpt-4o-mini\": 12,\n",
    "}\n",
    "\n",
    "# Extracting data\n",
    "chains = list(individual_wins.keys())\n",
    "wins = list(individual_wins.values())\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(chains, wins, color=['blue', 'green', 'red'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Number of Individual Wins')\n",
    "\n",
    "# Add text annotations to the plot\n",
    "for i in range(len(chains)):\n",
    "    plt.text(i, wins[i], str(wins[i]), ha='center', va='bottom')\n",
    "\n",
    "plt.title('Comparing different OpenAI Models of OG PerunaBot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data with wins based on thumbs up\n",
    "overall_wins = {\n",
    "    \"gpt-3.5-turbo\": 6,\n",
    "    \"gpt-4o\": 1,\n",
    "    \"gpt-4o-mini\": 2,\n",
    "}\n",
    "\n",
    "# Extracting data\n",
    "chains = list(overall_wins.keys())\n",
    "thumbs_up_wins = list(overall_wins.values())\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(chains, thumbs_up_wins, color=['blue', 'green', 'red'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Number of Total Wins (Thumbs Up Count)')\n",
    "\n",
    "# Add text annotations to the plot\n",
    "for i in range(len(chains)):\n",
    "    plt.text(i, thumbs_up_wins[i], str(thumbs_up_wins[i]), ha='center', va='bottom')\n",
    "\n",
    "plt.title('Comparing different OpenAI Models of OG PerunaBot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'PerunaBot 0 v1 (gpt-3.5-turbo)-d608a7a9' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=76f114e5-4a3f-4b79-973d-84ef862987d7\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bf0df7d41d46d9bf1811f3abc45048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator evaluate> on run eb46e283-fd1f-4d99-a359-7bd5f719ff25: LangSmithError('Failed to POST /feedback in LangSmith API. HTTPError(\\'503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\\', \\'{\"detail\":\"Internal server error\"}\\')')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 129, in raise_for_status_with_text\n",
      "    response.raise_for_status()\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 820, in request_with_retries\n",
      "    ls_utils.raise_for_status_with_text(response)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 131, in raise_for_status_with_text\n",
      "    raise requests.HTTPError(str(e), response.text) from e  # type: ignore[call-arg]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "requests.exceptions.HTTPError: [Errno 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback] {\"detail\":\"Internal server error\"}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1264, in _run_evaluators\n",
      "    self.client._log_evaluation_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3745, in _log_evaluation_feedback\n",
      "    self.create_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3935, in create_feedback\n",
      "    self.request_with_retries(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 860, in request_with_retries\n",
      "    raise ls_utils.LangSmithError(\n",
      "langsmith.utils.LangSmithError: Failed to POST /feedback in LangSmith API. HTTPError('503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback', '{\"detail\":\"Internal server error\"}')\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 41ef540c-bb82-44cc-9c3c-082433f19a7f: LangSmithError('Failed to POST /feedback in LangSmith API. HTTPError(\\'503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\\', \\'{\"detail\":\"Internal server error\"}\\')')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 129, in raise_for_status_with_text\n",
      "    response.raise_for_status()\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 820, in request_with_retries\n",
      "    ls_utils.raise_for_status_with_text(response)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 131, in raise_for_status_with_text\n",
      "    raise requests.HTTPError(str(e), response.text) from e  # type: ignore[call-arg]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "requests.exceptions.HTTPError: [Errno 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback] {\"detail\":\"Internal server error\"}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1264, in _run_evaluators\n",
      "    self.client._log_evaluation_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3745, in _log_evaluation_feedback\n",
      "    self.create_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3935, in create_feedback\n",
      "    self.request_with_retries(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 860, in request_with_retries\n",
      "    raise ls_utils.LangSmithError(\n",
      "langsmith.utils.LangSmithError: Failed to POST /feedback in LangSmith API. HTTPError('503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback', '{\"detail\":\"Internal server error\"}')\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 6ac55dcc-449b-45f0-aeea-25d6148f3800: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9931, Requested 538. Please try again in 2.814s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9931, Requested 538. Please try again in 2.814s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 67bbb5fa-a985-4120-b6ce-7b63ad1e1313: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9909, Requested 555. Please try again in 2.784s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9909, Requested 555. Please try again in 2.784s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 159c71df-d144-48ba-8712-0c84ce2de1e6: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9893, Requested 555. Please try again in 2.688s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9893, Requested 555. Please try again in 2.688s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 32b455d0-7214-4aec-a089-86f792655a93: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9598, Requested 456. Please try again in 324ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9598, Requested 456. Please try again in 324ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 67bbb5fa-a985-4120-b6ce-7b63ad1e1313: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9549, Requested 509. Please try again in 348ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9549, Requested 509. Please try again in 348ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 159c71df-d144-48ba-8712-0c84ce2de1e6: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9542, Requested 509. Please try again in 306ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9542, Requested 509. Please try again in 306ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 67bbb5fa-a985-4120-b6ce-7b63ad1e1313: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9555, Requested 517. Please try again in 432ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9555, Requested 517. Please try again in 432ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 159c71df-d144-48ba-8712-0c84ce2de1e6: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9554, Requested 518. Please try again in 432ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9554, Requested 518. Please try again in 432ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'PerunaBot 0 (gpt-4o)-aa57f368' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=5912163a-7251-482c-b7e9-b413a0b60910\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9977de00d18a450d9bc74def49335dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 30000, Used 29955, Requested 3009. Please try again in 5.928s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 485cbf99-aca7-4bd9-8945-591375646794: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9770, Requested 669. Please try again in 2.634s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9770, Requested 669. Please try again in 2.634s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run c5b4db76-a0e7-455f-9e73-22b04cf067ae: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9983, Requested 488. Please try again in 2.826s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9983, Requested 488. Please try again in 2.826s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a28f0544-dc6f-496b-8fd4-96206039c127: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9929, Requested 543. Please try again in 2.832s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9929, Requested 543. Please try again in 2.832s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run de03fedf-5886-44c8-9a40-43f5f7e13488: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9926, Requested 543. Please try again in 2.814s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9926, Requested 543. Please try again in 2.814s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 4c21b31f-9e5e-4243-85a5-5d9db4a4b446: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9741, Requested 733. Please try again in 2.844s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9741, Requested 733. Please try again in 2.844s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run de03fedf-5886-44c8-9a40-43f5f7e13488: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9933, Requested 552. Please try again in 2.91s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9933, Requested 552. Please try again in 2.91s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a28f0544-dc6f-496b-8fd4-96206039c127: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9930, Requested 552. Please try again in 2.892s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9930, Requested 552. Please try again in 2.892s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 485cbf99-aca7-4bd9-8945-591375646794: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9870, Requested 677. Please try again in 3.282s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9870, Requested 677. Please try again in 3.282s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run ba4cb5a2-30c8-45fd-8487-e483bc0e1de1: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9759, Requested 788. Please try again in 3.282s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9759, Requested 788. Please try again in 3.282s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 686a4489-9788-4a32-adf2-930fcf4fc5f1: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9983, Requested 419. Please try again in 2.412s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9983, Requested 419. Please try again in 2.412s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 4c21b31f-9e5e-4243-85a5-5d9db4a4b446: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9924, Requested 742. Please try again in 3.996s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9924, Requested 742. Please try again in 3.996s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 0daa05f2-57ea-4f78-9160-c010a5140cfe: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9622, Requested 898. Please try again in 3.12s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9622, Requested 898. Please try again in 3.12s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 967f17e4-120d-4f62-8d63-f04eca3bed51: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9673, Requested 417. Please try again in 540ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9673, Requested 417. Please try again in 540ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 2f8c2db6-6ed4-403a-84be-8622511795d4: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9415, Requested 674. Please try again in 534ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9415, Requested 674. Please try again in 534ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run ba4cb5a2-30c8-45fd-8487-e483bc0e1de1: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9923, Requested 796. Please try again in 4.314s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9923, Requested 796. Please try again in 4.314s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 04dee98a-1f49-4f61-a8ce-ad446d3052b6: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9913, Requested 803. Please try again in 4.296s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9913, Requested 803. Please try again in 4.296s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 5392de8d-137f-4078-8b83-7c4154dd8f03: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9888, Requested 814. Please try again in 4.212s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9888, Requested 814. Please try again in 4.212s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 0daa05f2-57ea-4f78-9160-c010a5140cfe: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9744, Requested 906. Please try again in 3.9s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9744, Requested 906. Please try again in 3.9s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 04dee98a-1f49-4f61-a8ce-ad446d3052b6: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9727, Requested 757. Please try again in 2.904s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9727, Requested 757. Please try again in 2.904s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 5392de8d-137f-4078-8b83-7c4154dd8f03: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9715, Requested 768. Please try again in 2.898s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9715, Requested 768. Please try again in 2.898s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 5392de8d-137f-4078-8b83-7c4154dd8f03: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9892, Requested 776. Please try again in 4.008s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9892, Requested 776. Please try again in 4.008s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a319c133-8e4b-4914-a900-a9859a213fef: LangSmithError('Failed to POST /feedback in LangSmith API. HTTPError(\\'503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\\', \\'{\"detail\":\"Internal server error\"}\\')')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 129, in raise_for_status_with_text\n",
      "    response.raise_for_status()\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 820, in request_with_retries\n",
      "    ls_utils.raise_for_status_with_text(response)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 131, in raise_for_status_with_text\n",
      "    raise requests.HTTPError(str(e), response.text) from e  # type: ignore[call-arg]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "requests.exceptions.HTTPError: [Errno 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback] {\"detail\":\"Internal server error\"}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1264, in _run_evaluators\n",
      "    self.client._log_evaluation_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3745, in _log_evaluation_feedback\n",
      "    self.create_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3935, in create_feedback\n",
      "    self.request_with_retries(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 860, in request_with_retries\n",
      "    raise ls_utils.LangSmithError(\n",
      "langsmith.utils.LangSmithError: Failed to POST /feedback in LangSmith API. HTTPError('503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback', '{\"detail\":\"Internal server error\"}')\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 4e2d6ceb-4c78-4598-8918-e791dc0387ec: LangSmithError('Failed to POST /feedback in LangSmith API. HTTPError(\\'503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\\', \\'{\"detail\":\"Internal server error\"}\\')')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 129, in raise_for_status_with_text\n",
      "    response.raise_for_status()\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 820, in request_with_retries\n",
      "    ls_utils.raise_for_status_with_text(response)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 131, in raise_for_status_with_text\n",
      "    raise requests.HTTPError(str(e), response.text) from e  # type: ignore[call-arg]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "requests.exceptions.HTTPError: [Errno 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback] {\"detail\":\"Internal server error\"}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1264, in _run_evaluators\n",
      "    self.client._log_evaluation_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3745, in _log_evaluation_feedback\n",
      "    self.create_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3935, in create_feedback\n",
      "    self.request_with_retries(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 860, in request_with_retries\n",
      "    raise ls_utils.LangSmithError(\n",
      "langsmith.utils.LangSmithError: Failed to POST /feedback in LangSmith API. HTTPError('503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback', '{\"detail\":\"Internal server error\"}')\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 2f8c2db6-6ed4-403a-84be-8622511795d4: LangSmithError('Failed to POST /feedback in LangSmith API. HTTPError(\\'503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\\', \\'{\"detail\":\"Internal server error\"}\\')')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 129, in raise_for_status_with_text\n",
      "    response.raise_for_status()\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 820, in request_with_retries\n",
      "    ls_utils.raise_for_status_with_text(response)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 131, in raise_for_status_with_text\n",
      "    raise requests.HTTPError(str(e), response.text) from e  # type: ignore[call-arg]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "requests.exceptions.HTTPError: [Errno 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback] {\"detail\":\"Internal server error\"}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1264, in _run_evaluators\n",
      "    self.client._log_evaluation_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3745, in _log_evaluation_feedback\n",
      "    self.create_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3935, in create_feedback\n",
      "    self.request_with_retries(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 860, in request_with_retries\n",
      "    raise ls_utils.LangSmithError(\n",
      "langsmith.utils.LangSmithError: Failed to POST /feedback in LangSmith API. HTTPError('503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback', '{\"detail\":\"Internal server error\"}')\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 2031fdc3-ca28-4110-b4ac-8cef3059263e: LangSmithError('Failed to POST /feedback in LangSmith API. HTTPError(\\'503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\\', \\'{\"detail\":\"Internal server error\"}\\')')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 129, in raise_for_status_with_text\n",
      "    response.raise_for_status()\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 820, in request_with_retries\n",
      "    ls_utils.raise_for_status_with_text(response)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 131, in raise_for_status_with_text\n",
      "    raise requests.HTTPError(str(e), response.text) from e  # type: ignore[call-arg]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "requests.exceptions.HTTPError: [Errno 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback] {\"detail\":\"Internal server error\"}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1264, in _run_evaluators\n",
      "    self.client._log_evaluation_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3745, in _log_evaluation_feedback\n",
      "    self.create_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3935, in create_feedback\n",
      "    self.request_with_retries(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 860, in request_with_retries\n",
      "    raise ls_utils.LangSmithError(\n",
      "langsmith.utils.LangSmithError: Failed to POST /feedback in LangSmith API. HTTPError('503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback', '{\"detail\":\"Internal server error\"}')\n",
      "Failed to get tenant ID from LangSmith: LangSmithError('Failed to GET /sessions in LangSmith API. HTTPError(\\'503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/sessions?limit=1\\', \\'{\"detail\":\"Internal server error\"}\\')')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 129, in raise_for_status_with_text\n",
      "    response.raise_for_status()\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/sessions?limit=1\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 820, in request_with_retries\n",
      "    ls_utils.raise_for_status_with_text(response)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 131, in raise_for_status_with_text\n",
      "    raise requests.HTTPError(str(e), response.text) from e  # type: ignore[call-arg]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "requests.exceptions.HTTPError: [Errno 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/sessions?limit=1] {\"detail\":\"Internal server error\"}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 2227, in _get_optional_tenant_id\n",
      "    response = self.request_with_retries(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 860, in request_with_retries\n",
      "    raise ls_utils.LangSmithError(\n",
      "langsmith.utils.LangSmithError: Failed to GET /sessions in LangSmith API. HTTPError('503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/sessions?limit=1', '{\"detail\":\"Internal server error\"}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'PerunaBot 0 v2 (gpt-4o-mini)-0dc697ef' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=3fef4b44-7505-41d8-b0b8-ecc6acfe55c6\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cdc5de0c9924ba0ab2077e408fe6f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 694b42aa-978f-4dad-ac0c-0660ade68495: LangSmithError('Failed to POST /feedback in LangSmith API. HTTPError(\\'503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\\', \\'{\"detail\":\"Internal server error\"}\\')')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 129, in raise_for_status_with_text\n",
      "    response.raise_for_status()\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 820, in request_with_retries\n",
      "    ls_utils.raise_for_status_with_text(response)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 131, in raise_for_status_with_text\n",
      "    raise requests.HTTPError(str(e), response.text) from e  # type: ignore[call-arg]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "requests.exceptions.HTTPError: [Errno 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback] {\"detail\":\"Internal server error\"}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1264, in _run_evaluators\n",
      "    self.client._log_evaluation_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3745, in _log_evaluation_feedback\n",
      "    self.create_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3935, in create_feedback\n",
      "    self.request_with_retries(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 860, in request_with_retries\n",
      "    raise ls_utils.LangSmithError(\n",
      "langsmith.utils.LangSmithError: Failed to POST /feedback in LangSmith API. HTTPError('503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback', '{\"detail\":\"Internal server error\"}')\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 1be245da-cc72-45b5-b5ea-e88fb29dc4aa: LangSmithError('Failed to POST /feedback in LangSmith API. HTTPError(\\'503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\\', \\'{\"detail\":\"Internal server error\"}\\')')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 129, in raise_for_status_with_text\n",
      "    response.raise_for_status()\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 820, in request_with_retries\n",
      "    ls_utils.raise_for_status_with_text(response)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 131, in raise_for_status_with_text\n",
      "    raise requests.HTTPError(str(e), response.text) from e  # type: ignore[call-arg]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "requests.exceptions.HTTPError: [Errno 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback] {\"detail\":\"Internal server error\"}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1264, in _run_evaluators\n",
      "    self.client._log_evaluation_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3745, in _log_evaluation_feedback\n",
      "    self.create_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3935, in create_feedback\n",
      "    self.request_with_retries(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 860, in request_with_retries\n",
      "    raise ls_utils.LangSmithError(\n",
      "langsmith.utils.LangSmithError: Failed to POST /feedback in LangSmith API. HTTPError('503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback', '{\"detail\":\"Internal server error\"}')\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 31a67aa2-c782-4b12-a9ed-d3a63b0f7c27: LangSmithError('Failed to POST /feedback in LangSmith API. HTTPError(\\'503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\\', \\'{\"detail\":\"Internal server error\"}\\')')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 129, in raise_for_status_with_text\n",
      "    response.raise_for_status()\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 820, in request_with_retries\n",
      "    ls_utils.raise_for_status_with_text(response)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 131, in raise_for_status_with_text\n",
      "    raise requests.HTTPError(str(e), response.text) from e  # type: ignore[call-arg]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "requests.exceptions.HTTPError: [Errno 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback] {\"detail\":\"Internal server error\"}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1264, in _run_evaluators\n",
      "    self.client._log_evaluation_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3745, in _log_evaluation_feedback\n",
      "    self.create_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3935, in create_feedback\n",
      "    self.request_with_retries(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 860, in request_with_retries\n",
      "    raise ls_utils.LangSmithError(\n",
      "langsmith.utils.LangSmithError: Failed to POST /feedback in LangSmith API. HTTPError('503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback', '{\"detail\":\"Internal server error\"}')\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 392fd6f4-37c4-491d-a624-33a160113364: LangSmithError('Failed to POST /feedback in LangSmith API. HTTPError(\\'503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\\', \\'{\"detail\":\"Internal server error\"}\\')')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 129, in raise_for_status_with_text\n",
      "    response.raise_for_status()\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 820, in request_with_retries\n",
      "    ls_utils.raise_for_status_with_text(response)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 131, in raise_for_status_with_text\n",
      "    raise requests.HTTPError(str(e), response.text) from e  # type: ignore[call-arg]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "requests.exceptions.HTTPError: [Errno 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback] {\"detail\":\"Internal server error\"}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1264, in _run_evaluators\n",
      "    self.client._log_evaluation_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3745, in _log_evaluation_feedback\n",
      "    self.create_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3935, in create_feedback\n",
      "    self.request_with_retries(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 860, in request_with_retries\n",
      "    raise ls_utils.LangSmithError(\n",
      "langsmith.utils.LangSmithError: Failed to POST /feedback in LangSmith API. HTTPError('503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback', '{\"detail\":\"Internal server error\"}')\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 392fd6f4-37c4-491d-a624-33a160113364: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9685, Requested 571. Please try again in 1.536s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9685, Requested 571. Please try again in 1.536s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 392fd6f4-37c4-491d-a624-33a160113364: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9901, Requested 580. Please try again in 2.886s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9901, Requested 580. Please try again in 2.886s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 1bca79c0-fbfe-4e00-af9e-dbaccdd4c8c9: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9741, Requested 873. Please try again in 3.684s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9741, Requested 873. Please try again in 3.684s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a896294c-45f3-47e9-8d9e-5beab2f0d0fa: LangSmithError('Failed to POST /feedback in LangSmith API. HTTPError(\\'503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\\', \\'{\"detail\":\"Internal server error\"}\\')')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 129, in raise_for_status_with_text\n",
      "    response.raise_for_status()\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 820, in request_with_retries\n",
      "    ls_utils.raise_for_status_with_text(response)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 131, in raise_for_status_with_text\n",
      "    raise requests.HTTPError(str(e), response.text) from e  # type: ignore[call-arg]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "requests.exceptions.HTTPError: [Errno 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback] {\"detail\":\"Internal server error\"}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1264, in _run_evaluators\n",
      "    self.client._log_evaluation_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3745, in _log_evaluation_feedback\n",
      "    self.create_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3935, in create_feedback\n",
      "    self.request_with_retries(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 860, in request_with_retries\n",
      "    raise ls_utils.LangSmithError(\n",
      "langsmith.utils.LangSmithError: Failed to POST /feedback in LangSmith API. HTTPError('503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback', '{\"detail\":\"Internal server error\"}')\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 80af62a1-a042-4d3b-9636-47d79ed05074: LangSmithError('Failed to POST /feedback in LangSmith API. HTTPError(\\'503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\\', \\'{\"detail\":\"Internal server error\"}\\')')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 129, in raise_for_status_with_text\n",
      "    response.raise_for_status()\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 820, in request_with_retries\n",
      "    ls_utils.raise_for_status_with_text(response)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 131, in raise_for_status_with_text\n",
      "    raise requests.HTTPError(str(e), response.text) from e  # type: ignore[call-arg]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "requests.exceptions.HTTPError: [Errno 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback] {\"detail\":\"Internal server error\"}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1264, in _run_evaluators\n",
      "    self.client._log_evaluation_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3745, in _log_evaluation_feedback\n",
      "    self.create_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3935, in create_feedback\n",
      "    self.request_with_retries(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 860, in request_with_retries\n",
      "    raise ls_utils.LangSmithError(\n",
      "langsmith.utils.LangSmithError: Failed to POST /feedback in LangSmith API. HTTPError('503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback', '{\"detail\":\"Internal server error\"}')\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 0f1919dc-0feb-4e85-abc9-99bb26ed73d5: LangSmithError('Failed to POST /feedback in LangSmith API. HTTPError(\\'503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\\', \\'{\"detail\":\"Internal server error\"}\\')')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 129, in raise_for_status_with_text\n",
      "    response.raise_for_status()\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 820, in request_with_retries\n",
      "    ls_utils.raise_for_status_with_text(response)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 131, in raise_for_status_with_text\n",
      "    raise requests.HTTPError(str(e), response.text) from e  # type: ignore[call-arg]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "requests.exceptions.HTTPError: [Errno 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback] {\"detail\":\"Internal server error\"}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1264, in _run_evaluators\n",
      "    self.client._log_evaluation_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3745, in _log_evaluation_feedback\n",
      "    self.create_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3935, in create_feedback\n",
      "    self.request_with_retries(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 860, in request_with_retries\n",
      "    raise ls_utils.LangSmithError(\n",
      "langsmith.utils.LangSmithError: Failed to POST /feedback in LangSmith API. HTTPError('503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback', '{\"detail\":\"Internal server error\"}')\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 950ef6e7-b830-48e5-bc50-4b2739c707f2: LangSmithError('Failed to POST /feedback in LangSmith API. HTTPError(\\'503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\\', \\'{\"detail\":\"Internal server error\"}\\')')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 129, in raise_for_status_with_text\n",
      "    response.raise_for_status()\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 820, in request_with_retries\n",
      "    ls_utils.raise_for_status_with_text(response)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 131, in raise_for_status_with_text\n",
      "    raise requests.HTTPError(str(e), response.text) from e  # type: ignore[call-arg]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "requests.exceptions.HTTPError: [Errno 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback] {\"detail\":\"Internal server error\"}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1264, in _run_evaluators\n",
      "    self.client._log_evaluation_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3745, in _log_evaluation_feedback\n",
      "    self.create_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3935, in create_feedback\n",
      "    self.request_with_retries(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 860, in request_with_retries\n",
      "    raise ls_utils.LangSmithError(\n",
      "langsmith.utils.LangSmithError: Failed to POST /feedback in LangSmith API. HTTPError('503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback', '{\"detail\":\"Internal server error\"}')\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 1bf2632c-e501-445b-b451-2ea59701d765: LangSmithError('Failed to POST /feedback in LangSmith API. HTTPError(\\'503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\\', \\'{\"detail\":\"Internal server error\"}\\')')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 129, in raise_for_status_with_text\n",
      "    response.raise_for_status()\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 820, in request_with_retries\n",
      "    ls_utils.raise_for_status_with_text(response)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 131, in raise_for_status_with_text\n",
      "    raise requests.HTTPError(str(e), response.text) from e  # type: ignore[call-arg]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "requests.exceptions.HTTPError: [Errno 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback] {\"detail\":\"Internal server error\"}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1264, in _run_evaluators\n",
      "    self.client._log_evaluation_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3745, in _log_evaluation_feedback\n",
      "    self.create_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3935, in create_feedback\n",
      "    self.request_with_retries(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 860, in request_with_retries\n",
      "    raise ls_utils.LangSmithError(\n",
      "langsmith.utils.LangSmithError: Failed to POST /feedback in LangSmith API. HTTPError('503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback', '{\"detail\":\"Internal server error\"}')\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 1be245da-cc72-45b5-b5ea-e88fb29dc4aa: LangSmithError('Failed to POST /feedback in LangSmith API. HTTPError(\\'503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\\', \\'{\"detail\":\"Internal server error\"}\\')')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 129, in raise_for_status_with_text\n",
      "    response.raise_for_status()\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 820, in request_with_retries\n",
      "    ls_utils.raise_for_status_with_text(response)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 131, in raise_for_status_with_text\n",
      "    raise requests.HTTPError(str(e), response.text) from e  # type: ignore[call-arg]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "requests.exceptions.HTTPError: [Errno 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback] {\"detail\":\"Internal server error\"}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1264, in _run_evaluators\n",
      "    self.client._log_evaluation_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3745, in _log_evaluation_feedback\n",
      "    self.create_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3935, in create_feedback\n",
      "    self.request_with_retries(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 860, in request_with_retries\n",
      "    raise ls_utils.LangSmithError(\n",
      "langsmith.utils.LangSmithError: Failed to POST /feedback in LangSmith API. HTTPError('503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback', '{\"detail\":\"Internal server error\"}')\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 31a67aa2-c782-4b12-a9ed-d3a63b0f7c27: LangSmithError('Failed to POST /feedback in LangSmith API. HTTPError(\\'503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\\', \\'{\"detail\":\"Internal server error\"}\\')')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 129, in raise_for_status_with_text\n",
      "    response.raise_for_status()\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 820, in request_with_retries\n",
      "    ls_utils.raise_for_status_with_text(response)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 131, in raise_for_status_with_text\n",
      "    raise requests.HTTPError(str(e), response.text) from e  # type: ignore[call-arg]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "requests.exceptions.HTTPError: [Errno 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback] {\"detail\":\"Internal server error\"}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1264, in _run_evaluators\n",
      "    self.client._log_evaluation_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3745, in _log_evaluation_feedback\n",
      "    self.create_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3935, in create_feedback\n",
      "    self.request_with_retries(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 860, in request_with_retries\n",
      "    raise ls_utils.LangSmithError(\n",
      "langsmith.utils.LangSmithError: Failed to POST /feedback in LangSmith API. HTTPError('503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback', '{\"detail\":\"Internal server error\"}')\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 1bca79c0-fbfe-4e00-af9e-dbaccdd4c8c9: LangSmithError('Failed to POST /feedback in LangSmith API. HTTPError(\\'503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\\', \\'{\"detail\":\"Internal server error\"}\\')')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 129, in raise_for_status_with_text\n",
      "    response.raise_for_status()\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\requests\\models.py\", line 1024, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 820, in request_with_retries\n",
      "    ls_utils.raise_for_status_with_text(response)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\utils.py\", line 131, in raise_for_status_with_text\n",
      "    raise requests.HTTPError(str(e), response.text) from e  # type: ignore[call-arg]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "requests.exceptions.HTTPError: [Errno 503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback] {\"detail\":\"Internal server error\"}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1264, in _run_evaluators\n",
      "    self.client._log_evaluation_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3745, in _log_evaluation_feedback\n",
      "    self.create_feedback(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 3935, in create_feedback\n",
      "    self.request_with_retries(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\client.py\", line 860, in request_with_retries\n",
      "    raise ls_utils.LangSmithError(\n",
      "langsmith.utils.LangSmithError: Failed to POST /feedback in LangSmith API. HTTPError('503 Server Error: Service Unavailable for url: https://api.smith.langchain.com/feedback', '{\"detail\":\"Internal server error\"}')\n"
     ]
    }
   ],
   "source": [
    "for name in PerunaBot_0_chains:\n",
    "    def predict_chain(inputs: dict):\n",
    "        chain = PerunaBot_0_chains[name]\n",
    "        response = chain.invoke({\"question\": inputs[\"Question\"]})\n",
    "        return response[\"output\"]\n",
    "    \n",
    "    eval = evaluate(\n",
    "        predict_chain,\n",
    "        data=new_data,\n",
    "        evaluators=new_evaluators,\n",
    "        experiment_prefix=f\"{name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 0 v1 (gpt-3.5-turbo)-d608a7a9 vs PerunaBot 0 (gpt-4o)-aa57f368 with prompt: base prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=76f114e5-4a3f-4b79-973d-84ef862987d7%2C5912163a-7251-482c-b7e9-b413a0b60910&comparativeExperiment=84ce9a59-15d6-4e6f-9aee-0b803507a87e\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429d3079a77a4e468618207d8f15197d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 0 v1 (gpt-3.5-turbo)-d608a7a9 vs PerunaBot 0 v2 (gpt-4o-mini)-0dc697ef with prompt: base prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=76f114e5-4a3f-4b79-973d-84ef862987d7%2C3fef4b44-7505-41d8-b0b8-ecc6acfe55c6&comparativeExperiment=12a45220-ce16-46df-966b-1bfb0adf1ead\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e81ba49b709420ab27ee6a0fb685cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 0 (gpt-4o)-aa57f368 vs PerunaBot 0 v2 (gpt-4o-mini)-0dc697ef with prompt: base prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=5912163a-7251-482c-b7e9-b413a0b60910%2C3fef4b44-7505-41d8-b0b8-ecc6acfe55c6&comparativeExperiment=be4d9109-f988-435b-8965-9d5eaf744dff\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "073d8b798c5f489691a3e59d8245ca91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 0 v1 (gpt-3.5-turbo)-d608a7a9 vs PerunaBot 0 (gpt-4o)-aa57f368 with prompt: rag prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=76f114e5-4a3f-4b79-973d-84ef862987d7%2C5912163a-7251-482c-b7e9-b413a0b60910&comparativeExperiment=9fa288c9-a0a8-4ee5-8f50-d4b2176fc396\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8834ba4ad83e44419eeb8f6c3a269577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 0 v1 (gpt-3.5-turbo)-d608a7a9 vs PerunaBot 0 v2 (gpt-4o-mini)-0dc697ef with prompt: rag prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=76f114e5-4a3f-4b79-973d-84ef862987d7%2C3fef4b44-7505-41d8-b0b8-ecc6acfe55c6&comparativeExperiment=61241ed3-1379-4874-84e1-717655f1f358\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f1257496c44626ba83cc94e1bd6c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 0 (gpt-4o)-aa57f368 vs PerunaBot 0 v2 (gpt-4o-mini)-0dc697ef with prompt: rag prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=5912163a-7251-482c-b7e9-b413a0b60910%2C3fef4b44-7505-41d8-b0b8-ecc6acfe55c6&comparativeExperiment=f70479d3-e70b-4cbf-bd54-ba1c506f38bd\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e8605d86024dd9911f21ddf9dba2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 0 v1 (gpt-3.5-turbo)-d608a7a9 vs PerunaBot 0 (gpt-4o)-aa57f368 with prompt: academic advisor prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=76f114e5-4a3f-4b79-973d-84ef862987d7%2C5912163a-7251-482c-b7e9-b413a0b60910&comparativeExperiment=fa5987bd-1310-4a3b-b776-b984180d9e72\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01578a1a0c6749728970be784b1fe61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 0 v1 (gpt-3.5-turbo)-d608a7a9 vs PerunaBot 0 v2 (gpt-4o-mini)-0dc697ef with prompt: academic advisor prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=76f114e5-4a3f-4b79-973d-84ef862987d7%2C3fef4b44-7505-41d8-b0b8-ecc6acfe55c6&comparativeExperiment=55988da4-5389-43e2-9d4d-7f07b26df39e\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4027b35b2c3d43c09cac22385d6c28f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 0 (gpt-4o)-aa57f368 vs PerunaBot 0 v2 (gpt-4o-mini)-0dc697ef with prompt: academic advisor prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=5912163a-7251-482c-b7e9-b413a0b60910%2C3fef4b44-7505-41d8-b0b8-ecc6acfe55c6&comparativeExperiment=1cf732bf-d947-44ab-9010-94d546ec70bf\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b02d9c46e445dbb442f924d169bef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the experiments\n",
    "PerunaBot_0_experiments = [\n",
    "    \"PerunaBot 0 v1 (gpt-3.5-turbo)-d608a7a9\",\n",
    "    \"PerunaBot 0 (gpt-4o)-aa57f368\",\n",
    "    \"PerunaBot 0 v2 (gpt-4o-mini)-0dc697ef\"\n",
    "]\n",
    "\n",
    "# Run the evaluations\n",
    "PerunaBot_0_pairwise_results = run_pairwise_evaluations(PerunaBot_0_experiments, evaluate_pairwise_functions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "![Model Pairwise Evaluation Results](../Data/Evaluation%20Results/pairwise%20evaluation_model%20PerunaBot%200.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data with corrected ties\n",
    "individual_wins = {\n",
    "    \"gpt-3.5-turbo\": 10,\n",
    "    \"gpt-4o\": 41,\n",
    "    \"gpt-4o-mini\": 20,\n",
    "}\n",
    "\n",
    "# Extracting data\n",
    "chains = list(individual_wins.keys())\n",
    "wins = list(individual_wins.values())\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(chains, wins, color=['blue', 'green', 'red'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Number of Individual Wins')\n",
    "\n",
    "# Add text annotations to the plot\n",
    "for i in range(len(chains)):\n",
    "    plt.text(i, wins[i], str(wins[i]), ha='center', va='bottom')\n",
    "\n",
    "plt.title('Comparing different OpenAI Models of PerunaBot 0')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data with wins based on thumbs up\n",
    "overall_wins = {\n",
    "    \"gpt-3.5-turbo\": 0,\n",
    "    \"gpt-4o\": 6,\n",
    "    \"gpt-4o-mini\": 3,\n",
    "}\n",
    "\n",
    "# Extracting data\n",
    "chains = list(overall_wins.keys())\n",
    "thumbs_up_wins = list(overall_wins.values())\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(chains, thumbs_up_wins, color=['blue', 'green', 'red'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Number of Total Wins (Thumbs Up Count)')\n",
    "\n",
    "# Add text annotations to the plot\n",
    "for i in range(len(chains)):\n",
    "    plt.text(i, thumbs_up_wins[i], str(thumbs_up_wins[i]), ha='center', va='bottom')\n",
    "\n",
    "plt.title('Comparing different OpenAI Models of PerunaBot 0')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'PerunaBot 1 v1 (gpt-3.5-turbo)-49ffec10' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=29fac94c-a3ad-46b8-91c1-374bf0dba2d8\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da1a5e1d3be4b47a84827e0502ad36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 5c94ddc5-32df-4b05-b9aa-2f92790c3ed0: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9614, Requested 456. Please try again in 420ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9614, Requested 456. Please try again in 420ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 373d778c-c198-48df-9c10-28f334610384: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9888, Requested 776. Please try again in 3.984s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9888, Requested 776. Please try again in 3.984s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 98c94bcd-3ba1-487d-95a7-7167c94ed3d0: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9777, Requested 500. Please try again in 1.662s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9777, Requested 500. Please try again in 1.662s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 6cf05bbf-5947-4c39-9f42-8c007e20f8bf: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9615, Requested 655. Please try again in 1.62s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9615, Requested 655. Please try again in 1.62s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 373d778c-c198-48df-9c10-28f334610384: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9942, Requested 785. Please try again in 4.362s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9942, Requested 785. Please try again in 4.362s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e9430aaa-fd6d-4493-b5b3-238895b3836e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9928, Requested 513. Please try again in 2.646s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9928, Requested 513. Please try again in 2.646s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 6890ee81-88f6-4931-9d01-b4c2ffd61ad7: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9880, Requested 560. Please try again in 2.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9880, Requested 560. Please try again in 2.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 703e8c98-717c-40f7-a9de-800f59b9f7d9: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9649, Requested 451. Please try again in 600ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9649, Requested 451. Please try again in 600ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 857cb7f0-23ac-4411-ae38-4b9524514dbb: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9616, Requested 482. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9616, Requested 482. Please try again in 588ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run afb6d853-9d39-4f1f-876b-1ecf6f540c14: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9582, Requested 518. Please try again in 600ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9582, Requested 518. Please try again in 600ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a9d000f9-e16d-40e3-ab3a-9618d3cd5e84: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9926, Requested 581. Please try again in 3.042s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9926, Requested 581. Please try again in 3.042s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run ebbeb9b0-7505-45b0-ba70-653adf25aef5: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9474, Requested 585. Please try again in 354ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9474, Requested 585. Please try again in 354ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a9d000f9-e16d-40e3-ab3a-9618d3cd5e84: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9979, Requested 535. Please try again in 3.084s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9979, Requested 535. Please try again in 3.084s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 2967eaf5-cb4b-426a-b3e0-51481680e8c4: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9766, Requested 633. Please try again in 2.394s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9766, Requested 633. Please try again in 2.394s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'PerunaBot 1 (gpt-4o)-dcef3d4e' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=49ef5af7-8ff4-4205-ab6b-35d52fa8f9f4\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb87eefe08de4162ac7c01918a025191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 30000, Used 27609, Requested 3238. Please try again in 1.694s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run bf2b2e9e-7a46-4180-9068-5cda9dbc1a0d: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9954, Requested 816. Please try again in 4.62s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9954, Requested 816. Please try again in 4.62s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 591185fe-e440-4565-8146-4deb77d14776: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9927, Requested 844. Please try again in 4.626s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9927, Requested 844. Please try again in 4.626s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 0ee05866-2203-4154-a4dc-5f091ab0ea84: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9666, Requested 407. Please try again in 438ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9666, Requested 407. Please try again in 438ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f2f65d64-c8df-4ffa-88c0-d70a4099a267: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9639, Requested 799. Please try again in 2.628s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9639, Requested 799. Please try again in 2.628s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run bf2b2e9e-7a46-4180-9068-5cda9dbc1a0d: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9612, Requested 770. Please try again in 2.292s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9612, Requested 770. Please try again in 2.292s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 591185fe-e440-4565-8146-4deb77d14776: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9585, Requested 798. Please try again in 2.298s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9585, Requested 798. Please try again in 2.298s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run bdd864bd-4583-4639-99af-52c7ab11ed7b: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9962, Requested 510. Please try again in 2.832s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9962, Requested 510. Please try again in 2.832s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 89434f78-0516-49fd-a95b-207c622b7ba1: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9910, Requested 560. Please try again in 2.82s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9910, Requested 560. Please try again in 2.82s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run ade497f3-5d73-4c88-800e-a6af955351af: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9799, Requested 655. Please try again in 2.724s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9799, Requested 655. Please try again in 2.724s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f2f65d64-c8df-4ffa-88c0-d70a4099a267: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9738, Requested 753. Please try again in 2.946s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9738, Requested 753. Please try again in 2.946s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 146d5e70-a3f2-4c2b-9031-4103f0a1a20f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9762, Requested 744. Please try again in 3.036s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9762, Requested 744. Please try again in 3.036s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run bf2b2e9e-7a46-4180-9068-5cda9dbc1a0d: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9850, Requested 779. Please try again in 3.774s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9850, Requested 779. Please try again in 3.774s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 591185fe-e440-4565-8146-4deb77d14776: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9821, Requested 807. Please try again in 3.767s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9821, Requested 807. Please try again in 3.767s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 89434f78-0516-49fd-a95b-207c622b7ba1: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9879, Requested 569. Please try again in 2.688s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9879, Requested 569. Please try again in 2.688s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 4423382e-8340-4c05-95d8-d52040665e38: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9797, Requested 650. Please try again in 2.682s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9797, Requested 650. Please try again in 2.682s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run ade497f3-5d73-4c88-800e-a6af955351af: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9783, Requested 664. Please try again in 2.682s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9783, Requested 664. Please try again in 2.682s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f2f65d64-c8df-4ffa-88c0-d70a4099a267: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9976, Requested 762. Please try again in 4.428s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9976, Requested 762. Please try again in 4.428s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 76497bfc-16f0-493e-ad5d-ff7b39b90e1a: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9854, Requested 866. Please try again in 4.32s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9854, Requested 866. Please try again in 4.32s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 146d5e70-a3f2-4c2b-9031-4103f0a1a20f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9744, Requested 753. Please try again in 2.982s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9744, Requested 753. Please try again in 2.982s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 4423382e-8340-4c05-95d8-d52040665e38: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9623, Requested 659. Please try again in 1.692s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9623, Requested 659. Please try again in 1.692s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 474cae85-9e2d-48f1-8c8c-62407b043853: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9595, Requested 801. Please try again in 2.376s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9595, Requested 801. Please try again in 2.376s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 2840bf61-5537-4423-9ecc-19a32afe24fa: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9581, Requested 699. Please try again in 1.68s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9581, Requested 699. Please try again in 1.68s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 76497bfc-16f0-493e-ad5d-ff7b39b90e1a: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9875, Requested 875. Please try again in 4.5s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9875, Requested 875. Please try again in 4.5s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 2840bf61-5537-4423-9ecc-19a32afe24fa: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9823, Requested 653. Please try again in 2.856s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9823, Requested 653. Please try again in 2.856s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 474cae85-9e2d-48f1-8c8c-62407b043853: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9548, Requested 755. Please try again in 1.818s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9548, Requested 755. Please try again in 1.818s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'PerunaBot 1 v2 (gpt-4o-mini)-ef930257' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=8e31113b-4d30-4e7c-98ed-c4d5fd3f6bfa\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c93a905e7d4cc9bd432390416b0c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a7e5f89c-c7cb-48ef-bbcb-2f0c445884a6: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9870, Requested 749. Please try again in 3.714s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9870, Requested 749. Please try again in 3.714s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 1b5cd123-aae2-45a1-bac9-5e1aaca96825: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9861, Requested 759. Please try again in 3.72s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9861, Requested 759. Please try again in 3.72s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 8a5d2acf-89e6-4393-8f1c-acce7479221f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9729, Requested 847. Please try again in 3.456s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9729, Requested 847. Please try again in 3.456s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 3bbea751-340d-4bd9-bccc-5a6532a7ce5e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9645, Requested 692. Please try again in 2.022s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9645, Requested 692. Please try again in 2.022s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 4ddc10fa-3f04-43cb-b506-0d7e39dc26d9: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9943, Requested 477. Please try again in 2.52s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9943, Requested 477. Please try again in 2.52s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a7e5f89c-c7cb-48ef-bbcb-2f0c445884a6: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9737, Requested 703. Please try again in 2.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9737, Requested 703. Please try again in 2.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 1b5cd123-aae2-45a1-bac9-5e1aaca96825: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9720, Requested 713. Please try again in 2.598s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9720, Requested 713. Please try again in 2.598s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 8a5d2acf-89e6-4393-8f1c-acce7479221f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9643, Requested 801. Please try again in 2.664s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9643, Requested 801. Please try again in 2.664s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 081245c2-6ed4-415d-b8ac-da3f09928046: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9529, Requested 490. Please try again in 114ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9529, Requested 490. Please try again in 114ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 85936023-2231-43d4-ae91-82b8dc110b5b: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9512, Requested 505. Please try again in 102ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9512, Requested 505. Please try again in 102ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run c8cbcf1b-838e-4beb-b04c-e448f1202980: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9505, Requested 512. Please try again in 102ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9505, Requested 512. Please try again in 102ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 3bbea751-340d-4bd9-bccc-5a6532a7ce5e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9831, Requested 646. Please try again in 2.862s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9831, Requested 646. Please try again in 2.862s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 081245c2-6ed4-415d-b8ac-da3f09928046: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9988, Requested 499. Please try again in 2.922s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9988, Requested 499. Please try again in 2.922s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 85936023-2231-43d4-ae91-82b8dc110b5b: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9978, Requested 514. Please try again in 2.952s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9978, Requested 514. Please try again in 2.952s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e43250e2-5f1d-4a53-849a-632dc1803bb4: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9895, Requested 601. Please try again in 2.976s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9895, Requested 601. Please try again in 2.976s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a7e5f89c-c7cb-48ef-bbcb-2f0c445884a6: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9782, Requested 712. Please try again in 2.964s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9782, Requested 712. Please try again in 2.964s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 1b5cd123-aae2-45a1-bac9-5e1aaca96825: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9769, Requested 722. Please try again in 2.946s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9769, Requested 722. Please try again in 2.946s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 8a5d2acf-89e6-4393-8f1c-acce7479221f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9659, Requested 810. Please try again in 2.814s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9659, Requested 810. Please try again in 2.814s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run c8cbcf1b-838e-4beb-b04c-e448f1202980: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9936, Requested 521. Please try again in 2.742s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9936, Requested 521. Please try again in 2.742s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run f60a66a3-8423-452a-8999-1f6a2023920b: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9922, Requested 539. Please try again in 2.766s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9922, Requested 539. Please try again in 2.766s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 3bbea751-340d-4bd9-bccc-5a6532a7ce5e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9805, Requested 655. Please try again in 2.76s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9805, Requested 655. Please try again in 2.76s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e43250e2-5f1d-4a53-849a-632dc1803bb4: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9906, Requested 609. Please try again in 3.09s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9906, Requested 609. Please try again in 3.09s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 2924f18c-c1d1-420e-8a8b-61060b3a4c61: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9884, Requested 644. Please try again in 3.168s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9884, Requested 644. Please try again in 3.168s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 129aedc8-6e96-4d09-a411-c6fb4f31a668: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9858, Requested 675. Please try again in 3.198s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9858, Requested 675. Please try again in 3.198s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 2924f18c-c1d1-420e-8a8b-61060b3a4c61: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9824, Requested 598. Please try again in 2.532s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9824, Requested 598. Please try again in 2.532s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 129aedc8-6e96-4d09-a411-c6fb4f31a668: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9793, Requested 629. Please try again in 2.532s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9793, Requested 629. Please try again in 2.532s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 129aedc8-6e96-4d09-a411-c6fb4f31a668: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9949, Requested 638. Please try again in 3.522s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9949, Requested 638. Please try again in 3.522s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "for name in PerunaBot_1_chains:\n",
    "    def predict_chain(inputs: dict):\n",
    "        chain = PerunaBot_1_chains[name]\n",
    "        response = chain.invoke({\"question\": inputs[\"Question\"]})\n",
    "        return response[\"output\"]\n",
    "    \n",
    "    eval = evaluate(\n",
    "        predict_chain,\n",
    "        data=new_data,\n",
    "        evaluators=new_evaluators,\n",
    "        experiment_prefix=f\"{name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 1 v1 (gpt-3.5-turbo)-49ffec10 vs PerunaBot 1 (gpt-4o)-dcef3d4e with prompt: base prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=29fac94c-a3ad-46b8-91c1-374bf0dba2d8%2C49ef5af7-8ff4-4205-ab6b-35d52fa8f9f4&comparativeExperiment=7d32619a-40ff-4817-90cc-19517eececb9\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47cb542734442fa8652e980e744ff57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 1 v1 (gpt-3.5-turbo)-49ffec10 vs PerunaBot 1 v2 (gpt-4o-mini)-ef930257 with prompt: base prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=29fac94c-a3ad-46b8-91c1-374bf0dba2d8%2C8e31113b-4d30-4e7c-98ed-c4d5fd3f6bfa&comparativeExperiment=91cecbcf-650a-4313-90a5-6e57105c290c\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db58933cf5dc48719cef08dc2a5c3cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 1 (gpt-4o)-dcef3d4e vs PerunaBot 1 v2 (gpt-4o-mini)-ef930257 with prompt: base prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=49ef5af7-8ff4-4205-ab6b-35d52fa8f9f4%2C8e31113b-4d30-4e7c-98ed-c4d5fd3f6bfa&comparativeExperiment=3f706bbb-fe6d-414a-b461-14b527fb9d36\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4dd3b2641f4a2281dd56b2091fa5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 1 v1 (gpt-3.5-turbo)-49ffec10 vs PerunaBot 1 (gpt-4o)-dcef3d4e with prompt: rag prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=29fac94c-a3ad-46b8-91c1-374bf0dba2d8%2C49ef5af7-8ff4-4205-ab6b-35d52fa8f9f4&comparativeExperiment=8759a31d-3c54-4a90-a8ec-1628e30736e6\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570edca913ca4108a200d0cf708f11bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 1 v1 (gpt-3.5-turbo)-49ffec10 vs PerunaBot 1 v2 (gpt-4o-mini)-ef930257 with prompt: rag prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=29fac94c-a3ad-46b8-91c1-374bf0dba2d8%2C8e31113b-4d30-4e7c-98ed-c4d5fd3f6bfa&comparativeExperiment=08c134f0-5d15-4a35-83cd-6fd6f4f753cf\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c38a3e99c6144b509987188cde1badf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 1 (gpt-4o)-dcef3d4e vs PerunaBot 1 v2 (gpt-4o-mini)-ef930257 with prompt: rag prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=49ef5af7-8ff4-4205-ab6b-35d52fa8f9f4%2C8e31113b-4d30-4e7c-98ed-c4d5fd3f6bfa&comparativeExperiment=3a72f5ff-ca96-4b8e-99a7-1f55d84584ab\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97b1fe12b1d40738690b95c5c04e2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 1 v1 (gpt-3.5-turbo)-49ffec10 vs PerunaBot 1 (gpt-4o)-dcef3d4e with prompt: academic advisor prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=29fac94c-a3ad-46b8-91c1-374bf0dba2d8%2C49ef5af7-8ff4-4205-ab6b-35d52fa8f9f4&comparativeExperiment=04ce5f9c-8290-4d52-b170-cbe1392005fa\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa0ebe1b09847bc9ac7b5c4ba44bf19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 1 v1 (gpt-3.5-turbo)-49ffec10 vs PerunaBot 1 v2 (gpt-4o-mini)-ef930257 with prompt: academic advisor prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=29fac94c-a3ad-46b8-91c1-374bf0dba2d8%2C8e31113b-4d30-4e7c-98ed-c4d5fd3f6bfa&comparativeExperiment=5f5a5a29-98e6-4a1c-9278-7eb9ec617f80\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da00ba19019e4741908a1a3750c1c375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 1 (gpt-4o)-dcef3d4e vs PerunaBot 1 v2 (gpt-4o-mini)-ef930257 with prompt: academic advisor prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=49ef5af7-8ff4-4205-ab6b-35d52fa8f9f4%2C8e31113b-4d30-4e7c-98ed-c4d5fd3f6bfa&comparativeExperiment=bef5ef5f-a303-4556-b8ae-6747cc2c8e38\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf44ea3aca684a30ae32a04cd43d62ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the experiments\n",
    "PerunaBot_1_experiments = [\n",
    "    \"PerunaBot 1 v1 (gpt-3.5-turbo)-49ffec10\",\n",
    "    \"PerunaBot 1 (gpt-4o)-dcef3d4e\",\n",
    "    \"PerunaBot 1 v2 (gpt-4o-mini)-ef930257\"\n",
    "]\n",
    "\n",
    "# Run the evaluations\n",
    "PerunaBot_1_pairwise_results = run_pairwise_evaluations(PerunaBot_1_experiments, evaluate_pairwise_functions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "![Model Pairwise Evaluation Results](../Data/Evaluation%20Results/pairwise%20evaluation_model%20PerunaBot%201.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data with corrected ties\n",
    "individual_wins = {\n",
    "    \"gpt-3.5-turbo\": 9,\n",
    "    \"gpt-4o\": 40,\n",
    "    \"gpt-4o-mini\": 24,\n",
    "}\n",
    "\n",
    "# Extracting data\n",
    "chains = list(individual_wins.keys())\n",
    "wins = list(individual_wins.values())\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(chains, wins, color=['blue', 'green', 'red'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Number of Individual Wins')\n",
    "\n",
    "# Add text annotations to the plot\n",
    "for i in range(len(chains)):\n",
    "    plt.text(i, wins[i], str(wins[i]), ha='center', va='bottom')\n",
    "\n",
    "plt.title('Comparing different OpenAI Models of PerunaBot 1')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data with wins based on thumbs up\n",
    "overall_wins = {\n",
    "    \"gpt-3.5-turbo\": 0,\n",
    "    \"gpt-4o\": 6,\n",
    "    \"gpt-4o-mini\": 3,\n",
    "}\n",
    "\n",
    "# Extracting data\n",
    "chains = list(overall_wins.keys())\n",
    "thumbs_up_wins = list(overall_wins.values())\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(chains, thumbs_up_wins, color=['blue', 'green', 'red'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Number of Total Wins (Thumbs Up Count)')\n",
    "\n",
    "# Add text annotations to the plot\n",
    "for i in range(len(chains)):\n",
    "    plt.text(i, thumbs_up_wins[i], str(thumbs_up_wins[i]), ha='center', va='bottom')\n",
    "\n",
    "plt.title('Comparing different OpenAI Models of PerunaBot 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'PerunaBot 2 v1 (gpt-3.5-turbo)-a65a6d5f' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=c312def6-4b20-44e6-85de-95ebf88dbe3e\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836ea95888c5482bbbb6b2b776d51321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator evaluate> on run b817345e-c6d4-4fb6-884d-1d447d8336b3: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9981, Requested 494. Please try again in 2.85s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9981, Requested 494. Please try again in 2.85s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 217813c8-a1bd-43b8-b2d6-ed540bd91816: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9955, Requested 529. Please try again in 2.904s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9955, Requested 529. Please try again in 2.904s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 4af52912-e781-4849-bb8d-58213629801f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9878, Requested 605. Please try again in 2.898s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9878, Requested 605. Please try again in 2.898s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run b817345e-c6d4-4fb6-884d-1d447d8336b3: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9673, Requested 503. Please try again in 1.056s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9673, Requested 503. Please try again in 1.056s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 217813c8-a1bd-43b8-b2d6-ed540bd91816: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9838, Requested 538. Please try again in 2.256s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9838, Requested 538. Please try again in 2.256s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 494bf15d-fa3b-4f98-b277-d09ea34579bf: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9664, Requested 476. Please try again in 840ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9664, Requested 476. Please try again in 840ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 187da213-6d2f-4b3c-a3ea-ee8a04878c75: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9648, Requested 491. Please try again in 834ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9648, Requested 491. Please try again in 834ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 1f74b548-90e2-4cef-b2df-75906e27a734: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9640, Requested 502. Please try again in 852ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9640, Requested 502. Please try again in 852ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d46aeca7-3d45-484f-a735-8565cd2ffedb: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9560, Requested 579. Please try again in 834ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9560, Requested 579. Please try again in 834ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 4af52912-e781-4849-bb8d-58213629801f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9954, Requested 614. Please try again in 3.408s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9954, Requested 614. Please try again in 3.408s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 1a8b5e11-be50-4114-87d4-4ec9737fa69d: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9905, Requested 513. Please try again in 2.508s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9905, Requested 513. Please try again in 2.508s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run ffb7ea5c-99ae-4dbf-ad99-8ceaacfc653d: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9549, Requested 583. Please try again in 792ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9549, Requested 583. Please try again in 792ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d6507e06-d9aa-47ba-91d7-15568d2e1edf: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9523, Requested 609. Please try again in 792ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9523, Requested 609. Please try again in 792ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d69a33f5-fac0-4abf-aec4-9d396f8767d6: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9924, Requested 699. Please try again in 3.738s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9924, Requested 699. Please try again in 3.738s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 1d00ec9a-6c7a-4b06-98bf-ffe1e7393441: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9849, Requested 776. Please try again in 3.75s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9849, Requested 776. Please try again in 3.75s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run ffb7ea5c-99ae-4dbf-ad99-8ceaacfc653d: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9675, Requested 537. Please try again in 1.272s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9675, Requested 537. Please try again in 1.272s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d6507e06-d9aa-47ba-91d7-15568d2e1edf: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9646, Requested 563. Please try again in 1.254s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9646, Requested 563. Please try again in 1.254s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run d6507e06-d9aa-47ba-91d7-15568d2e1edf: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9827, Requested 572. Please try again in 2.394s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9827, Requested 572. Please try again in 2.394s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'PerunaBot 2 (gpt-4o)-8055c6d2' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=7cbbf56a-dc72-4a84-9320-de6bc6fc1229\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c084449104d4f57b5c2db3895634330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 30000, Used 29279, Requested 3468. Please try again in 5.494s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 30000, Used 26485, Requested 4036. Please try again in 1.042s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 30000, Used 29963, Requested 4156. Please try again in 8.238s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 30000, Used 25903, Requested 4846. Please try again in 1.498s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run bc63f8d9-5f58-4b4b-90a8-51c8371d2022: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9878, Requested 513. Please try again in 2.346s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9878, Requested 513. Please try again in 2.346s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 9d2a8d77-fe4c-4a6e-bb93-8ff6eeb80ce6: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9838, Requested 550. Please try again in 2.328s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9838, Requested 550. Please try again in 2.328s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run de1b5e1b-a186-461c-824a-f435c24fb472: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9939, Requested 863. Please try again in 4.812s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9939, Requested 863. Please try again in 4.812s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run bc63f8d9-5f58-4b4b-90a8-51c8371d2022: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9923, Requested 467. Please try again in 2.34s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9923, Requested 467. Please try again in 2.34s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 9d2a8d77-fe4c-4a6e-bb93-8ff6eeb80ce6: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9889, Requested 504. Please try again in 2.358s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9889, Requested 504. Please try again in 2.358s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 3e01e6a4-3dec-4a99-ad83-bf06237283cd: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9734, Requested 1112. Please try again in 5.076s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9734, Requested 1112. Please try again in 5.076s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run bc63f8d9-5f58-4b4b-90a8-51c8371d2022: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9567, Requested 475. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9567, Requested 475. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run ac892539-9b8b-4613-abe1-c59256f18963: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9562, Requested 626. Please try again in 1.128s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9562, Requested 626. Please try again in 1.128s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 9d2a8d77-fe4c-4a6e-bb93-8ff6eeb80ce6: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9958, Requested 513. Please try again in 2.826s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9958, Requested 513. Please try again in 2.826s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run db49e4f7-73aa-41d8-93af-9fcdb3ce626f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9881, Requested 676. Please try again in 3.342s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9881, Requested 676. Please try again in 3.342s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run b0d6dffc-3a65-4d4a-a184-86fb2b5efd4a: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9795, Requested 615. Please try again in 2.46s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9795, Requested 615. Please try again in 2.46s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run de1b5e1b-a186-461c-824a-f435c24fb472: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9704, Requested 817. Please try again in 3.126s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9704, Requested 817. Please try again in 3.126s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 3b4185b0-a2b6-4e84-a119-96c38108d87c: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9863, Requested 574. Please try again in 2.622s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9863, Requested 574. Please try again in 2.622s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 13169ea3-29d2-4756-920e-8f5483121815: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9928, Requested 547. Please try again in 2.85s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9928, Requested 547. Please try again in 2.85s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run b0d6dffc-3a65-4d4a-a184-86fb2b5efd4a: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9746, Requested 624. Please try again in 2.22s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9746, Requested 624. Please try again in 2.22s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run ac892539-9b8b-4613-abe1-c59256f18963: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9739, Requested 634. Please try again in 2.238s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9739, Requested 634. Please try again in 2.238s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run db49e4f7-73aa-41d8-93af-9fcdb3ce626f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9687, Requested 685. Please try again in 2.232s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9687, Requested 685. Please try again in 2.232s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a9d31ee1-07af-4b74-92ff-3bed0803f2b6: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9961, Requested 745. Please try again in 4.236s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9961, Requested 745. Please try again in 4.236s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 52f475a7-2a01-45a3-a7b4-40192182a24d: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9910, Requested 418. Please try again in 1.968s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9910, Requested 418. Please try again in 1.968s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run de1b5e1b-a186-461c-824a-f435c24fb472: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9886, Requested 825. Please try again in 4.266s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9886, Requested 825. Please try again in 4.266s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a393a35e-832b-4595-b49b-c5205cf25a0c: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9861, Requested 914. Please try again in 4.65s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9861, Requested 914. Please try again in 4.65s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 3e01e6a4-3dec-4a99-ad83-bf06237283cd: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9749, Requested 1066. Please try again in 4.89s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9749, Requested 1066. Please try again in 4.89s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 3b4185b0-a2b6-4e84-a119-96c38108d87c: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9747, Requested 583. Please try again in 1.98s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9747, Requested 583. Please try again in 1.98s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 13169ea3-29d2-4756-920e-8f5483121815: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9869, Requested 501. Please try again in 2.22s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9869, Requested 501. Please try again in 2.22s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a9d31ee1-07af-4b74-92ff-3bed0803f2b6: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9530, Requested 754. Please try again in 1.704s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9530, Requested 754. Please try again in 1.704s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a393a35e-832b-4595-b49b-c5205cf25a0c: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9951, Requested 923. Please try again in 5.244s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9951, Requested 923. Please try again in 5.244s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 3e01e6a4-3dec-4a99-ad83-bf06237283cd: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9818, Requested 1075. Please try again in 5.358s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9818, Requested 1075. Please try again in 5.358s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'PerunaBot 2 v2 (gpt-4o-mini)-86160f66' at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=cb83589e-4620-43ab-a88f-eb79fcb80ef7\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc5206776654ca1808161ec97f6a772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 243746ac-a7b9-4305-906e-d7c9a6d5c191: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9791, Requested 605. Please try again in 2.376s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9791, Requested 605. Please try again in 2.376s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a1faee7b-21d9-4cec-8ef9-1890d8484525: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9793, Requested 600. Please try again in 2.358s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9793, Requested 600. Please try again in 2.358s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 642f6c0d-69ca-4761-9af7-d870f957ea29: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9762, Requested 634. Please try again in 2.376s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9762, Requested 634. Please try again in 2.376s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run bf366290-ec0a-4dd3-8e4a-06ed6fc980ee: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9722, Requested 675. Please try again in 2.382s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9722, Requested 675. Please try again in 2.382s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 9ff68c54-2c08-4e5a-b204-51a1fb38124a: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9669, Requested 727. Please try again in 2.376s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9669, Requested 727. Please try again in 2.376s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e264b6ef-cb5e-4a93-9a44-92ee6146ec3e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9649, Requested 747. Please try again in 2.376s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9649, Requested 747. Please try again in 2.376s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 35d544be-c8e9-475e-b3f5-55ee81cdd689: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9978, Requested 433. Please try again in 2.466s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9978, Requested 433. Please try again in 2.466s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run c81f7607-836a-437f-8bba-a9d50601c384: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9974, Requested 469. Please try again in 2.658s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9974, Requested 469. Please try again in 2.658s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a1faee7b-21d9-4cec-8ef9-1890d8484525: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9900, Requested 554. Please try again in 2.724s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9900, Requested 554. Please try again in 2.724s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 243746ac-a7b9-4305-906e-d7c9a6d5c191: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9896, Requested 559. Please try again in 2.73s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9896, Requested 559. Please try again in 2.73s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 642f6c0d-69ca-4761-9af7-d870f957ea29: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9818, Requested 588. Please try again in 2.436s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9818, Requested 588. Please try again in 2.436s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run bf366290-ec0a-4dd3-8e4a-06ed6fc980ee: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9780, Requested 629. Please try again in 2.454s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9780, Requested 629. Please try again in 2.454s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 9ff68c54-2c08-4e5a-b204-51a1fb38124a: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9732, Requested 681. Please try again in 2.478s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9732, Requested 681. Please try again in 2.478s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e264b6ef-cb5e-4a93-9a44-92ee6146ec3e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9710, Requested 701. Please try again in 2.466s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9710, Requested 701. Please try again in 2.466s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 7ce9087b-a6e5-41a0-b96a-10ab9f9bec7f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9937, Requested 494. Please try again in 2.586s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9937, Requested 494. Please try again in 2.586s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run eb2e99d0-9256-42a2-a6d1-414d97ae4fdd: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9897, Requested 522. Please try again in 2.514s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9897, Requested 522. Please try again in 2.514s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run a1faee7b-21d9-4cec-8ef9-1890d8484525: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9900, Requested 562. Please try again in 2.772s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9900, Requested 562. Please try again in 2.772s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 243746ac-a7b9-4305-906e-d7c9a6d5c191: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9892, Requested 568. Please try again in 2.76s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9892, Requested 568. Please try again in 2.76s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 642f6c0d-69ca-4761-9af7-d870f957ea29: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9867, Requested 597. Please try again in 2.784s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9867, Requested 597. Please try again in 2.784s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run bf366290-ec0a-4dd3-8e4a-06ed6fc980ee: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9827, Requested 638. Please try again in 2.79s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9827, Requested 638. Please try again in 2.79s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 9ff68c54-2c08-4e5a-b204-51a1fb38124a: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9774, Requested 689. Please try again in 2.778s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9774, Requested 689. Please try again in 2.778s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run e264b6ef-cb5e-4a93-9a44-92ee6146ec3e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9756, Requested 710. Please try again in 2.796s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9756, Requested 710. Please try again in 2.796s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 7ce9087b-a6e5-41a0-b96a-10ab9f9bec7f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9626, Requested 503. Please try again in 774ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9626, Requested 503. Please try again in 774ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run eb2e99d0-9256-42a2-a6d1-414d97ae4fdd: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9597, Requested 531. Please try again in 768ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9597, Requested 531. Please try again in 768ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 2c9931ad-7fb1-421e-8292-7dc4e56a6bd5: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9760, Requested 623. Please try again in 2.298s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9760, Requested 623. Please try again in 2.298s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 8cf2837f-ba4d-4158-b538-6ed3d651fba4: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9736, Requested 639. Please try again in 2.25s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9736, Requested 639. Please try again in 2.25s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 0c701213-1014-4176-bf27-613f6ccfd2d2: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9632, Requested 904. Please try again in 3.216s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\qa\\eval_chain.py\", line 308, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9632, Requested 904. Please try again in 3.216s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 2c9931ad-7fb1-421e-8292-7dc4e56a6bd5: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9530, Requested 577. Please try again in 642ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9530, Requested 577. Please try again in 642ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 8cf2837f-ba4d-4158-b538-6ed3d651fba4: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9984, Requested 593. Please try again in 3.462s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9984, Requested 593. Please try again in 3.462s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 0c701213-1014-4176-bf27-613f6ccfd2d2: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9945, Requested 858. Please try again in 4.818s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1258, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 278, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 582, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 579, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 260, in evaluate\n",
      "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\schema.py\", line 220, in evaluate_strings\n",
      "    return self._evaluate_strings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\evaluation\\criteria\\eval_chain.py\", line 447, in _evaluate_strings\n",
      "    result = self(\n",
      "             ^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 168, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 383, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 128, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py\", line 140, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 703, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 560, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 550, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 775, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 589, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 646, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 942, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1031, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1079, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1046, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-Hkbsf8yAWp77cZYrVZcR2Dim on tokens per min (TPM): Limit 10000, Used 9945, Requested 858. Please try again in 4.818s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "for name in PerunaBot_2_chains:\n",
    "    def predict_chain(inputs: dict):\n",
    "        chain = PerunaBot_2_chains[name]\n",
    "        response = chain.invoke({\"question\": inputs[\"Question\"]})\n",
    "        return response[\"output\"]\n",
    "    \n",
    "    eval = evaluate(\n",
    "        predict_chain,\n",
    "        data=new_data,\n",
    "        evaluators=new_evaluators,\n",
    "        experiment_prefix=f\"{name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 2 v1 (gpt-3.5-turbo)-a65a6d5f vs PerunaBot 2 (gpt-4o)-f9aa86ca with prompt: base prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=c312def6-4b20-44e6-85de-95ebf88dbe3e%2C501e9203-57e1-49d2-a5ad-f3fe53831c54&comparativeExperiment=520e13c2-941b-426f-a6c5-f18e94555f8d\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808e09ca040d4ea2829fc16eb3fe3d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 2 v1 (gpt-3.5-turbo)-a65a6d5f vs PerunaBot 2 v2 (gpt-4o-mini)-86160f66 with prompt: base prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=c312def6-4b20-44e6-85de-95ebf88dbe3e%2Ccb83589e-4620-43ab-a88f-eb79fcb80ef7&comparativeExperiment=2cff9ec0-56b8-4a69-8a22-56167bd9e63b\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a62ab09f9c54cd59efdf4594574532b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 2 (gpt-4o)-f9aa86ca vs PerunaBot 2 v2 (gpt-4o-mini)-86160f66 with prompt: base prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=501e9203-57e1-49d2-a5ad-f3fe53831c54%2Ccb83589e-4620-43ab-a88f-eb79fcb80ef7&comparativeExperiment=4e31909f-d741-4a76-92fa-f32297678f8c\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6143ab693a794f72b8a1e664a1347446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 2 v1 (gpt-3.5-turbo)-a65a6d5f vs PerunaBot 2 (gpt-4o)-f9aa86ca with prompt: rag prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=c312def6-4b20-44e6-85de-95ebf88dbe3e%2C501e9203-57e1-49d2-a5ad-f3fe53831c54&comparativeExperiment=8098fbc7-97b9-4f0c-8a4f-db38d87bf060\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a73f643bc8941f6ab2b4df62c687d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 2 v1 (gpt-3.5-turbo)-a65a6d5f vs PerunaBot 2 v2 (gpt-4o-mini)-86160f66 with prompt: rag prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=c312def6-4b20-44e6-85de-95ebf88dbe3e%2Ccb83589e-4620-43ab-a88f-eb79fcb80ef7&comparativeExperiment=48ed42ce-3531-43c0-aa7e-6b4020be31d9\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c5c0c0673a41debb533fbe95e9fd00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 2 (gpt-4o)-f9aa86ca vs PerunaBot 2 v2 (gpt-4o-mini)-86160f66 with prompt: rag prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=501e9203-57e1-49d2-a5ad-f3fe53831c54%2Ccb83589e-4620-43ab-a88f-eb79fcb80ef7&comparativeExperiment=633ab6e5-3144-468a-b5b6-a874179e69c7\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49dcecf067dc4ffb8231c7d2d3124f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 2 v1 (gpt-3.5-turbo)-a65a6d5f vs PerunaBot 2 (gpt-4o)-f9aa86ca with prompt: academic advisor prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=c312def6-4b20-44e6-85de-95ebf88dbe3e%2C501e9203-57e1-49d2-a5ad-f3fe53831c54&comparativeExperiment=3788a987-5d9c-4b36-b398-48781591f52f\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063bedec198f43a399429ccafbe42de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 2 v1 (gpt-3.5-turbo)-a65a6d5f vs PerunaBot 2 v2 (gpt-4o-mini)-86160f66 with prompt: academic advisor prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=c312def6-4b20-44e6-85de-95ebf88dbe3e%2Ccb83589e-4620-43ab-a88f-eb79fcb80ef7&comparativeExperiment=d3263f25-eaba-4b48-bfa1-34d901e53038\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ca14366a7246718d7a85c00340ba41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: PerunaBot 2 (gpt-4o)-f9aa86ca vs PerunaBot 2 v2 (gpt-4o-mini)-86160f66 with prompt: academic advisor prompt\n",
      "View the pairwise evaluation results at:\n",
      "https://smith.langchain.com/o/d6d3de7f-d3b8-5077-9835-ce02339ff6b9/datasets/90a80182-3966-43f5-8ab9-b06519a23848/compare?selectedSessions=501e9203-57e1-49d2-a5ad-f3fe53831c54%2Ccb83589e-4620-43ab-a88f-eb79fcb80ef7&comparativeExperiment=a1881e9c-b64f-4348-85e0-02f40562f2d5\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87fa0c2d1ae44a77a2d39f635bda468b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the experiments\n",
    "PerunaBot_2_experiments = [\n",
    "    \"PerunaBot 2 v1 (gpt-3.5-turbo)-a65a6d5f\",\n",
    "    \"PerunaBot 2 (gpt-4o)-f9aa86ca\",\n",
    "    \"PerunaBot 2 v2 (gpt-4o-mini)-86160f66\"\n",
    "]\n",
    "\n",
    "# Run the evaluations\n",
    "PerunaBot_2_pairwise_results = run_pairwise_evaluations(PerunaBot_2_experiments, evaluate_pairwise_functions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "![Model Pairwise Evaluation Results](../Data/Evaluation%20Results/pairwise%20evaluation_model%20PerunaBot%202.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data with corrected ties\n",
    "individual_wins = {\n",
    "    \"gpt-3.5-turbo\": 19,\n",
    "    \"gpt-4o\": 37,\n",
    "    \"gpt-4o-mini\": 29,\n",
    "}\n",
    "\n",
    "# Extracting data\n",
    "chains = list(individual_wins.keys())\n",
    "wins = list(individual_wins.values())\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(chains, wins, color=['blue', 'green', 'red'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Number of Individual Wins')\n",
    "\n",
    "# Add text annotations to the plot\n",
    "for i in range(len(chains)):\n",
    "    plt.text(i, wins[i], str(wins[i]), ha='center', va='bottom')\n",
    "\n",
    "plt.title('Comparing different OpenAI Models of PerunaBot 1')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data with wins based on thumbs up\n",
    "overall_wins = {\n",
    "    \"gpt-3.5-turbo\": 0,\n",
    "    \"gpt-4o\": 3,\n",
    "    \"gpt-4o-mini\": 3,\n",
    "}\n",
    "\n",
    "# Extracting data\n",
    "chains = list(overall_wins.keys())\n",
    "thumbs_up_wins = list(overall_wins.values())\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(chains, thumbs_up_wins, color=['blue', 'green', 'red'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Number of Total Wins (Thumbs Up Count)')\n",
    "\n",
    "# Add text annotations to the plot\n",
    "for i in range(len(chains)):\n",
    "    plt.text(i, thumbs_up_wins[i], str(thumbs_up_wins[i]), ha='center', va='bottom')\n",
    "\n",
    "plt.title('Comparing different OpenAI Models of PerunaBot 1')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
