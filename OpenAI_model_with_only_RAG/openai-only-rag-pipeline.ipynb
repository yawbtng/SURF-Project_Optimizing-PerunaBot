{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2a: RAG pipeline for the OpenAI chat model\n",
    "Now we are moving on to the RAG pipeline for the base Open AI model that is not fine-tuned. This is the most identical to how it was done in [the original project](https://github.com/yawbtng/SMUChatBot_Project/blob/main/app.py) where we did not train the model on the data but just gave it access to the data. Think of it like an open book test where you haven't **learned** the information, but it's directly in front of you.\n",
    "\n",
    "So in this step, we will create the actual [RAG chain](https://python.langchain.com/v0.2/docs/tutorials/rag/#retrieval-and-generation) using the vectorstores and retrievers we made in the data preprocessing python script in the 'Common' folder, along with other modules we will need.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to include the proper imports and load any environment variables we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up to initialize API keys from .env file into the\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "# Load environment variables from the .env files\n",
    "load_dotenv(find_dotenv(filename='SURF-Project_Optimizing-PerunaBot/setup/.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='2 + 7 = 9', response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 13, 'total_tokens': 20}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c7f93632-7be0-4fb6-91a9-e790010ac9d9-0', usage_metadata={'input_tokens': 13, 'output_tokens': 7, 'total_tokens': 20})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# langsmith for tracing\n",
    "\n",
    "from langsmith import Client\n",
    "langsmith_api_key = os.environ[\"LANGSMITH_API_KEY\"]\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]\n",
    "langchain_endpoint = os.environ[\"LANGCHAIN_ENDPOINT\"]\n",
    "langsmith_project = os.environ[\"LANGCHAIN_PROJECT\"]\n",
    "\n",
    "langmsiht_client = Client()\n",
    "\n",
    "# test\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI()\n",
    "llm.invoke(\"What is 2+7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are importing data_preprocessing.py in the Common folder to use the functions that geet the langchain docs, vectorstores, and retrievers for us to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Southern Methodist University \n",
      "General Information \n",
      "Undergraduate Catalog  \n",
      "2023 -2024  \n",
      "{'source': 'C:/Users/yawbt/OneDrive/Documents/GitHub/SURF-Project_Optimizing-PerunaBot/Data/20232024 Undergraduate Catalog91123.pdf', 'page': 0}\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Southern Methodist University \n",
      "General Information \n",
      "Undergraduate Catalog  \n",
      "2023 -2024   \n",
      "2443\n",
      "Southern Methodist University \n",
      "General Information \n",
      "Undergraduate Catalog  \n",
      "2023 -2024\n",
      "7323\n",
      "['University Advising Center FAQs', 'Student Financial Services FAQs', 'Parent FAQs', 'SMU Experience FAQs', 'UG Admissions Academics FAQs']\n",
      "[('C:/Users/yawbt/OneDrive/Documents/GitHub/SURF-Project_Optimizing-PerunaBot/Data/University Advising Center FAQs.csv', 'https://www.smu.edu/provost/saes/academic-support/university-advising-center/frequently-asked-questions'), ('C:/Users/yawbt/OneDrive/Documents/GitHub/SURF-Project_Optimizing-PerunaBot/Data/Student Financial Services FAQs.csv', 'https://www.smu.edu/provost/saes/academic-support/student-academic-success/faq'), ('C:/Users/yawbt/OneDrive/Documents/GitHub/SURF-Project_Optimizing-PerunaBot/Data/Parent FAQs.csv', 'https://www.smu.edu/provost/saes/academic-support/university-advising-center/incoming-students/for-parents'), ('C:/Users/yawbt/OneDrive/Documents/GitHub/SURF-Project_Optimizing-PerunaBot/Data/SMU Experience FAQs.csv', 'https://www.smu.edu/admission/campuslife/faqlivingoncampus'), ('C:/Users/yawbt/OneDrive/Documents/GitHub/SURF-Project_Optimizing-PerunaBot/Data/UG Admissions Academics FAQs.csv', 'https://www.smu.edu/admission/academics/faqsacademics')]\n",
      "page_content=\"question: What's the difference between all-college GPA and SMU GPA?\\nanswer: Your all-college GPA is the GPA used from all your grades at any college or university you’ve attended, including SMU. \\nYour SMU GPA is your GPA based only on your SMU grades. Some schools/majors use your all-college GPA or grades in courses you’ve\\n taken at another institution to determine if they will admit you to their major.\" metadata={'source': 'https://www.smu.edu/provost/saes/academic-support/university-advising-center/frequently-asked-questions', 'row': 0}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/yawbt/OneDrive/Documents/GitHub/SURF-Project_Optimizing-PerunaBot/Common')\n",
    "import data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PDF docs: 1015\n",
      "Number of CSV docs: 105\n"
     ]
    }
   ],
   "source": [
    "# getting langchain docs\n",
    "pdf_docs = data_preprocessing.get_all_langchain_docs()[\"pdf_docs\"]\n",
    "csv_docs = data_preprocessing.get_all_langchain_docs()[\"csv_docs\"]\n",
    "\n",
    "# getting collection 0 retriever and vector store\n",
    "vector_store_0 = data_preprocessing.get_all_vectorstores()[\"vector_store_0\"]\n",
    "vector_store_0_retriever = data_preprocessing.get_all_retrievers()[\"vector_store_0_retriever\"]\n",
    "\n",
    "# getting collection 1 retriever and vector store\n",
    "vector_store_1 = data_preprocessing.get_all_vectorstores()[\"vector_store_1\"]\n",
    "parent_retriever =  data_preprocessing.get_all_retrievers()[\"parent_retriever\"]\n",
    "\n",
    "# getting collection 2 retriever and vector store\n",
    "vector_store_2 = data_preprocessing.get_all_vectorstores()[\"vector_store_2\"]\n",
    "ensemble_retriever =  data_preprocessing.get_all_retrievers()[\"ensemble_retriever\"]\n",
    "\n",
    "# Now you can use these objects as needed in your notebook\n",
    "print(f\"Number of PDF docs: {len(pdf_docs)}\")\n",
    "print(f\"Number of CSV docs: {len(csv_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initializing OpenAI API key for chat model and later use\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "gpt_4o = ChatOpenAI(model=\"gpt-4o\", temperature=0, max_tokens=None, \n",
    "                         timeout=None, max_retries=2)\n",
    "\n",
    "gpt_3point5 = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, max_tokens=None, \n",
    "                         timeout=None, max_retries=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
