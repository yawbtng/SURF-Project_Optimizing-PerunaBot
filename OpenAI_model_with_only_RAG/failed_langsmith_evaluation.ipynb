{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load environment variables from the .env file using 'from dotenv import find_dotenv, load_dotenv'\n",
    "load_dotenv(find_dotenv(filename='SURF-Project_Optimizing-PerunaBot/setup/.env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from OG_PerunaBot_chain import Original_PerunaBot_eval_chain\n",
    "from chain_0 import base_retriever_eval_chain_0\n",
    "from chain_1 import parent_retriever_eval_chain_1\n",
    "from chain_2 import ensemble_retriever_eval_chain_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#langsmith\n",
    "from langsmith import Client\n",
    "import os\n",
    "\n",
    "langsmith_api_key = os.environ[\"LANGSMITH_API_KEY\"]\n",
    "langchain_endpoint = os.environ[\"LANGCHAIN_ENDPOINT\"]\n",
    "langsmith_project = os.environ[\"LANGCHAIN_PROJECT\"]\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]\n",
    "\n",
    "# Initialize LangSmith Client using 'from langsmith import Client'\n",
    "langsmith_client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_function(chain):\n",
    "    def predict(inputs: dict) -> dict:\n",
    "        text = inputs.get(\"question\", \"test\")  # Extract the 'text' key from the input dictionary\n",
    "        result = chain.invoke({\"input\": text})  # Call your chain with the extracted text\n",
    "        return {\"output\": result}  # Return the result as a dictionary\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.smith import RunEvalConfig, run_on_dataset\n",
    "from langchain.evaluation import EvaluatorType, load_evaluator\n",
    "from langchain.evaluation.criteria import CriteriaEvalChain, Criteria\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# datasets in langsmith\n",
    "data_set_1 = \"SMU Schools Basic Info\"\n",
    "data_set_2 = \"SMU Campus Facts\"\n",
    "project_name = \"First test eval for \"\n",
    "\n",
    "eval_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Evaluation configuration\n",
    "eval_config = RunEvalConfig(\n",
    "    evaluators = [\n",
    "        load_evaluator(EvaluatorType.QA),\n",
    "        load_evaluator(EvaluatorType.CONTEXT_QA),\n",
    "        load_evaluator(EvaluatorType.COT_QA),\n",
    "        CriteriaEvalChain.from_llm(eval_llm, criteria=Criteria.RELEVANCE),\n",
    "        CriteriaEvalChain.from_llm(eval_llm, criteria=Criteria.COHERENCE),\n",
    "        CriteriaEvalChain.from_llm(eval_llm, criteria=Criteria.DETAIL),\n",
    "        CriteriaEvalChain.from_llm(eval_llm, criteria=Criteria.HELPFULNESS)\n",
    "    ],\n",
    "    eval_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the target task\n",
    "def evaluate_chain(chain, dataset, chain_name):\n",
    "    chain_results = run_on_dataset(\n",
    "        client=langsmith_client,\n",
    "        llm_or_chain_factory=predict_function(chain),\n",
    "        evaluation=eval_config,\n",
    "        dataset_name=dataset,\n",
    "        verbose=True,\n",
    "        project_name= project_name + chain_name,\n",
    "        project_metadata={\n",
    "            \"chain\": chain_name,\n",
    "            \"dataset\": dataset,\n",
    "            \"version\": \"0.1\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluate_chain(Original_PerunaBot_eval_chain, data_set_1, \"Original PerunaBot chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chain 0 on data set 1\n",
    "evaluate_chain(base_retriever_eval_chain_0, data_set_1, \"Base Retriever Chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chain 1 on data set 1\n",
    "evaluate_chain(parent_retriever_eval_chain_1, data_set_1, \"Parent Retriever Chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chain 2 on data set 1\n",
    "evaluate_chain(ensemble_retriever_eval_chain_2, data_set_1, \"Ensemble Retriever Chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OG PerunaBot Chain on data set 2\n",
    "evaluate_chain(Original_PerunaBot__eval_chain, data_set_2, \"Original PerunaBot chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chain 0 on data set 2\n",
    "evaluate_chain(base_retriever__eval_chain_0, data_set_2, \"Base Retriever Chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chain 1 on data set 2\n",
    "evaluate_chain(parent_retriever__eval_chain_1, data_set_2, \"Parent Retriever Chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chain 2 on data set 2\n",
    "evaluate_chain(ensemble_retriever__eval_chain_2, data_set_2, \"Ensemble Retriever Chain\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
