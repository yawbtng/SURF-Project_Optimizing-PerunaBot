{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load environment variables from the .env file using 'from dotenv import find_dotenv, load_dotenv'\n",
    "load_dotenv(find_dotenv(filename='SURF-Project_Optimizing-PerunaBot/setup/.env'))\n",
    "\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#langsmith\n",
    "from langsmith import Client\n",
    "import os\n",
    "\n",
    "langsmith_api_key = os.environ[\"LANGSMITH_API_KEY\"]\n",
    "langchain_endpoint = os.environ[\"LANGCHAIN_ENDPOINT\"]\n",
    "langsmith_project = os.environ[\"LANGCHAIN_PROJECT\"]\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]\n",
    "\n",
    "# Initialize LangSmith Client using 'from langsmith import Client'\n",
    "langsmith_client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yawbt\\OneDrive\\Documents\\GitHub\\SURF-Project_Optimizing-PerunaBot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.1.2 and will be removed in 0.5.0. Use QdrantVectorStore instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from OG_PerunaBot_chain import Original_PerunaBot_eval_chain\n",
    "from chain_0 import base_retriever_eval_chain_0\n",
    "from chain_1 import parent_retriever_eval_chain_1\n",
    "from chain_2 import ensemble_retriever_eval_chain_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.integrations.langchain import EvaluatorChain\n",
    "from langchain.smith import run_on_dataset, RunEvalConfig\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    ")\n",
    "\n",
    "# create evaluation chains\n",
    "faithfulness_chain = EvaluatorChain(metric=faithfulness)\n",
    "answer_rel_chain = EvaluatorChain(metric=answer_relevancy)\n",
    "context_rel_chain = EvaluatorChain(metric=context_precision)\n",
    "context_recall_chain = EvaluatorChain(metric=context_recall)\n",
    "\n",
    "\n",
    "# Wrap the RAGAS metrics to use in LangChain\n",
    "evaluators = [\n",
    "    faithfulness_chain,\n",
    "    answer_rel_chain,\n",
    "    context_rel_chain,\n",
    "    context_recall_chain,\n",
    "]\n",
    "\n",
    "eval_config = RunEvalConfig(custom_evaluators=evaluators)\n",
    "\n",
    "# datasets in langsmith\n",
    "data_set_1 = \"SMU Schools Basic Info\"\n",
    "data_set_2 = \"SMU Campus Facts\"\n",
    "project_name = \"First test eval for \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Original PerunaBot chain on dataset 1\n",
    "chain_results = run_on_dataset(\n",
    "    client=langsmith_client,\n",
    "    llm_or_chain_factory=Original_PerunaBot_eval_chain,\n",
    "    dataset_name=data_set_1,\n",
    "    verbose=True,\n",
    "    evaluation=eval_config,\n",
    "    project_name=project_name + \"Original PerunaBot chain\",\n",
    "    project_metadata={\n",
    "            \"chain\": \"Original_PerunaBot_eval_chain\",\n",
    "            \"dataset\": data_set_1,\n",
    "            \"version\": \"0.1\"\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      "14 \n",
      " About SMU  \n",
      "The Vision of Southern Methodist University  \n",
      "To create and impart knowledge that w\n",
      "{'source': '../Data/Evaluation Data/Southern Methodist University - 2023-2024 Undergraduate Catalog from About SMU to Right to Know.pdf', 'page': 7}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# file paths of PDFs to be used\n",
    "pdf_paths = ['../Data/Evaluation Data/Southern Methodist University - 2023-2024 Undergraduate Catalog from About SMU to Right to Know.pdf',\n",
    "             '../Data/Evaluation Data/Important University Resources from SMU Student Handbook 23-24.pdf',\n",
    "             '../Data/Evaluation Data/Important SMU Numbers and Websites.pdf'\n",
    "             ]\n",
    "\n",
    "# Function to load PDFs using LangChain's PyPDFLoader\n",
    "def load_pdfs_with_langchain(pdf_paths):\n",
    "    documents = []\n",
    "    for path in pdf_paths:\n",
    "        try:\n",
    "            # Use LangChain's PyPDFLoader to load the PDF\n",
    "            loader = PyPDFLoader(path)\n",
    "            # Load and pase the PDF into document instances\n",
    "            pdf_doc = loader.load()\n",
    "            # Insert the parsed PDF documents into the documents list\n",
    "            documents.extend(pdf_doc)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {path}: {e}\")\n",
    "    return documents\n",
    "\n",
    "# Load PDF documents using the function\n",
    "evaluation_pdf_docs = load_pdfs_with_langchain(pdf_paths)\n",
    "\n",
    "print(len(evaluation_pdf_docs))\n",
    "print(evaluation_pdf_docs[0].page_content[0:100])\n",
    "print(evaluation_pdf_docs[7].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798\n",
      "14 \n",
      " About SMU  \n",
      "The Vision of Southern Methodist University  \n",
      "To create and impart knowledge that w\n",
      "{'source': '../Data/Evaluation Data/Southern Methodist University - 2023-2024 Undergraduate Catalog from About SMU to Right to Know.pdf', 'page': 0, 'start_index': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50, \n",
    "                                                length_function=len, add_start_index=True)  \n",
    "\n",
    "# Split the PDF documents into chunks using the text splitter\n",
    "split_evaluation_pdf_docs = text_splitter.split_documents(evaluation_pdf_docs)\n",
    "print(len(split_evaluation_pdf_docs))\n",
    "print(split_evaluation_pdf_docs[0].page_content[0:100])\n",
    "print(split_evaluation_pdf_docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303017c611874b7899691f6d4a90d6c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/1596 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b855dbd9ccf42eea0a926bbaad46a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import embeddings\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "#generator with openai models\n",
    "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "critic_llm= ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "     generator_llm=generator_llm,\n",
    "    critic_llm=critic_llm,\n",
    "    embeddings=embeddings, \n",
    ")\n",
    "\n",
    "# Generate testset\n",
    "testset_1 = generator.generate_with_langchain_docs(split_evaluation_pdf_docs, test_size=10, distributions = {simple: 0.5, reasoning: 0.3, multi_context: 0.2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad32cf6d0d9740e19f65e4758854118d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/1596 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01ad710656d4333886f5851b6a202ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate testset\n",
    "testset_2 = generator.generate_with_langchain_docs(split_evaluation_pdf_docs, test_size=10, distributions = {simple: 0.5, reasoning: 0.3, multi_context: 0.2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eace5c19a2754660bee36c82e4891a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/1596 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfb0349472f4173ad400bcc354667a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate testset\n",
    "testset_3 = generator.generate_with_langchain_docs(split_evaluation_pdf_docs, test_size=10, distributions = {simple: 0.2, reasoning: 0.4, multi_context: 0.4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testset_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test_df_1 \u001b[38;5;241m=\u001b[39m \u001b[43mtestset_1\u001b[49m\u001b[38;5;241m.\u001b[39mto_pandas()\n\u001b[0;32m      3\u001b[0m test_df_2 \u001b[38;5;241m=\u001b[39m testset_2\u001b[38;5;241m.\u001b[39mto_pandas()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testset_1' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "test_df_1 = testset_1.to_pandas()\n",
    "test_df_2 = testset_2.to_pandas()\n",
    "test_df_3 = testset_3.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test set data frames to pandas data frames\n",
    "test_df_1 = testset_1.to_pandas()\n",
    "test_df_2 = testset_2.to_pandas()\n",
    "test_df_3 = testset_3.to_pandas()\n",
    "\n",
    "# Save pandas data frames as CSV files\n",
    "test_df_1.to_csv('testset_1.csv', index=False)\n",
    "test_df_2.to_csv('testset_2.csv', index=False)\n",
    "test_df_3.to_csv('testset_3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
